# Материал для подгоовки к собесам

> ## SOLID

### Single Responsibility Principle - Принцип единственной ответственности.

_**У класса должен быть только один мотив для изменения.**_<br>

Каждый класс должен отвечать только за одну часть функциональности программы,
причём она должна быть полностью инкапсулирована в этот класс
(читай, скрыта внутри класса).

### Open/Closed Principle - Принцип открытости/закрытости

**_Расширяйте классы, но не изменяйте их первоначальный код._**

Классы должны быть открыты для расширения, но закрыты для изменения. Главная
идея этого принципа в том, чтобы не ломать существующий код при
внесении изменений в программу.

### Liskov Substitution Principle - Принцип подстановки Барбары Лисков

**_Подклассы должны дополнять, а не замещать поведение базового класса._**

Подклассы должны создаваться таким образом, чтобы их объекты можно было бы
подставлять вместо объектов базового класса, не ломая при этом функциональности
клиентского кода.

### Interface Segregation Principle - Принцип разделения интерфейса

**_Клиенты не должны зависеть от методов, которые они не используют._**

Интерфейсы должны быть достаточно узкими, чтобы классам не приходилось
реализовывать
избыточное поведение.

Принцип разделения интерфейсов говорит о том, что слишком «толстые» интерфейсы
необходимо разделять на более маленькие и специфические, чтобы клиенты маленьких
интерфейсов знали только о методах, которые необходимы им в работе. В итоге при
изменении метода интерфей- са не должны меняться клиенты, которые этот метод не
используют.

Наследование позволяет классу иметь только один суперкласс, но не ограничивает
количество интерфейсов, которые он может реализовать. Большинство объектных
языков программирования позволяют классам реализовывать сразу несколько
интерфейсов, поэтому нет нужды заталкивать в ваш интерфейс больше поведений, чем
он того требует. Вы всегда можете присвоить классу сразу несколько интерфейсов
поменьше.

### Dependency Inversion Principle - Принцип инверсии зависимостей

**_Классы верхних уровней не должны зависеть от классов нижних уровней. Оба
должны зависеть от абстракций. Абстракции не должны зависеть от деталей. Детали
должны зависеть от абстракций._**

> ## Java Generic. Можем как-то ограничить типы (про super)

Верхний уровень обобщений (Upper Bound Wildcards)

Верхний уровень обобщений используется для ограничения типа, который может быть
использован в качестве параметра. Это делается с помощью ключевого слова
extends. Например:

```java
public void processList(List<? extends Number> list) {
    for (Number number : list) {
        System.out.println(number);
    }
}
```

Нижний уровень обобщений (Lower Bound Wildcards)

Нижний уровень обобщений используется для указания того, что параметр может быть
определён как определённый тип или любой его суперкласс. Это делается с помощью
ключевого слова super. Например:

```java
public void addNumbers(List<? super Integer> list) {
    list.add(1);
    list.add(2);
}
```

Применение

Верхние границы полезны, когда вы хотите читать данные из структуры данных и не
хотите беспокоиться о том, какой конкретный подтип вы получаете.
Нижние границы полезны, когда вы хотите добавлять данные в структуру данных и
хотите гарантировать, что вы можете добавлять элементы определенного типа или
его подтипов.  
Эти концепции позволяют создавать более гибкие и безопасные API в Java.

> ## JAVA CORE. <br> Generics. PECS

Принцип PECS (Producer Extends, Consumer Super) — это концепция, связанная с
использованием обобщений (generics) в Java, которая помогает правильно управлять
типами при работе с коллекциями и другими обобщенными структурами данных. Этот
принцип особенно полезен для понимания, как использовать wildcard-тип (неопреде-
ленный тип) в Java.

**Основные идеи PECS**

Producer Extends: Если вы хотите создать структуру данных, которая будет
производить элементы (например, возвращать элементы из коллекции), используйте
`? extends T`. Это означает, что вы можете использовать любой подтип T.

Consumer Super: Если вы хотите создать структуру данных, которая будет
потреблять элементы (например, добавлять элементы в коллекцию), используйте
`? super T`. Это означает, что вы можете использовать любой суперкласс T.

Идея принципа в следующем:

### **Producer — Extends**

Если коллекция **производит** объекты (т.е. ты **читаешь** из неё), тогда нужно
использовать `? extends T`.

```java
List<? extends Number> numbers = List.of(1, 2, 3);
Number n = numbers.get(0); // OK
// numbers.add(4);  — нельзя добавлять, неизвестно, какой именно тип
```

Пример: ты читаешь числа из списка, но не добавляешь — подойдёт
`? extends Number`.

### **Consumer — Super**

Если коллекция **потребляет** объекты (т.е. ты **записываешь** в неё), тогда
нужно использовать `? super T`.

```java
public class Demo {
    public static void main(String[] args) {
        List<? super Integer> numbers2 = new ArrayList<Number>();
        numbers2.add(42); // OK
        Object obj = numbers2.get(0);
    }
}

```

Пример: ты добавляешь `Integer` в список — подойдёт `? super Integer`.

Или проще запомнить:
**"Если достаёшь — используй `extends`, если кладёшь — используй `super`"**


> ## Java StreamApi. Вызов без терминальной операции

Промежуточные операции не выполняются немедленно — они откладываются до тех пор,
пока не будет вызвана терминальная операция.  
Именно терминальная операция запускает выполнение потока. После ее вызова
происходит анализ операций в пайплайне, и определяется эффективная стратегия его
выполнения.

> ## Java StreamApi. .parallel(), fork-join-poll

Для параллельного выполнения потоков в Stream Api collection.stream()
можно заменить на` collection.parallelStream().operation()`  
либо в общем случае для произвольного stream:
`Source.stream().parallel().operation()`.

.parallel()<br>

Для запуска потоков в параллельном режиме можно использовать методы
parallelStream() или parallel(). По умолчанию потоки выполняются
последовательно, но с явным вызовом одного из этих методов поток переключается в
параллельный режим.<br>
Для разделения коллекций на части, которые обрабатываются параллельно, Java
использует Spliterator и его метод trySplit(). Этот метод разделяет данные на
подзадачи, которые затем могут быть распределены между несколькими потоками.
Каждая часть обрабатывается независимо, и результаты объединяются после
завершения работы всех потоков.<br>

parallelStream()

Методы stream().parallel() и parallelStream() в Java представляют два разных
способа создания параллельного потока.

1. stream().parallel(): этот метод используется для преобразования
   последовательного потока в параллельный поток. Его можно вызвать для любого
   объекта последовательного потока, чтобы включить параллельную обработку этого
   потока. Например:

        List<String> list = Arrays.asList("a", "b", "c");
        Stream<String> parallelStream = list.stream().parallel();

2. parallelStream(): этот метод вызывается непосредственно для объекта коллекции
   для создания параллельного потока. Он возвращает параллельный поток,
   позволяющий выполнять параллельную обработку элементов коллекции. Например:

        List<String> list = Arrays.asList("a", "b", "c");
        Stream<String> parallelStream = list.parallelStream();

Оба метода достигают одного и того же результата создания параллельного потока,
но основное различие заключается в способе их вызова. Метод stream().parallel()
вызывается для последовательного объекта потока, тогда как метод
parallelStream() вызывается непосредственно для объекта коллекции.

ForkJoinPool<br>

Когда вы создаете параллельный поток, он использует ForkJoinPool по умолчанию,
предоставленный Java, для параллельного выполнения операций потока. Это
означает, что работа по разделению данных и их распределению по нескольким
потокам выполняется ForkJoinPool. ForkJoinPool управляет пулом рабочих потоков и
планирует выполнение подзадач параллельного потока этими потоками. Он
динамически регулирует количество потоков в зависимости от доступных ядер ЦП и
рабочей нагрузки. Таким образом обеспечивается эффективное использование
системных ресурсов и повышается общая производительность обработки параллельных
потоков. Таким образом, связь между параллельными потоками и ForkJoinPool
заключается в том, что параллельные потоки используют ForkJoinPool для
параллельного выполнения операций потока, используя возможности параллельной
обработки и эффективного распределения рабочей нагрузки.


> ## Java Core. GCRoot

В Java, GC Root (или корень сборщика мусора) — это объект, который является
начальной точкой для процесса сборки мусора (Garbage Collection, GC). Сборщик
мусора использует корни для определения, какие объекты в памяти все еще доступны
и могут быть использованы, а какие объекты больше не нужны и могут быть удалены.
GC Root — это набор объектов, которые всегда доступны и служат отправной точкой
для поиска всех достижимых объектов в памяти. Если объект не может быть
достигнут из любого из корней, он считается "мусором" и может быть удален
сборщиком мусора.

Примеры GC Root<br>
Вот несколько примеров объектов, которые считаются GC Root:<br>

- Статические поля
- Активные потоки
- Объекты в локальных переменных
- Объекты класса `java.lang.Runtime`

Как работает сборка мусора?<br>
Сборщик мусора использует алгоритмы для определения достижимости объектов:

1. Начинает с GC Roots: Сборщик начинает с объектов GC Root и проходит по всем
   ссылкам от этих объектов.
2. Обходит граф объектов: Он рекурсивно проверяет все объекты, на которые
   ссылаются корни.
3. Определяет недостижимые объекты: Все объекты, которые не могут быть
   достигнуты из корней, помечаются как "мусор" и подлежат удалению.

Как пометить объект "живым"<br>

Если объект доступен через одну или несколько ссылок, он считается живым (или "
достижимым") и не может быть удален сборщиком мусора. Вот несколько способов,
как можно пометить объект как живой:

1. Создание ссылок на объект<br>
   Чтобы объект считался живым, необходимо создать хотя бы одну ссылку на него.
   Например:

2. Использование коллекций<br>
   Объекты могут быть помечены как живые, если они хранятся в коллекциях, таких
   как списки, множества или карты:

3. Статические поля<br>
   Если объект хранится в статическом поле класса, он также будет считаться
   живым:

4. Передача объектов в методы<br>
   Когда вы передаете объект в метод, он также считается живым, пока метод
   выполняется:

5. Использование внешних библиотек или фреймворков
   Некоторые фреймворки и библиотеки могут управлять жизненным циклом объектов и
   поддерживать ссылки на них для обеспечения их доступности.

Заключение<br>
Объекты в Java считаются "живыми", если на них существуют ссылки из других
объектов или переменных. Чтобы пометить объект как живой, достаточно создать
хотя бы одну ссылку на него — это может быть локальная переменная, элемент
коллекции или статическое поле класса. Как только все ссылки на объект будут
удалены (например, переменные выйдут из области видимости или будут присвоены
null), объект станет недостижимым и может быть удален сборщиком мусора.

GC Root — это ключевая концепция в управлении памятью Java и сборке мусора. Она
определяет начальные точки для поиска достижимых объектов и помогает сборщику
мусора эффективно освобождать память от ненужных объектов.

> ## Java Collection. HashMap чуть лучше про то как устроен и сложности методов

### **Устройство**

HashMap в Java — это структура данных, которая реализует интерфейс Map и
использует хеш-таблицу для хранения пар "ключ-значение". Она обеспечивает
быстрый доступ к элементам по ключу, что делает её одной из самых популярных
реализаций Map.

**Основные характеристики HashMap**

1. Ключи и значения: HashMap хранит данные в виде пар "ключ-значение". Каждый
   ключ должен быть уникальным, но значения могут повторяться.
2. Неупорядоченность: Элементы в HashMap не имеют определенного порядка. Порядок
   вставки не сохраняется.
3. Допускает null: HashMap позволяет использовать один null в качестве ключа и
   любое количество null в качестве значений.
4. Не синхронизирован: HashMap не является потокобезопасным. Если несколько
   потоков одновременно изменяют его, необходимо использовать внешнюю
   синхронизацию.

**Как работает HashMap**

1. Хеширование<br>
   Когда вы добавляете пару "ключ-значение" в HashMap, ключ проходит через
   хеш-функцию, которая вычисляет хеш-код для этого ключа. Хеш-код — это целое
   число, которое используется для определения индекса (или бакета) в массиве
   (хеш-таблице), где будет храниться значение.

```java
int hash = key.hashCode();
int index = hash % array.length; // Определяем индекс в массиве
```

2. Создание бакета: Если по этому индексу еще нет других элементов, создается
   новый бакет. В Java это обычно реализуется как связный список или дерево.
3. Добавление элементов: Если по этому индексу уже есть элементы (из-за
   коллизий), новая пара "ключ-значение" добавляется в существующий бакет. В
   случае связного списка новый элемент добавляется в конец списка, а если
   используется сбалансированное дерево (например, Red-Black Tree), то элемент
   будет вставлен в соответствующее место дерева.

4. Обработка коллизий<br>
   Когда два ключа имеют одинаковый хеш-код и попадают в один и тот же индекс
   массива, HashMap создает связный список (или дерево) для хранения всех пар "
   ключ-значение", которые имеют одинаковый индекс. HashMap использует метод
   цепочек (chaining) для обработки этих коллизий. В Java 8 и выше, если
   количество элементов в цепочке превышает определенный порог (обычно 8),
   HashMap преобразует связный список в сбалансированное дерево (например,
   Red-Black Tree) для улучшения производительности.

5. Резервирование места<br>
   Когда количество элементов в HashMap превышает определенный порог (обычно 75%
   от текущей емкости), происходит увеличение емкости:
6. Время доступа<br>
   В среднем время доступа к элементам по ключу составляет O(1) благодаря
   использованию хеширования. Однако в худшем случае (например, если все
   элементы попадают в одну цепочку) время доступа может составлять O(n). Чтобы
   избежать этого, важно правильно выбирать размер начального массива и
   коэффициент загрузки.
7. Получение значения по ключу сначала вычисляется его хеш-код. Затем
   определяется индекс массива. Если по этому индексу есть несколько элементов (
   из-за коллизий), HashMap будет перебирать элементы в связанном списке или
   дереве до тех пор, пока не найдет нужный ключ.

**Бакеты**

В контексте HashMap в Java "бакеты" (или "ведра") — это структуры данных,
которые используются для хранения пар "ключ-значение". Бакеты помогают
организовать данные в HashMap и обеспечивают эффективный доступ к ним. Давайте
рассмотрим, как это работает.

**Причины Колизий**

1. Ограниченное количество индексов<br>
2. Хеш-функция<br>
3. Ограниченная длина хеша<br>
4. Сходство ключей<br>

Причины, почему два ключа могут иметь одинаковый хеш-код:<br>

1. **Ограниченное пространство значений**: Хеш-функция преобразует объект в
   целое число (хеш-код), и поскольку количество возможных объектов значительно
   больше, чем количество возможных целых чисел, разные объекты могут быть
   преобразованы в одно и то же значение.
2. **Алгоритм хеширования**: Хеш-функции не идеальны и могут создавать коллизии.
   Например, если два объекта имеют одинаковые значения для всех полей, которые
   участвуют в вычислении хеш-кода, они будут иметь одинаковый хеш-код.
3. **Пользовательские классы**: Если вы создаете собственный класс и
   переопределяете метод `hashCode()`, вы можете случайно создать коллизии, если
   не будете учитывать все важные поля объекта.

### Сложности методов

В среднем, операция добавления, удаления и поиска элемента по ключу в HashMap
имеют
временную сложность O(1).

Проверка наличия значения (containsValue), итерация по элементам - O(n).

Однако, в худшем случае, когда все элементы попадают в
одну корзину, они будут связаны в связный список или дерево, и операция может
занимать время O(n), где n - количество элементов в корзине. Таким образом,
сложность операций в HashMap зависит от количества коллизий и хеш-функции.<br>
В среднем, сложность выборки элемента также составляет O(1), но в худшем случае
может достигать O(n).

> ## Java Collection. Сложность получения последнего элемента в LinkedList (O(1))

### **ARRAYLIST**

**АЛГОРИТМИЧЕСКАЯ СЛОЖНОСТЬ**

1. **Добавление элемента**:

- В конец списка: O(1) в среднем (если массив не переполнен). Если массив
  переполнен, происходит его увеличение, что требует O(n) времени, но это
  происходит редко, поэтому в среднем сложность остается O(1).
- В начало или в произвольную позицию/середину: O(n) (необходимо сдвинуть
  элементы).
- Чтобы вставить элемент в середину списка, необходимо сначала сдвинуть все
  элементы, находящиеся после позиции вставки, на одну позицию вправо. Это
  требует O(n) времени в худшем случае, так как вам нужно пройти по всем
  элементам после вставляемого. После сдвига сам процесс вставки (изменение
  значения по индексу)
  выполняется за O(1). В итоге общая сложность вставки элемента в середину
  списка составляет O(n).

2. **Удаление элемента**:

- Из конца списка: O(1) (если не требуется уменьшение размера массива).
- Из начала или из произвольной позиции/середины: O(n) (необходимо сдвинуть
  элементы).
- Для удаления элемента из середины списка также необходимо сначала найти этот
  элемент (если у вас нет ссылки на него), что требует O(n) времени. После
  нахождения элемента необходимо сдвинуть все элементы, находящиеся после
  удаляемого, на одну позицию влево. Это также требует O(n) времени. Таким
  образом, общая сложность удаления элемента из середины списка составляет O(n).


3. **Поиск элемента**:

- O(n) (в худшем случае необходимо пройти по всему списку).

4. **Доступ к элементу по индексу**:

- O(1) (доступ к элементу по индексу осуществляется за константное время,
  так как `ArrayList` основан на массиве).

Таким образом, `ArrayList` хорошо подходит для операций доступа по индексу и
добавления элементов в конец списка, но менее эффективен для вставки и удаления
элементов в начале или середине списка из-за необходимости сдвига элементов.

Для `ArrayList` в Java сложность вставки и удаления элементов из середины
списка составляет O(n). В общем, операции вставки и удаления в середине
`ArrayList` имеют линейную сложность из-за необходимости сдвига элементов.

### **LINKEDLIST**

LinkedList\<E> является реализацией двусвязного списка для интерфейса List
который работает эффективно как для вставки элементов, так и для удаления,
используя, как издержки, более сложную структуру.

### Принцип работы LinkedList

#### Основные операции

1. **Добавление элемента (add)**:
    - При добавлении элемента в конец списка создается новый узел, который
      ссылается на `null` (если это последний элемент).
    - Если список не пустой, новый узел связывается с текущим последним узлом, а
      последний узел обновляется для ссылки на новый узел.
    - Если элемент добавляется в начало или в середину списка, ссылки
      соответствующих узлов обновляются для поддержания связности.

Сложность:

- В LinkedList добавление нового узла в начало или конец списка осуществляется
  за константное время O(1), так как нужно просто изменить ссылки на первый или
  последний элемент.
- Чтобы добавить элемент по индексу, необходимо сначала найти нужный индекс, что
  требует линейного времени O(n). После нахождения нужного узла добавление
  нового узла происходит за O(1).

2. **Удаление элемента (remove)**:
    - При удалении элемента необходимо найти соответствующий узел.
    - После нахождения узла его предыдущий и следующий узлы обновляют свои
      ссылки так, чтобы пропустить удаляемый узел.
    - Если удаляется первый или последний элемент, необходимо обновить указатели
      на голову или хвост списка.

Сложность

- Удаление первого или последнего элемента также выполняется за O(1), так как
  нужно просто изменить ссылки на первый или последний элемент.
  Для удаления элемента по индексу необходимо сначала найти нужный индекс, что
  требует O(n). Удаление узла после его нахождения выполняется за O(1).
- Удаление элемента по значению также требует линейного времени O(n), так как
  нужно пройти через весь список для поиска элемента.

3. **Поиск элемента (get)**:
    - Для поиска элемента по индексу необходимо пройти по списку от начала до
      нужного индекса (или от конца, если индекс ближе к концу).

Сложность

- Сложность поиска составляет O(n) в худшем случае.
- Сложность поиска элемента по значению в LinkedList в Java составляет O(n)
  в худшем и среднем случаях.
- Итерация: В отличие от массивов или ArrayList, где доступ к элементам
  осуществляется за O(1) благодаря прямому индексированию, в LinkedList нет
  такого механизма. Чтобы получить элемент по индексу, необходимо пройти от
  начала списка до нужного индекса.

4. **Итерация**:
    - Итерация по элементам `LinkedList` может быть выполнена с помощью
      итератора или цикла for-each.
    - Итератор позволяет проходить по элементам без необходимости знать
      внутреннюю структуру списка.
    - В LinkedList нет прямого доступа к элементам по индексу, как в массивах
      или ArrayList. Поэтому для поиска элемента по значению необходимо
      последовательно проверять каждый узел.

> ## Отличия ArrayList и LinkedList:

`ArrayList` и `LinkedList` — это две реализации интерфейса `List` в Java, и у
них есть несколько ключевых отличий:

1. **Структура данных**:
    - `ArrayList` основан на массиве. Он использует динамический массив для
      хранения элементов, что позволяет быстро получать доступ к элементам по
      индексу.
    - `LinkedList` основан на связном списке. Каждый элемент (узел) содержит
      ссылку на следующий (и предыдущий) элемент, что позволяет легко добавлять
      и удалять элементы.

2. **Производительность**:
    - **Доступ по индексу**: В `ArrayList` доступ к элементам по индексу
      осуществляется за O(1), так как это просто обращение к массиву. В
      `LinkedList` доступ по индексу требует O(n), так как нужно пройти по
      узлам.
    - **Добавление/удаление элементов**: В `ArrayList` добавление элемента в
      конец списка обычно выполняется за O(1), но может потребовать O(n) в
      случае необходимости увеличения размера массива. Удаление элемента также
      может потребовать O(n) из-за необходимости сдвига элементов. В
      `LinkedList` добавление и удаление элементов (в начале, в конце или в
      середине) выполняется за O(1), если у вас есть ссылка на узел, но поиск
      узла требует O(n).

3. **Память**:
    - `ArrayList` использует меньше памяти на элемент, так как хранит только
      данные и индекс. Однако он может выделять больше памяти, чем фактически
      используется (из-за динамического массива).
    - `LinkedList` использует больше памяти на элемент, так как каждый узел
      хранит ссылки на следующий и предыдущий элементы.

4. **Итерация**:
    - Итерация по элементам в `ArrayList` обычно быстрее из-за лучшей
      локальности данных (элементы хранятся последовательно в памяти).
    - Итерация по `LinkedList` может быть медленнее из-за необходимости перехода
      от одного узла к другому.

5. **Использование**:
    - Используйте `ArrayList`, когда вам нужно часто получать доступ к элементам
      по индексу или когда размер списка не меняется часто.
    - Используйте `LinkedList`, когда вам нужно часто добавлять или удалять
      элементы из середины списка.

В общем, выбор между `ArrayList` и `LinkedList` зависит от конкретных требований
вашего приложения и того, какие операции вы будете выполнять чаще всего.
___

> ## Java multithreading. ExecutorService

`ExecutorService` в Java — это интерфейс из пакета `java.util.concurrent`,
который представляет собой фреймворк для управления многопоточностью. Он
позволяет выполнять задачи асинхронно, управлять пулом потоков, и упрощает
работу с многопоточностью по сравнению с использованием `Thread` напрямую.

### Основные особенности `ExecutorService`:

1. **Управление потоками**: `ExecutorService` позволяет вам управлять пулом
   потоков, что означает, что вы можете повторно использовать потоки для
   выполнения нескольких задач, вместо создания нового потока для каждой задачи.
   Это значительно снижает накладные расходы на создание и уничтожение потоков.

2. **Асинхронное выполнение**: Вы можете отправлять задачи на выполнение и
   продолжать выполнять другие операции, не дожидаясь завершения этих задач.

3. **Планирование задач**: `ExecutorService` поддерживает планирование задач с
   использованием методов, таких как `schedule()` (в классе
   `ScheduledExecutorService`), что позволяет выполнять задачи через
   определенные интервалы времени или с задержкой.
4. **Разные типы задач**: Вы можете отправлять как `Runnable`, так и `Callable`
   задачи. `Callable` позволяет возвращать результат и обрабатывать исключения.

5. **Управление жизненным циклом**: `ExecutorService` предоставляет методы для
   управления жизненным циклом пула потоков, такие как `shutdown()` и
   `shutdownNow()`, которые позволяют корректно завершить выполнение задач.

4. **Фабрики для создания экземпляров**: Для создания экземпляров
   `ExecutorService` обычно используются статические методы класса `Executors`,
   такие как:
    - `Executors.newFixedThreadPool(int nThreads)`: создает пул фиксированного
      размера.
    - `Executors.newCachedThreadPool()`: создает пул, который создает новые
      потоки по мере необходимости, но повторно использует ранее созданные
      потоки.
    - `Executors.newSingleThreadExecutor()`: создает пул с одним потоком.

### Ключевые методы:

- `submit()` - Отправляет `Runnable` или `Callable` на выполнение. Возвращает
  `Future`.
- `shutdown()` - Останавливает приём новых задач, завершает текущие.
- `shutdownNow()` - Пытается остановить все задачи и возвращает список
  непринятых.
- `invokeAll()` - Принимает список `Callable` и возвращает список `Future`
- `invokeAny()` - Выполняет несколько задач, возвращает результат самой
  быстрой.

### Разновидности пула:

`Executors` предоставляет фабрики для создания различных реализаций
`ExecutorService`:

- `Executors.newFixedThreadPool(int n)` - фиксированное количество потоков
- `Executors.newCachedThreadPool()` - новый поток при необходимости, повторное
  использование
- `Executors.newSingleThreadExecutor()` - один поток, задачи выполняются по
  очереди

> Java multithreading. Atomic пакет Механизм под капотом (CAS)

В Java термин "atomic" (атомарный) относится к операциям, которые выполняются
как единое целое, без возможности прерывания. Это означает, что такие операции
являются неделимыми: они либо полностью выполняются, либо не выполняются вовсе.
Атомарные операции важны в контексте многопоточности, поскольку они помогают
избежать проблем с синхронизацией и состоянием гонки.

### Основные аспекты атомарности в Java

1. **Атомарные операции**: Атомарные операции гарантируют, что данные не будут
   изменены другими потоками во время выполнения операции. Например, если один
   поток обновляет значение переменной, другой поток не сможет увидеть
   промежуточное состояние этой переменной.

2. **Классы из пакета `java.util.concurrent.atomic`**: Java предоставляет
   несколько классов для работы с атомарными переменными в пакете
   `java.util.concurrent.atomic`. Эти классы обеспечивают атомарные операции над
   примитивными типами данных и объектами. Вот некоторые из них:
    - `AtomicInteger`: Атомарная целочисленная переменная.
    - `AtomicLong`: Атомарная переменная типа `long`.
    - `AtomicBoolean`: Атомарная булева переменная.
    - `AtomicReference<T>`: Атомарная ссылка на объект типа `T`.
    - `AtomicStampedReference<V>`: Атомарная ссылка на объект с меткой (
      стампом), что позволяет избежать проблем с состоянием гонки при обновлении
      ссылок.

3. **Методы атомарных классов**: Классы из пакета `java.util.concurrent.atomic`
   предоставляют методы для выполнения атомарных операций, такие как:
    - `get()`: Получает текущее значение.
    - `set(value)`: Устанавливает новое значение.
    - `incrementAndGet()`: Увеличивает текущее значение на 1 и возвращает новое
      значение.
    - `compareAndSet(expectedValue, newValue)`: Сравнивает текущее значение с
      ожидаемым значением и устанавливает новое значение, если они равны.

### CAS

В Java "CAS" (Compare-And-Swap) — это атомарная операция, которая используется
для реализации механизмов синхронизации и управления состоянием в многопоточной
среде. CAS позволяет безопасно обновлять значение переменной, проверяя, равно ли
текущее значение ожидаемому значению, и только в этом случае заменяя его на
новое значение. Это делает CAS полезным для реализации неблокирующих алгоритмов
и структур данных.


> ## Spring. Scope бинов чуть лучше

В Spring Framework "scope" (область видимости) бинов определяет, как и когда
создаются экземпляры бинов, а также как они управляются контейнером Spring.
Области видимости позволяют контролировать жизненный цикл бинов и их доступность
в приложении. В Spring есть несколько основных областей видимости бинов:

### 1. Singleton (по умолчанию)

В этой области видимости контейнер Spring создает только один
экземпляр бина на весь контекст приложения. Этот экземпляр будет
использоваться для всех запросов к этому бину.

### 2. Prototype

При этой области видимости каждый запрос к контейнеру Spring
создает новый экземпляр бина. Это означает, что каждый раз, когда вы
запрашиваете бин, вы получаете новый объект.

### 3. Request

Эта область видимости используется в веб-приложениях. Бин
создается для каждого HTTP-запроса и уничтожается по завершении обработки
этого запроса.

### 4. Session

Также используется в веб-приложениях. Бин создается для каждой
HTTP-сессии и уничтожается, когда сессия завершается. Это полезно для хранения
информации, специфичной для пользователя, в течение всего времени его сессии.

### 5. Global Session/Application

Application: Бин с данной областью видимости создается один раз
для всего сервлет-контекста. Это полезно для данных, которые должны быть
общими для всех пользователей и сессий в приложении.

### 6. WebSocket

Бин с данной областью видимости создается для каждой сессии WebSocket. Это
полезно для работы с данными, специфичными для каждой WebSocket-сессии.

### Применение области видимости

Чтобы задать область видимости для бина, можно использовать аннотацию `@Scope`
вместе с аннотацией `@Component`, `@Service`, `@Repository` или `@Controller`.
Например:


> ## Жизненный цикл бинов

В контексте Java и, в частности, фреймворка Spring, жизненный цикл бинов (или
компонентов) описывает последовательность этапов, через которые проходит бин от
его создания до уничтожения. Понимание этого жизненного цикла важно для
правильного управления ресурсами и поведения ваших компонентов. Давайте
рассмотрим основные этапы жизненного цикла бинов в Spring.

### 1. Создание бина

- **Инстанцирование**: Когда Spring контейнер создает бин, он использует
  конструктор класса для создания его экземпляра. Это может быть стандартный
  конструктор или конструктор с параметрами, если используется внедрение
  зависимостей.

### 2. Внедрение зависимостей

- **Внедрение зависимостей**: После создания бина Spring инжектирует все
  необходимые зависимости (например, другие бины или конфигурационные параметры)
  в созданный объект. Это может происходить через конструкторы, сеттеры или
  поля (в зависимости от конфигурации).

### 3. Инициализация

- **Методы инициализации**: После внедрения зависимостей Spring вызывает методы
  инициализации, если они определены. Это может быть:
    - Метод с аннотацией `@PostConstruct`, который будет вызван после завершения
      инъекции зависимостей.
    - Метод, указанный в атрибуте `init-method` в XML-конфигурации.

Пример использования `@PostConstruct`:

```java

@Component
public class MyBean {

    @PostConstruct
    public void init() {
        // Логика инициализации
    }
}
```

### 4. Использование

- **Использование бина**: На этом этапе бин готов к использованию в приложении.
  Он может обрабатывать запросы, выполнять бизнес-логику и взаимодействовать с
  другими компонентами.

### 5. Уничтожение

- **Методы уничтожения**: Когда контейнер Spring закрывается или бин больше не
  нужен, он проходит процесс уничтожения. На этом этапе могут быть вызваны
  методы для освобождения ресурсов или выполнения завершающих действий:
    - Метод с аннотацией `@PreDestroy`, который будет вызван перед уничтожением
      бина.
    - Метод, указанный в атрибуте `destroy-method` в XML-конфигурации.

Пример использования `@PreDestroy`:

```java

@Component
public class MyBean {

    @PreDestroy
    public void cleanup() {
        // Логика освобождения ресурсов
    }
}
```

### Полный жизненный цикл бина

1. **Создание**: Инстанцирование бина.
2. **Внедрение зависимостей**: Инъекция необходимых зависимостей.
3. **Инициализация**: Вызов методов инициализации.
4. **Использование**: Бин готов к использованию.
5. **Уничтожение**: Вызов методов для освобождения ресурсов перед уничтожением.

### Заключение

Понимание жизненного цикла бинов в Spring позволяет разработчикам эффективно
управлять ресурсами и поведением своих компонентов. Знание о том, когда
происходят различные этапы жизненного цикла, помогает избежать утечек памяти и
других проблем с производительностью приложения.



> ## Hibernate. Проблема n+1

**Проблема N+1 запросов** возникает, когда при работе с ORM (например,
Hibernate) в приложении для получения данных из базы вместо одного оптимального
запроса выполняется **множество отдельных запросов**. Это приводит к
существенным затратам времени и ресурсов.

**_Как возникает проблема?_**

Допустим, у нас есть две связанные сущности: **`User`** и **`Order`**, где
`User` имеет список `orders`. Например:

```java

@Entity
public class User {
    @Id
    private Long id;

    private String name;

    @OneToMany(mappedBy = "user", fetch = FetchType.LAZY)
    private List<Order> orders;
}

@Entity
public class Order {
    @Id
    private Long id;

    private String description;

    @ManyToOne
    private User user;
}
```

Теперь мы хотим получить список пользователей с их заказами:

```java
class Demo {
    void demo() {

        List<User> users = entityManager
                .createQuery("SELECT u FROM User u", User.class)
                .getResultList();

        for (User user : users) {
            System.out.println("User: " + user.getName());
            System.out.println("Orders: " + user.getOrders());
        }
    }
}

```

_**Что происходит под капотом?**_

1. Первый запрос:
   ```sql
   SELECT * FROM user;
   ```
   Загружаются все пользователи.

2. Для каждого пользователя (N пользователей) выполняется отдельный запрос для
   получения его заказов:
   ```sql
   SELECT * FROM order WHERE user_id = ?;
   ```

Итого:

- **1 запрос для загрузки пользователей.**
- **N запросов для загрузки заказов.**
- Получается `N+1` запросов.

### Решение проблемы N+1

#### 1. **Использование `JOIN FETCH` (жадная загрузка)**

Перепишем запрос, чтобы сразу загрузить заказы:

```java
List<User> users = entityManager
        .createQuery("SELECT u FROM User u JOIN FETCH u.orders", User.class)
        .getResultList();
```

Теперь Hibernate выполнит **один запрос** с `JOIN`:

```sql
SELECT u.*, o.*
FROM user u
         JOIN order o ON u.id = o.user_id;
```

**Важно:** Это решает проблему, но может вернуть дублирующиеся строки, если у
одного пользователя несколько заказов. Hibernate автоматически устраняет
дубликаты, но это тоже имеет накладные расходы.

#### 2. **Использование графов сущностей (Entity Graphs)**

С помощью **графов сущностей** можно явно указать, какие данные подгружать:

```java

@EntityGraph(attributePaths = "orders")
List<User> users = entityManager
        .createQuery("SELECT u FROM User u", User.class)
        .setHint("javax.persistence.fetchgraph", entityGraph)
        .getResultList();
```

Это также позволяет избежать проблемы N+1, загружая связанные сущности в одном
запросе.

### 3. **Использование `@BatchSize`**

Hibernate может группировать загрузку данных с помощью аннотации `@BatchSize`:

```java

@Entity
@BatchSize(size = 10)
public class User {
    @Id
    private Long id;

    @OneToMany(mappedBy = "user", fetch = FetchType.LAZY)
    private List<Order> orders;
}
```

Теперь вместо одного запроса на каждый объект, Hibernate будет подгружать данные
пачками:

```sql
SELECT *
FROM order
WHERE user_id IN (?, ?, ?, ?, ?, ?, ?, ?, ?, ?);
```

### 4. **Кэширование (`Second-Level Cache`)**

В некоторых случаях проблему можно частично решить с помощью **вторичного кэша
Hibernate**. Он позволяет повторно использовать данные, которые уже были
загружены, чтобы избежать лишних запросов.

## ENTITY MANAGER

_**Что такое `EntityManager`?**_

`EntityManager` — это **основной интерфейс JPA**, через который осуществляется
**вся работа с базой данных**:создание, чтение, обновление, удаление объектов (
CRUD), а также управление жизненным циклом сущностей.

Это как "менеджер" между Java-приложением и базой данных. Он отвечает за:

- сохранение объекта в базу
- получение объекта из базы
- обновление и удаление
- управление транзакциями
- кеширование сущностей
- создание запросов (JPQL, SQL, Criteria API)

_**Пример использования `EntityManager`**_

```java

@PersistenceContext
private EntityManager entityManager;

public User getUserById(Long id) {
    return entityManager.find(User.class, id);
}

public void saveUser(User user) {
    entityManager.persist(user);
}
```

_**Основные методы `EntityManager`**_

| Метод                    | Что делает                                   |
|--------------------------|----------------------------------------------|
| `persist(Object entity)` | Сохраняет объект в базу данных               |
| `find(Class<T>, id)`     | Находит сущность по id                       |
| `merge(Object entity)`   | Обновляет объект в базе                      |
| `remove(Object entity)`  | Удаляет объект                               |
| `createQuery()`          | Создаёт JPQL-запрос                          |
| `createNativeQuery()`    | SQL-запрос                                   |
| `flush()`                | Принудительно синхронизирует изменения с БД  |
| `clear()`                | Очищает контекст (все отслеживаемые объекты) |

### Жизненный цикл сущностей

`EntityManager` управляет состоянием объектов:

| Состояние                 | Описание                                                                   |
|---------------------------|----------------------------------------------------------------------------|
| `Transient`(Новая)        | Объект создан, но не привязан к БД                                         |
| `Managed`(Управляемая)    | Контролируется `EntityManager`, любые изменения автоматически попадут в БД |
| `Detached`(Отсоединенная) | Больше не контролируется, но может быть сохранён снова через `merge()`     |
| `Removed`(Удаленная)      | Помечен на удаление                                                        |

### Откуда берётся `EntityManager`?

В Spring или Jakarta EE его можно внедрить через:

```java

@PersistenceContext
private EntityManager em;
```

А в обычных Java SE-приложениях — создать вручную:

```java
EntityManagerFactory emf = Persistence.createEntityManagerFactory("myUnit");
EntityManager em = emf.createEntityManager();
```

_**Резюме**_

`EntityManager` = главный API для работы с базой в JPA.  
Он:

- управляет сущностями
- делает запросы к базе
- отвечает за транзакции
- предоставляет гибкий доступ к данным

## ENTITY GRAPH

**`Entity Graph`** в Hibernate (и JPA в целом) — это инструмент,
который помогает **гибко управлять стратегиями загрузки данных**: что подгружать
сразу (жадно), а что позже (лениво), **без изменения аннотаций в сущностях**.
Entity Graphs (графы сущностей) — это механизм в JPA (Java Persistence API),
который позволяет разработчикам управлять загрузкой связанных сущностей более
гибко и эффективно. С помощью графов сущностей можно указать, какие связанные
объекты должны быть загружены вместе с основной сущностью, что помогает избежать
проблемы N+1 и оптимизировать производительность запросов.



> ## Hibernate. Уровни кеширования в Hibernate лучше изучить

### Основные уровни кэширования в Hibernate:

1. **Первичный кэш (Session Cache)** — кэш на уровне сессии.
2. **Вторичный кэш (Second-level Cache)** — кэш на уровне сессии-фабрики.
3. **Кэш запросов (Query Cache)** — кэширование результатов запросов.

### 1. Первичный кеш (First-Level Cache)

- Это **встроенный кеш**, работающий **в пределах одной сессии (`Session`) или
  транзакции**.
- **Всегда включён** — ничего дополнительно настраивать не нужно.
- Кэширует сущности, загруженные в текущей `Session`.
- Первичный кеш является неотъемлемой частью сессии Hibernate. Он
  хранит объекты, загруженные в текущей сессии, и обеспечивает их повторное
  использование без необходимости повторного запроса к базе данных.

**Пример:**

```java
Session session = sessionFactory.openSession();
User user1 = session.get(User.class, 1L); // SELECT из БД
User user2 = session.get(User.class, 1L); // из кэша, без запроса
```

Второй вызов не пойдёт в базу, потому что объект уже есть в памяти.

#### Очистка кэша:

- `session.clear()` — очищает весь кэш
- `session.evict(user)` — удаляет конкретную сущность из кэша
- `session.close()` — кэш уничтожается

### 2. Вторичный кеш (Second-Level Cache)

Это глобальный кеш, работающий между сессиями и транзакциями. Выключен
по умолчанию, его нужно явно включить и настроить. Используется для повторно
используемых данных (справочники, настройки, часто читаемые сущности).
Действует на уровне сессии-фабрики (SessionFactory). Данные остаются в этом кэше
даже после закрытия сессий. Вторичный кэш может быть использован для хранения
часто запрашиваемых сущностей или коллекций, что позволяет уменьшить количество
запросов к базе данных. Вторичный кеш доступен для всех сессий, использующих
одну и ту же фабрику сессий. Для использования второго уровня кеша необходимо
включить его в конфигурации Hibernate и выбрать провайдер кеша (например,
Ehcache, Infinispan и т.д.).

**Настраивается через конфигурацию и провайдер кеша:**

Hibernate сам по себе не кеширует на 2 уровне — он **использует сторонние
библиотеки**, например:

- **Ehcache**
- **Infinispan**
- **Caffeine**
- **Redis (через адаптеры)**

Как включить 2-й уровень кеша

```properties
hibernate.cache.use_second_level_cache=true
hibernate.cache.region.factory_class=org.hibernate.cache.jcache.JCacheRegionFactory
hibernate.javax.cache.provider=org.ehcache.jsr107.EhcacheCachingProvider
```

И в сущности:

```java

@Entity
@Cacheable
@org.hibernate.annotations.Cache(usage = CacheConcurrencyStrategy.READ_WRITE)
public class User {
    ...
}
```

#### Стратегии кэширования

Hibernate поддерживает несколько стратегий кэширования для второго уровня:

1. **READ_ONLY**: Используется для объектов, которые не изменяются после их
   создания. Это наиболее эффективная стратегия.
2. **READ_WRITE**: Используется для объектов, которые могут изменяться.
   Hibernate управляет блокировками при записи.
3. **NONSTRICT_READ_WRITE**: Позволяет более высокую производительность за счет
   менее строгого контроля за изменениями.
4. **TRANSACTIONAL**: Поддерживает транзакционное поведение.

### 3. **Кэш запросов (Query Cache)**

- **Описание:** Это дополнительный уровень кеширования, который позволяет
  кешировать результаты запросов.
- **Область видимости:** Работает совместно со вторичным кэшем и может
  использоваться для кеширования результатов HQL или Criteria запросов.
- **Применение:** Если вы выполняете один и тот же запрос несколько раз,
  результаты могут быть извлечены из кеша вместо выполнения запроса к базе
  данных.

### Включение кэша запросов в Hibernate

1. Включить **вторичный кэш**.
2. Включить **кэш запросов**.

#### Кэширование запросов с параметрами

Кэширование работает **по запросу и его параметрам**. Это значит, что если ты
выполняешь запрос с разными параметрами, то результат будет кэшироваться
отдельно для каждого набора параметров. Но если запрос повторится с тем же
параметром "John", результат будет взят из кэша

#### Интеграция с Spring Data JPA

В **Spring Data JPA** кэширование запросов также поддерживается. Для этого можно
использовать аннотацию `@Query` с параметром `cacheable = true`.

#### Важные замечания:

- Кэширование запросов не **обновляет** кэш автоматически. То есть, если данные
  изменяются в базе данных, кэшированные результаты не будут обновлены.
- Нужно помнить, что если запрос включает много данных или параметров,
  кэширование может **занимать много памяти**. Старайся кэшировать только *
  *часто используемые запросы с ограниченным количеством результатов**.
- **Параметризация** запросов критична — кэширование работает по параметрам, и
  если параметры изменяются, запрос будет выполнен заново.

> ## Сессии в Hibernate

Сессия в Hibernate — это основной интерфейс для взаимодействия с базой данных.
Она представляет собой единицу работы с данными и обеспечивает механизм для
выполнения операций с сущностями, таких как создание, чтение, обновление и
удаление (CRUD). Сессия управляет состоянием объектов и их жизненным циклом, а
также обеспечивает кэширование на уровне первого уровня.

Сессия отслеживает изменения в сущностях, которые она загружает. Когда вы
загружаете сущность из базы данных, она становится "управляемой" (managed)и
находится в состоянии "приложения" (persistent). Если вы изменяете управляемую
сущность, Hibernate автоматически отслеживает эти изменения и может
синхронизировать их с базой данных при вызове метода `session.flush()` или при
закрытии сессии.

Сессия имеет свой собственный первичный кэш (first-level cache), который
хранит загруженные объекты. Если вы запрашиваете одну и ту же сущность
несколько раз в рамках одной сессии, Hibernate будет возвращать объект из
этого кэша вместо выполнения нового запроса к базе данных.

### Фабрика сессий

Фабрика сессий (SessionFactory) в Hibernate — это интерфейс, который отвечает за
создание и управление сессиями (Session). Она является основным компонентом,
который настраивается один раз при запуске приложения и используется для
получения экземпляров сессий. В контексте второго уровня кэширования (Second
Level Cache) фабрика сессий играет важную роль в управлении кэшированием данных
между различными сессиями.

> ## HQL, native, JPQL, Criteria запросы

### HQL

HQL (Hibernate Query Language) — это язык запросов, очень похожий на SQL, но с
одной ключевой разницей - HQL работает с сущностями и их полями, а не с
таблицами и колонками.

### Native Query

В Hibernate **native запросы** — это **SQL-запросы**, написанные напрямую, **без
использования HQL** или `Criteria API`.
Это **"сырой" SQL-запрос**, который выполняется прямо в базу данных, **в обход
Hibernate Query Language** (HQL).

### JPQL

**JPQL (Java Persistence Query Language)** — это **стандартизированный язык
запросов**, который входит в JPA (Java Persistence API). Он **похож на SQL**, но
работает **с Java-сущностями и их полями**, а **не с таблицами и колонками**
базы данных.

### Criteria запросы

**Criteria-запросы** в JPA (или Hibernate) — это способ
**построения запросов через Java-код**, а не через строки. Это особенно полезно,
когда запрос должен быть **динамическим**, например, фильтры меняются во время
выполнения.


> ## SQL. Оптимистические/Пессимистические блокировки

**Оптимистические** и **пессимистические блокировки** —
два подхода к управлению **конкурентным доступом** к данным в
многопользовательских системах или распределённых приложениях.  
**Блокировка** — это механизм, который предотвращает **конкурентный доступ** к
данным, чтобы избежать **несогласованных изменений** или **повреждения данных**.

- **Пессимистическая блокировка**: когда мы блокируем данные на время их
  использования, чтобы гарантировать эксклюзивный доступ.
- **Оптимистическая блокировка**: когда предполагается, что **конфликтов не
  будет**, и проверка их происходит только в момент **сохранения** данных.

### Пессимистическая блокировка (Pessimistic Locking)

**Пессимистическая блокировка** — это подход, при котором предполагается, что
**конфликт между транзакциями** может возникнуть. Поэтому, прежде чем начать
работать с данными, транзакция **блокирует** их на уровне базы данных или на
уровне приложения. Другие транзакции **не могут получить доступ к этим данным**,
пока первая не завершит свои операции.

#### Как это работает?

1. **Захват блокировки**: когда транзакция получает доступ к записи, она
   "блокирует" её, чтобы другие транзакции не могли её изменить.
2. **Ожидание**: если другая транзакция пытается изменить эти данные, она будет
   **ждать**, пока первая не завершит работу.
3. **Завершение работы**: блокировка снимается, когда транзакция завершена, и
   другие транзакции могут получить доступ к данным.

### Оптимистическая блокировка (Optimistic Locking)

**Оптимистическая блокировка** предполагает, что **конфликтов не будет**, и
предоставляет всем транзакциям возможность работать с данными без блокировки.
Вместо того чтобы блокировать ресурсы, транзакция будет **проверять, были ли
данные изменены**, прежде чем записать их обратно в базу данных.

#### Как это работает?

1. **Чтение данных**: транзакция считывает данные и работает с ними.
2. **Запись данных**: перед сохранением изменений в базу данных транзакция
   проверяет, не были ли данные изменены другой транзакцией (например, через
   версионный номер).
3. **Конфликт**: если данные были изменены другим пользователем (или
   транзакцией), то транзакция **не будет выполнена** (будет выброшено
   исключение, например, `OptimisticLockException`), и нужно решить, как
   поступить — повторить операцию или отменить.

#### Итог:

- **Пессимистическая блокировка** — это более **агрессивный подход** с гарантией
  того, что данные не изменяются другими транзакциями, но может привести к
  проблемам с производительностью.
- **Оптимистическая блокировка** — **более лёгкий** подход, который
  предполагает, что конфликтов не будет, и проверяет это только при сохранении
  данных.

> ## Spring. Self injection и как работать с аннотациями в спринге. Например, Transaction, Уровни транзакции, ACID, проблемы

## Self injection

**Self Injection** в **Spring Framework** — это концепция, при которой **объект
сам себе инжектит зависимости** через механизмы Spring DI (Dependency
Injection). Обычно это может происходить с помощью **аннотаций**, таких как
`@Autowired`, когда объект **автоматически подставляется** в сам себя как
зависимость.

**Self Injection** возникает, когда компонент (bean) инжектит **сам себя** через
механизмы Spring DI (Dependency Injection) в своём собственном контексте. Это
может быть полезно в некоторых ситуациях, например, когда нужно обеспечить
доступ к текущему экземпляру класса в самом классе, например, для внедрения
через какие-то специфические методы или для манипуляции внутри компонента.

### В чем смысл Self Injection?

**Self Injection** может быть полезен в специфичных случаях, например:

- **Для кэширования**: когда компонент сам себе инжектирует зависимости для
  работы с кэшом.
- **Для рекурсии**: когда объект должен быть способен работать сам с собой в
  рекурсивных структурах.
- **Циклические зависимости**: хотя Spring не рекомендует циклические
  зависимости, бывают случаи, когда такой подход используется для их разрешения.

Однако стоит помнить, что использование **Self Injection** — это довольно редкая
практика, которая чаще всего может сигнализировать о том, что архитектура
нуждается в **рефакторинге**. В большинстве случаев, **инжекция зависимостей**
должна быть направлена на **внедрение внешних зависимостей**, а не инъекцию
самого себя.

### Зачем это нужно?

Например, если у вас есть метод с аннотацией `@Transactional`, и вы вызываете
этот метод из другого метода того же класса напрямую
(`this.someTransactionalMethod()`), то Spring **не применит прокси и не создаст
транзакцию**, потому что вызов идёт внутри одного объекта.

Если же вызвать метод через прокси (через self injection), то аспекты сработают
корректно.

### Когда стоит использовать Self Injection?

- **Инициализация через бин**: если требуется инжектить зависимости **только
  через Spring** (например, для корректной работы в контексте Spring).
- **Тестирование**: в некоторых случаях Self Injection используется в **тестовых
  приложениях**, когда важно, чтобы зависимости инжектировались, а сам объект
  должен быть доступен для проверки в других местах.

#### Пример self injection

```java

@Component
public class MyService {

    @Autowired
    private MyService self;  // self injection

    public void methodA() {
        // вызов метода с транзакцией через прокси
        self.methodB();
    }

    @Transactional
    public void methodB() {
        // код, который должен выполняться в транзакции
    }
}
```

Здесь вызов `self.methodB()` пройдет через прокси Spring, и транзакция будет
создана. Если бы вызвали `this.methodB()`, то аннотация `@Transactional` не
сработала бы.

#### Как работает?

Spring создает прокси-объект для бина и внедряет его в поле `self`. Таким
образом, при вызове методов через `self` вызывается проксированный объект с
применением аспектов.

#### Кратко

**Self Injection** — это когда бин внедряет сам себя из контекста Spring для
того, чтобы внутренние вызовы методов проходили через прокси и корректно
работали такие механизмы как транзакции и AOP.

## Как работать с аннотациями на примере @Transaction

Аннотация **`@Transactional`** в **Spring Framework** используется для
управления транзакциями в приложении, что позволяет обеспечить консистентность
данных при работе с базой данных. С помощью этой аннотации можно обозначить, что
определённый метод или класс должен работать в рамках одной транзакции, и Spring
автоматически будет управлять процессом начала, коммита и отката транзакции.

### Основные моменты, которые стоит учитывать при работе с `@Transactional`:

1. **`@Transactional` на уровне класса и метода:**
    - **На уровне метода:** Когда аннотация применяется на методе, транзакция
      будет начинаться и завершаться (коммититься или откатываться) для этого
      конкретного метода.
    - **На уровне класса:** Если `@Transactional` применяется на уровне класса,
      то транзакция будет работать для всех методов этого класса (если только
      для метода не задано своё поведение).

2. **Типы транзакций:**
    - **Программные транзакции** — Spring создает транзакции на основе операций
      с базой данных с помощью менеджера транзакций.
    - **Менеджер транзакций:** Spring использует `PlatformTransactionManager`
      для управления транзакциями, например, `DataSourceTransactionManager` для
      работы с базой данных через JDBC.

3. **Поведение транзакций:**
    - **Коммит и откат:** Если метод выполняется без ошибок, то транзакция будет
      зафиксирована (commit). Если произойдёт исключение, то транзакция будет
      откатана (rollback).
    - **Типы исключений:** По умолчанию транзакция откатывается только в случае
      непроверяемых исключений (наследников `RuntimeException`). Для
      проверяемых исключений (наследников `Exception`) транзакция не будет
      откатана, если это явно не указано в аннотации.

## @Transactional

Аннотация `@Transactional` в **Spring Framework** используется для обозначения
методов или классов, которые должны работать в рамках **транзакции**. Она
упрощает управление транзакциями, автоматически обрабатывая создание, коммиты и
откаты транзакций, что значительно упрощает работу с базой данных и другими
ресурсами.

### Основные моменты:

- **Транзакции** — это механизмы, которые обеспечивают **атомарность** операций,
  чтобы данные оставались согласованными, даже если система сталкивается с
  ошибками.
- **`@Transactional`** позволяет Spring автоматически управлять транзакциями,
  начиная их в момент вызова метода и заканчивая при его завершении (с коммитом
  или откатом, в зависимости от результата).

### Важные аспекты `@Transactional`

1. **Управление транзакциями**:

    - **Начало транзакции** происходит сразу перед выполнением метода.
    - **Коммит**: если метод завершился успешно, транзакция будет зафиксирована.
    - **Откат**: если в методе произошло исключение, Spring автоматически
      откатит транзакцию, восстанавливая состояние данных до начала метода.

2. **По умолчанию откат на RuntimeException**:

   Spring откатывает транзакцию по умолчанию только для unchecked exceptions
   (например, `RuntimeException`), но не для checked exceptions (например,
   `IOException` или `SQLException`).

3. **Сквозной аспект (Aspect-Oriented Programming, AOP)**:

   `@Transactional` работает на основе **аспектно-ориентированного
   программирования (AOP)**, что означает, что Spring создаёт прокси для класса,
   а сама транзакция управляется этим прокси. Это позволяет Spring автоматически
   перехватывать вызовы методов и оборачивать их в транзакции.

### Настройки аннотации `@Transactional`

Аннотация `@Transactional` имеет несколько полезных атрибутов, которые позволяют
настроить поведение транзакции.

1. **`propagation`** — уровень распространения транзакции

(или propagation level) в Spring Framework
определяет, как транзакция будет вести себя в случае, если она уже существует
или не существует в текущем потоке. Этот параметр используется в аннотации
@Transactional и играет ключевую роль в управлении транзакциями, особенно при
работе с вложенными вызовами методов и несколькими сервисами.

- **`REQUIRED`** (по умолчанию): Если существует активная транзакция, то текущий
  метод будет выполнен в рамках этой транзакции. Если транзакции нет — она будет
  создана.
- **`REQUIRES_NEW`**: Всегда создаёт новую транзакцию. Если транзакция уже
  существует, она будет приостановлена.
- **`NESTED`**: Создаёт новую транзакцию, но внутри существующей. Это как
  вложенная транзакция, которая может быть откатана отдельно, не влияя на
  внешнюю.
- **`SUPPORTS`**: Если существует активная транзакция, метод будет выполнен в её
  рамках, если нет — транзакция не будет создана.
- **`NOT_SUPPORTED`**: Метод не будет выполнять транзакцию, если она есть.
- **`MANDATORY`**: Требует, чтобы существовала активная транзакция. Если
  транзакции нет, будет выброшено исключение.
- **`NEVER`**: Метод не может быть выполнен в транзакции. Если она существует,
  будет выброшено исключение.

2. **`isolation`** — уровень изоляции транзакции

определяет, как транзакция будет взаимодействовать с
другими параллельными транзакциями:

- **`DEFAULT`**: Используется уровень изоляции по умолчанию, настроенный в базе
  данных.
- **`READ_COMMITTED`**: Гарантирует, что данные, которые транзакция читает, были
  зафиксированы.
- **`READ_UNCOMMITTED`**: Разрешает чтение "грязных" данных (неподтвержденных
  другими транзакциями).
- **`REPEATABLE_READ`**: Гарантирует, что данные, которые были прочитаны, не
  изменятся в течение транзакции.
- **`SERIALIZABLE`**: Самый высокий уровень изоляции, при котором транзакции
  выполняются последовательно, исключая всякую параллельность.

3. **`timeout`** — время ожидания транзакции

позволяет задать максимальное время, в течение которого транзакция
должна быть завершена. Если транзакция не завершится за это время, она будет
откатана.

4. **`readOnly`** — режим только для чтения

Если транзакция не должна изменять данные (только читать), то можно пометить её
как **`readOnly`** для оптимизации. В некоторых случаях это позволяет базе
данных или другим компонентам системы оптимизировать выполнение транзакции.

5. **`rollbackFor` и `noRollbackFor`** — управление откатом

Эти атрибуты позволяют задать исключения, при которых транзакция будет откатана.

- **`rollbackFor`**: Указывает исключения, при которых транзакция должна быть
  откатана.
- **`noRollbackFor`**: Указывает исключения, при которых транзакция **не будет
  откатана**.

### Пример работы с несколькими транзакциями:

#### Можно ли вызывать метод с @Transactional из другого метода с @Transactional?

Да, можно вызывать метод с аннотацией `@Transactional` внутри другого метода,
также помеченного аннотацией `@Transactional`. Однако нужно учитывать несколько
важных моментов, чтобы это работало корректно.

##### 1. **Влияние уровня распространения транзакции (`Propagation`)**

- Если оба метода помечены аннотацией `@Transactional` и используют уровень
  распространения по умолчанию (`Propagation.REQUIRED`), то оба метода будут
  работать в одной и той же транзакции. Это означает, что если один из методов
  завершится с ошибкой, то транзакция будет откачена для обоих методов.
- Если же уровни распространения транзакции в этих методах отличаются, например,
  один использует `Propagation.REQUIRES_NEW` (создание новой транзакции), то для
  каждого метода будет своя отдельная транзакция, и ошибки в одном методе не
  повлияют на другую.

##### 2. **Важный момент: прокси и внутренняя вызовность**

- Важно понимать, что аннотация `@Transactional` работает через **прокси** (
  используется аспектно-ориентированное программирование, или AOP). Это
  означает, что транзакционная логика будет применяться только для **внешних
  вызовов методов**, то есть только когда метод вызывается из другого класса или
  из другого компонента.

Если метод с аннотацией `@Transactional` вызывается внутри того же класса (
например, из другого метода этого же класса), то транзакция **не будет**
корректно управляться. Это связано с тем, что прокси применяется только к
внешним вызовам, а внутри класса Java вызов метода будет обычным вызовом,
который не проходит через механизм транзакционного проксирования.

Чтобы это работало, необходимо, чтобы один метод был вызван **из другого
компонента** (например, с использованием Dependency Injection).

##### 3. **Пример: внутренний вызов**

В следующем примере метод `methodB` вызывает метод `methodA` внутри того же
класса, и это не приведет к созданию новой транзакции, так как транзакции будут
управляться только при внешнем вызове:

   ```java

@Service
public class MyService {

    @Transactional
    public void methodA() {
        // Транзакция начнется здесь
        methodB();  // Внутренний вызов, транзакция не будет проксирована
    }

    @Transactional
    public void methodB() {
        // Транзакция начнется здесь, но на самом деле она не будет работать
        // корректно, так как вызов был внутри того же класса.
    }
}
   ```

В данном случае `methodB` не будет транзакционным, потому что он вызван из того
же класса, и Spring не применит прокси-транзакцию.

##### 4. **Решение: использование инъекции зависимостей**

Чтобы транзакционная аннотация работала корректно при вызове метода из другого
метода в том же классе, вы должны инжектировать экземпляр текущего класса в тот
же класс (или использовать другой механизм). Пример:

   ```java

@Service
public class MyService {

    @Autowired
    private MyService self;  // инжекция самого себя

    @Transactional
    public void methodA() {
        // Транзакция начнется здесь
        self.methodB();  // Вызов через инжекцию приводит к правильному проксированию
    }

    @Transactional
    public void methodB() {
        // Транзакция будет правильно управляться
    }
}
   ```

Здесь `self.methodB()` вызовет метод через прокси, и транзакционная логика будет
корректно применена.

##### 5. **Пример с разными уровнями распространения транзакции**

Если вы хотите, чтобы один метод создал новую транзакцию, а другой использовал
уже существующую, вы можете использовать разные уровни распространения
транзакций.

   ```java

@Service
public class MyService {

    @Transactional(propagation = Propagation.REQUIRED)
    public void methodA() {
        // Транзакция начнется здесь
        methodB();  // Внутренний вызов, метод будет использовать ту же транзакцию
    }

    @Transactional(propagation = Propagation.REQUIRES_NEW)
    public void methodB() {
        // В методе будет создана новая транзакция, независимо от текущей
    }
}
   ```

В данном примере, метод `methodA` будет использовать транзакцию, если она
существует, а метод `methodB` будет создавать свою собственную транзакцию (в
случае использования `REQUIRES_NEW`).

##### **Заключение**

1. **Внешний вызов метода**: Если метод с аннотацией `@Transactional` вызывается
   из другого компонента, Spring правильно применяет транзакцию.
2. **Внутренний вызов метода**: Если метод с аннотацией `@Transactional`
   вызывается внутри того же класса, то транзакция не будет работать, так как
   транзакции управляются через прокси, а вызов метода внутри того же класса не
   приводит к проксированию.
3. **Использование разных уровней распространения** позволяет гибко управлять
   поведением транзакций при вызове методов.

Таким образом, если вы хотите использовать транзакции при вызове методов внутри
одного класса, нужно инжектировать сам класс (самого себя) и вызывать методы
через инжекцию, чтобы проксирование сработало.

#### Метод с аннотацией `@Transactional` из метода без этой аннотации?

Да, можно вызывать метод с аннотацией `@Transactional` из метода без этой
аннотации, и это будет работать, как ожидается, **при условии, что вызов
происходит из другого компонента** или другого слоя в приложении (например,
через Spring's Dependency Injection).

##### Как работает `@Transactional`:

Аннотация `@Transactional` работает на основе **прокси**, и транзакционное
поведение применяется только тогда, когда метод вызывается **вне зависимости**
от самого объекта, то есть через проксирование.

Если метод с аннотацией `@Transactional` вызывается из другого метода, который
находится в другом классе или через Spring инъекцию, то Spring создаст прокси
для этого метода и обеспечит правильное управление транзакциями.

##### Важные моменты:

1. **Внешний вызов метода**: Когда вы вызываете метод, помеченный аннотацией
   `@Transactional`, из метода без аннотации `@Transactional`, и этот вызов
   происходит через Spring (например, через инъекцию зависимостей), то
   транзакция будет создана и управляться для вызова этого метода. Метод,
   который не аннотирован `@Transactional`, не будет автоматически участвовать в
   транзакции. Однако сам вызов метода с `@Transactional` будет обработан
   Spring, и транзакция будет работать корректно.

2. **Внутренний вызов метода**: Важно заметить, что если метод с
   `@Transactional` вызывается внутри того же класса, это не приведет к
   корректному применению транзакции, так как прокси работает только для
   внешних вызовов. Если же метод с аннотацией вызывается из другого класса,
   например, через инъекцию зависимостей, то транзакция будет работать, как
   ожидалось.

##### Пример: Вызов метода с `@Transactional` из метода без этой аннотации

```java

@Service
public class MyService {

    @Autowired
    private AnotherService anotherService;  // Другой сервис с транзакционным методом

    public void methodWithoutTransaction() {
        // Этот метод не будет транзакционным, но вызовет метод с @Transactional
        anotherService.methodWithTransaction();
    }
}

@Service
public class AnotherService {

    @Transactional
    public void methodWithTransaction() {
        // Этот метод будет выполняться в рамках транзакции
        System.out.println("This method is transactional.");
    }
}
```

В данном примере:

- `methodWithoutTransaction()` не имеет аннотации `@Transactional`, но вызывает
  метод `methodWithTransaction()`, который помечен как транзакционный.
- Поскольку вызов `methodWithTransaction()` происходит через инъекцию
  зависимостей (то есть это внешний вызов), транзакция будет корректно
  управляться Spring для метода `methodWithTransaction()`.

##### Важное ограничение:

- **Внутренний вызов**: Если вы вызовете метод с аннотацией `@Transactional` из
  другого метода **в том же классе**, транзакция не будет корректно применена.
  Прокси транзакций в Spring работает только для **внешних** вызовов, то есть
  вызов должен происходить через Spring (например, через инъекцию зависимостей).

Пример, где транзакция **не будет работать**:

```java

@Service
public class MyService {

    @Transactional
    public void methodWithTransaction() {
        // Транзакция начнется здесь
        methodWithoutTransaction();  // Вызов из того же класса, транзакция не будет применена
    }

    public void methodWithoutTransaction() {
        // Этот метод не будет транзакционным
    }
}
```

В этом случае, вызов `methodWithoutTransaction()` из `methodWithTransaction()`
не приведет к транзакционному поведению, так как вызов происходит внутри того же
класса, и прокси не срабатывает.

#### Заключение:

- **Да**, можно вызывать метод с аннотацией `@Transactional` из метода, не
  помеченного этой аннотацией, если вызов происходит через Spring (например,
  через инъекцию зависимостей).
- Однако **если метод с аннотацией `@Transactional` вызывается внутри того же
  класса**, транзакция не будет применяться, так как прокси применяется только к
  внешним вызовам.

Поэтому всегда учитывайте, что Spring применяет проксирование только к **внешним
вызовам**.

### Работа аннотации @Transactional шаг за шагом

#### Что происходит, когда ты пишешь `@Transactional`

```java

@Service
public class OrderService {

    @Transactional
    public void createOrder() {
        // 1. Начинаем транзакцию
        // 2. Выполняем SQL/ORM операции
        // 3. Коммит или откат
    }
}
```

Ты вроде написал всего одну аннотацию, а на самом деле запускается целый
механизм:

#### Шаг за шагом — как это работает

##### **1. Spring создает прокси**

Когда Spring видит аннотацию `@Transactional`, он не просто использует твой
класс напрямую, а **создает обёртку** (прокси), которая перехватывает вызовы
методов и добавляет транзакционную логику.

- Если ты используешь интерфейсы — применяется **JDK proxy**.
- Если нет интерфейсов — используется **CGLIB proxy** (динамическое
  наследование).

> Это важно: внутренние вызовы методов не проходят через прокси — именно поэтому
`@Transactional` может не сработать, если вызвать метод изнутри того же класса.

##### **2. Прокси перехватывает вызов метода**

Когда ты вызываешь `createOrder()`, на самом деле вызывается:

```
proxy.createOrder();
```

И тут Spring делает следующее:

**Проверка контекста транзакции:**

- Есть ли уже активная транзакция?
    - Если **да**, и `Propagation` = `REQUIRED` — используем её.
    - Если `REQUIRES_NEW` — **приостанавливаем текущую**, начинаем новую.
    - Если `NOT_SUPPORTED` — **приостанавливаем текущую** и выполняем без
      транзакции.
    - И т.д.

**Вызов `TransactionManager`:**

- Выбирается нужный `PlatformTransactionManager`.
- Вызывается метод `getTransaction()` -> начинается транзакция.

##### **3. Выполняется твой метод**

Теперь вызывается **реальный** метод `createOrder()`.

##### **4. Коммит или откат**

После завершения метода:

- Если всё прошло без исключений → `commit`.
- Если было `RuntimeException` или `Error` → `rollback`.

> По умолчанию Spring откатывает **только unchecked exceptions** (например,
`RuntimeException`). Для checked-исключений (`IOException`, `SQLException`) —
> нужно указать явно:

```java
@Transactional(rollbackFor = IOException.class)
```

##### **5. Завершение**

Текущая транзакция закрывается, и Spring "возвращает" выполнение дальше.

**Пример жизненного цикла**

```java

@Transactional
public void process() {
    dao.save();
    dao.update();
    if (someConditionFails()) {
        throw new RuntimeException("Oops");
    }
}
```

**Под капотом:**

1. `TransactionManager.begin()` — старт
2. `save()` и `update()` вызываются внутри транзакции
3. Если исключение — `rollback`
4. Если всё ок — `commit`

#### Подводные камни

- **Внутренний вызов метода** — не работает, транзакция не включится.
- **Не те исключения** — если не RuntimeException, то откат не произойдёт.
- **Неправильный уровень распространения (`Propagation`)** — можно нечаянно
  вложить транзакции или потерять их.

## ACID

**ACID** — это набор четырёх принципов, которые гарантируют, что транзакции в
**системах управления базами данных (СУБД)** выполняются корректно и с
сохранением **целостности** данных, даже в случае сбоев или ошибок.

ACID — это аббревиатура, расшифровывается как:

1. **A** — **Atomicity** (Атомарность)
2. **C** — **Consistency** (Согласованность)
3. **I** — **Isolation** (Изоляция)
4. **D** — **Durability** (Долговечность)

Каждый из этих принципов играет важную роль в обеспечении корректной работы
транзакций в базе данных.

### 1. **Atomicity** (Атомарность)

**Атомарность** означает, что транзакция рассматривается как **единое целое**,
которое либо выполняется полностью, либо не выполняется вообще. Если в процессе
выполнения транзакции произошла ошибка, все изменения, сделанные в рамках
транзакции, будут откатаны, и база данных вернется в состояние, которое было до
её начала.

- **Пример**: Если транзакция включает в себя два действия, например, перевод
  денег с одного счёта на другой, и при этом происходит сбой при снятии денег,
  то операция будет отменена, и деньги не будут сняты.

### 2. **Consistency** (Согласованность)

**Согласованность** гарантирует, что транзакция переводит базу данных из одного
**консистентного состояния** в другое, соблюдая все бизнес-правила, ограничения
и инварианты, заданные для данных. Если транзакция завершена успешно, база
данных должна оставаться в консистентном состоянии. В случае сбоя транзакция не
должна приводить к нарушению целостности данных.

- **Пример**: Если в базе данных есть ограничения, например, на уникальность
  идентификаторов или на значения валюты, то транзакция должна быть такой, чтобы
  после её выполнения эти ограничения не нарушались.

### 3. **Isolation** (Изоляция)

**Изоляция** гарантирует, что транзакции выполняются независимо друг от друга, и
их результаты не могут быть видны другим транзакциям до завершения. Это
означает, что одна транзакция не может "увидеть" изменения, сделанные другой
транзакцией, если эта другая транзакция ещё не завершена (в зависимости от
уровня изоляции транзакций).

- **Пример**: Если две транзакции одновременно пытаются изменить один и тот же
  объект, одна из них должна быть заблокирована до завершения другой, чтобы
  избежать конфликтов и несогласованности данных.

### 4. **Durability** (Долговечность)

**Долговечность** гарантирует, что как только транзакция завершена (коммичена),
все её изменения будут сохранены в базе данных и не будут потеряны, даже если
произойдёт сбой системы, например, сбой питания или отключение компьютера.

- **Пример**: После того как вы перевели деньги на счёт другого человека,
  изменения должны остаться в базе данных даже если сервер упадет сразу после
  завершения транзакции.

## Уровни изоляции транзакций

**Уровни изоляции транзакций** — это ключевая концепция в работе с базами
данных, которая определяет, как транзакции взаимодействуют друг с другом и как
их операции влияют на данные в условиях параллельного выполнения. Эти уровни
обеспечивают баланс между **производительностью** и **согласованностью** данных.

В **SQL** и **Spring** есть несколько стандартных уровней изоляции, которые
контролируют, насколько одна транзакция может «видеть» изменения, сделанные
другими транзакциями. Чем выше уровень изоляции, тем больше ограничений
накладывается на параллельные транзакции, чтобы избежать **нежелательных
эффектов**, но это может снижать производительность.

### Уровни изоляции транзакций

1. **READ UNCOMMITTED** (Чтение неподтвержденных данных)
2. **READ COMMITTED** (Чтение только подтвержденных данных)
3. **REPEATABLE READ** (Повторяемое чтение)
4. **SERIALIZABLE** (Сериализуемый)

### 1. **READ UNCOMMITTED** (Чтение неподтвержденных данных)

- этот уровень изоляции позволяет транзакциям читать данные, которые еще не были
  зафиксированы другими транзакциями. Это может привести к **грязным чтениям**
  (dirty reads), когда транзакция читает данные, которые могут быть отменены,
  если транзакция, изменившая их, будет откатана.

- **Проблемы:**
    - **Грязные чтения**: Транзакция может читать данные, которые могут быть
      откатаны, что приведет к недостоверной информации.
    - **Невозможность гарантировать консистентность**.

- **Когда использовать?**
  Этот уровень обычно используется, если необходимо получить **высокую
  производительность**, но если допустимы **неполные или неточные данные** (
  например, для отчетности, где точность не так критична).

### 2. **READ COMMITTED** (Чтение только подтвержденных данных)

- транзакции могут читать только те данные, которые были **подтверждены**
  другими транзакциями (т.е. изменения, сделанные транзакциями, которые уже
  завершились, будут видны). Однако, если другая транзакция меняет данные во
  время чтения, текущая транзакция может получить разные данные при последующих
  чтениях одних и тех же строк (так называемое **неповторяемое чтение**).

- **Проблемы:**
    - **Неповторяемое чтение**: Транзакция может получить разные результаты при
      нескольких чтениях одних и тех же данных, если другая транзакция изменила
      их между чтениями.

- **Когда использовать?**
  Этот уровень изоляции — хороший компромисс между производительностью и
  консистентностью для большинства приложений, где требуется, чтобы транзакции
  не видели неподтвержденные изменения.

### 3. **REPEATABLE READ** (Повторяемое чтение)

- Этот уровень изоляции гарантирует, что данные, считанные транзакцией, не могут
  быть изменены другими транзакциями до завершения текущей транзакции.
  Транзакция не столкнется с **неповторяемыми чтениями**: если она прочитала
  данные, эти данные не изменятся, пока транзакция не завершится.

- **Проблемы:**
    - **Фантомные чтения**: Транзакция может столкнуться с ситуацией, когда
      новые строки данных появляются в результате других транзакций, несмотря на
      то, что сама транзакция видит стабильные данные.

- **Когда использовать?**
  Этот уровень подходит для приложений, где важно, чтобы данные, прочитанные в
  транзакции, оставались неизменными на протяжении всей транзакции. Например, в
  системах бронирования или финансовых приложениях, где важно, чтобы транзакция
  не "потеряла" информацию о том, что она уже прочитала.

### 4. **SERIALIZABLE** (Сериализуемый)

- Самый высокий уровень изоляции. Транзакции выполняются **по очереди**: каждая
  транзакция выполняется так, как если бы она была единственной в системе, и ее
  действия не могут пересекаться с действиями других транзакций. Это
  предотвращает **грязные чтения**, **неповторяемые чтения** и **фантомные
  чтения**.

- **Проблемы:**
    - **Производительность**: Это может значительно замедлить систему, потому
      что транзакции будут работать поочередно, а не параллельно.
    - **Блокировки**: Весь ряд данных, с которым работает транзакция, будет
      заблокирован для других, что может сильно снизить производительность
      системы при высокой нагрузке.

- **Когда использовать?**
  Используется, когда **требуется абсолютная консистентность** данных и при этом
  возможны **высокие задержки**. Например, в банковских системах или системах,
  где критически важна корректность финансовых данных.

### Таблица уровней изоляции

| Уровень изоляции     | Грязные чтения | Неповторяемое чтение | Фантомные чтения | Пример применения                |
|----------------------|----------------|----------------------|------------------|----------------------------------|
| **READ UNCOMMITTED** | Разрешены      | Разрешены            | Разрешены        | Внешняя отчетность               |
| **READ COMMITTED**   | Запрещены      | Разрешены            | Разрешены        | Большинство веб-приложений       |
| **REPEATABLE READ**  | Запрещены      | Запрещены            | Разрешены        | Финансовые приложения            |
| **SERIALIZABLE**     | Запрещены      | Запрещены            | Запрещены        | Критические системы (банковские) |

### Как установить уровень изоляции транзакции в Spring?

В Spring можно настроить уровень изоляции через аннотацию `@Transactional`,
используя атрибут `isolation`.

Пример:

```java
import org.springframework.transaction.annotation.Isolation;
import org.springframework.transaction.annotation.Transactional;

@Transactional(isolation = Isolation.SERIALIZABLE)
public void someMethod() {
    // Код, который будет выполнен с самым высоким уровнем изоляции
}
```

В Spring доступны следующие значения для **`Isolation`**:

- `Isolation.DEFAULT` — используется уровень изоляции по умолчанию (обычно это
  `READ_COMMITTED`).
- `Isolation.READ_UNCOMMITTED` — позволяет читать неподтвержденные данные.
- `Isolation.READ_COMMITTED` — запрещает грязные чтения.
- `Isolation.REPEATABLE_READ` — гарантирует отсутствие неповторяемых чтений.
- `Isolation.SERIALIZABLE` — самый строгий уровень изоляции.

### Резюме:

1. **`READ UNCOMMITTED`** — самый слабый уровень, позволяет грязные чтения.
2. **`READ COMMITTED`** — запрещает грязные чтения, но не исключает
   неповторяемые чтения.
3. **`REPEATABLE READ`** — гарантирует отсутствие неповторяемых чтений, но не
   защищает от фантомных чтений.
4. **`SERIALIZABLE`** — самый строгий уровень изоляции, исключает все виды
   конфликтов, но может сильно снижать производительность.

Выбор уровня изоляции зависит от потребностей вашего приложения: если вам нужно
**повышение производительности**, можно использовать **READ COMMITTED** или
**READ UNCOMMITTED**; если важна **абсолютная консистентность** данных, лучше
выбрать **SERIALIZABLE**.

## Проблемы, связанные с уровнями изоляции

Каждый уровень изоляции транзакций в базах данных имеет свои преимущества
и недостатки. При настройке уровней изоляции важно учитывать баланс между
**производительностью** и **целостностью данных**. Хотя более строгие уровни
изоляции обеспечивают большую консистентность данных, они могут привести к
потере производительности и другим проблемам, таким как блокировки и мёртвые
блокировки.

Основные проблемы, связанные с уровнями изоляции:

### 1. Потерянное обновление (lost update)

- при одновременном изменении одного блока данных разными транзакциями теряются
  все изменения, кроме последнего. Т.е. в этом случае одна транзакция
  переписывает изменения, осуществленные другой транзакцией, в результате одно
  из изменений будет утеряно;

### 2. **Грязные чтения (Dirty Reads)** — **`READ UNCOMMITTED`**

**Грязные чтения** происходят, когда одна транзакция читает данные,
которые были изменены другой транзакцией, но ещё не зафиксированы.

Это может привести к ошибочным или некорректным данным, так как данные,
прочитанные одной транзакцией, могут быть отменены другой.

Транзакция A считывает данные, которые были изменены транзакцией B, но
транзакция B откатывает изменения. Транзакция A использует некорректные
данные.

- **Решение**: Использовать более строгие уровни изоляции, такие как *
  *`READ COMMITTED`** или выше, чтобы исключить грязные чтения.

### 3. **Неповторяемое чтение (Non-repeatable Read)** — **`READ COMMITTED`**

Когда в одной и той же транзакции значение одной и той же строки при повторном
чтении меняется, потому что другая транзакция изменила и закоммитила эту строку

Решение: Использование уровня изоляции `REPEATABLE READ` или
`SERIALIZABLE` для блокировки данных и предотвращения их изменения другими
транзакциями.

### 4. **Фантомные чтения (Phantom Reads)** — **`REPEATABLE READ`**

**Фантомные чтения** происходят, когда в одной транзакции выполняется одинаковый
SELECT, возвращающий набор строк, и во втором чтении появляются новые строки,
которых раньше не было, потому что другая транзакция их вставила/удалила.

- **Проблема**:
    - Из-за изменения данных другим пользователем (добавление или удаление
      строк) результат выборки может измениться, что приводит к *
      *непредсказуемости** или **несогласованности данных**.

- **Пример**:
    - Транзакция A выполняет запрос для выборки всех заказов на сумму более 100
      долларов и получает 3 строки. В то время как транзакция A работает,
      транзакция B добавляет новый заказ на сумму 150 долларов. После завершения
      транзакции A тот же запрос даёт 4 строки, включая новый заказ.

- **Решение**: Использование уровня изоляции **`SERIALIZABLE`**, который
  блокирует изменения в наборе строк данных во время работы транзакции.

### 5. Мёртвая блокировка (Deadlock) — `SERIALIZABLE` и `REPEATABLE READ`

- **Что это?**
    - **Мёртвая блокировка** возникает, когда две или более транзакции блокируют
      друг друга, ожидая ресурсы, занятые другими транзакциями, образуя **цикл
      зависимостей**. Это приводит к тому, что транзакции не могут завершиться,
      и система остаётся в состоянии блокировки.

- **Проблема**:
    - Когда транзакции не могут быть выполнены, это может привести к **потере
      производительности** и **висению** системы, так как транзакции никогда не
      завершатся.

- **Пример**:
    - Транзакция A блокирует строку 1, а транзакция B блокирует строку 2.
      Транзакция A пытается получить блокировку на строку 2, а транзакция B
      пытается заблокировать строку 1. Обе транзакции ожидают друг друга, что
      приводит к **мёртвой блокировке**.

- **Решение**: Использование таймаутов, а также грамотная организация
  порядка блокировок и использование **уровней изоляции**, минимизирующих
  необходимость в блокировках (например, **`READ COMMITTED`**).

### 6. **Проблемы с производительностью** — **`SERIALIZABLE`**

- **Что это?**
    - Уровень изоляции **`SERIALIZABLE`** представляет собой самый строгий
      уровень изоляции и блокирует все данные, с которыми работает транзакция.
      Это может привести к значительным **потерям производительности**, так как
      транзакции становятся последовательными, и система не может эффективно
      использовать многозадачность.

- **Проблема**:
    - **Медленная работа** системы, поскольку транзакции ожидают друг друга, что
      значительно снижает **пропускную способность** и **конкурентность**.

- **Решение**: Использование более слабых уровней изоляции, таких как *
  *`READ COMMITTED`** или **`REPEATABLE READ`**, в зависимости от потребностей
  приложения.

### 7. **Иллюзия согласованности (Phantom Read + Dirty Read)** — *

*`READ UNCOMMITTED`**

- **Что это?**
    - Когда транзакции выполняются с уровнем изоляции **`READ UNCOMMITTED`**,
      могут возникать не только грязные чтения, но и иллюзия согласованности
      данных. Например, транзакция может видеть изменения данных, которые будут
      отменены или изменены другой транзакцией.

- **Проблема**:
    - Это может привести к **некорректным решениям** или действиям, основанным
      на данных, которые не являются истинными (например, неправильные расчеты
      или отчеты).

- **Решение**: Повышение уровня изоляции транзакций до **`READ COMMITTED`** или
  выше для предотвращения грязных чтений и повышения надёжности работы с
  данными.

### 🔧 **Резюме: Проблемы и решения**

| Проблема                           | Уровень изоляции   | Описание проблемы                                               | Рекомендация                                       |
|------------------------------------|--------------------|-----------------------------------------------------------------|----------------------------------------------------|
| **Грязные чтения**                 | `READ UNCOMMITTED` | Чтение неподтвержденных данных.                                 | Использовать `READ COMMITTED` или выше.            |
| **Неповторяемое чтение**           | `READ COMMITTED`   | Изменение данных между чтениями одной транзакции.               | Использовать `REPEATABLE READ` или выше.           |
| **Фантомные чтения**               | `REPEATABLE READ`  | Изменение набора данных (добавление/удаление строк).            | Использовать `SERIALIZABLE`.                       |
| **Мёртвая блокировка**             | Все уровни         | Транзакции блокируют друг друга, ожидая освобождения ресурсов.  | Использовать таймауты и упорядочивание блокировок. |
| **Проблемы с производительностью** | `SERIALIZABLE`     | Очень строгие блокировки могут замедлить систему.               | Использовать более слабые уровни изоляции.         |
| **Иллюзия согласованности**        | `READ UNCOMMITTED` | Невозможность корректно работать с промежуточными результатами. | Использовать `READ COMMITTED` или выше.            |

Выбор уровня изоляции зависит от **конкретных требований** к приложению. Для
большинства приложений достаточно **`READ COMMITTED`** или **`REPEATABLE READ`
**, но для критичных данных (например, в банковских системах) лучше использовать
**`SERIALIZABLE`** с учётом того, что это может снизить производительность.


> ## Kafka про партиции чуть лучше



> ## SQL. Индексы в SQL

Индексы в **SQL** — это структуры данных, которые улучшают производительность
операций поиска в базе данных, а также позволяют эффективно выполнять сортировку
и фильтрацию данных. Они создаются для улучшения скорости извлечения данных,
особенно когда таблицы становятся большими.

В SQL существует несколько типов индексов, каждый из которых имеет свои
особенности и применяется в зависимости от задач и структуры данных.

### 1. **Первичный индекс (Primary Index)**

- **Описание**: Это индекс, который автоматически создается для столбца (или
  столбцов), помеченных как **PRIMARY KEY**. Он гарантирует уникальность
  значений в столбце или группе столбцов.
- **Особенности**:
    - Таблица может иметь только один первичный индекс.
    - Он всегда уникален и не может содержать `NULL` значения.
    - Первичный индекс обычно является кластеризованным (см. ниже).
- **Пример**:
  ```sql
  CREATE TABLE users (
      user_id INT PRIMARY KEY,
      username VARCHAR(50),
      email VARCHAR(100)
  );
  ```

### 2. **Кластеризованный индекс (Clustered Index)**

- **Описание**: Кластеризованный индекс определяет физический порядок строк в
  таблице. Когда вы создаете кластеризованный индекс, данные таблицы будут
  отсортированы в соответствии с этим индексом. Как правило, в таблице может
  быть только один кластеризованный индекс.
- **Особенности**:
    - Обычно первичный ключ автоматически создаёт кластеризованный индекс.
    - Если кластеризованный индекс присутствует, строки таблицы хранятся в
      порядке, соответствующем этому индексу.
- **Пример**:
  ```sql
  CREATE CLUSTERED INDEX idx_user_id ON users(user_id);
  ```

### 3. **Некластеризованный индекс (Non-clustered Index)**

- **Описание**: Это обычный индекс, который хранит указатели на строки в
  таблице, но не изменяет физический порядок данных в таблице. Он работает как
  отдельная структура, которая хранит ключи и ссылки на строки.
- **Особенности**:
    - Один столбец или несколько столбцов могут быть индексированы.
    - Может быть создано несколько некластеризованных индексов на одной таблице.
- **Пример**:
  ```sql
  CREATE NONCLUSTERED INDEX idx_username ON users(username);
  ```

### 4. **Уникальный индекс (Unique Index)**

- **Описание**: Этот индекс гарантирует, что все значения в индексируемом
  столбце или группе столбцов будут уникальными, то есть не будет дублирующихся
  значений.
- **Особенности**:
    - Он создаётся автоматически, когда на столбец накладывается ограничение
      **UNIQUE**.
    - Может быть кластеризованным или некластеризованным.
- **Пример**:
  ```sql
  CREATE UNIQUE INDEX idx_email ON users(email);
  ```

### 5. **Индекс полного текста (Full-text Index)**

- **Описание**: Этот индекс используется для быстрого поиска текстовой
  информации в больших текстовых полях (например, в статьях или комментариях).
  Он позволяет выполнять полнотекстовый поиск, который учитывает не только
  точные совпадения, но и слова, синонимы, морфологию.
- **Особенности**:
    - Полнотекстовые индексы создаются на столбцах, которые содержат текстовые
      данные.
    - Используется для запросов с операторами типа `MATCH ... AGAINST`.
- **Пример**:
  ```sql
  CREATE FULLTEXT INDEX idx_fulltext_content ON articles(content);
  ```

### 6. **Индекс с битовыми картами (Bitmap Index)**

- **Описание**: Индекс с битовой картой используется для эффективного поиска в
  столбцах с небольшим количеством уникальных значений (например, в столбцах с
  флагами или перечислениями).
- **Особенности**:
    - Хорошо подходит для столбцов с небольшим числом уникальных значений,
      например, для флагов (т.е. `YES`/`NO`, `TRUE`/`FALSE`).
    - Быстрее, чем обычный индекс, для чтения, но медленнее при обновлениях или
      вставках.
- **Пример**:
  ```sql
  CREATE BITMAP INDEX idx_is_active ON users(is_active);
  ```

### 7. Индекс на основе B-дерева

### 8. Hash индекс

### 9. **Индекс для нескольких столбцов (Composite Index)**

- **Описание**: Этот индекс создаётся для нескольких столбцов одновременно. Он
  помогает ускорить запросы, которые фильтруют данные по нескольким столбцам
  одновременно.
- **Особенности**:
    - Используется для комбинированных запросов, которые включают несколько
      условий.
        - Индекс будет эффективным только для тех запросов, использующих  
          столбцы в том порядке, в котором они были определены в индексе.
- **Пример**:
  ```sql
  CREATE INDEX idx_username_email ON users(username, email);
  ```

### **Как выбирать индекс для своей базы данных?**

1. **Производительность чтения vs записи**: Индексы значительно ускоряют
   операции чтения (поиск, фильтрация, сортировка), но замедляют операции
   записи (вставка, обновление, удаление), так как они требуют обновления самого
   индекса. Поэтому нужно тщательно подбирать, какие столбцы индексировать.
2. **Тип данных**: Некоторые индексы лучше подходят для работы с текстовыми
   данными (например, полнотекстовый индекс), другие — с числовыми или булевыми
   значениями (например, битовые индексы).
3. **Размер таблицы**: Для очень больших таблиц индексы становятся
   необходимостью для ускорения запросов.
4. **Тип запросов**: Индексы помогают при выполнении запросов с фильтрацией,
   сортировкой или объединениями по индексированным столбцам.

### **Заключение**

Индексы в SQL играют важную роль в повышении производительности запросов,
особенно при работе с большими объемами данных. Различные типы индексов
предоставляют разные преимущества в зависимости от типа данных и структуры
запросов, которые выполняются в базе данных. Выбор правильного типа индекса и
грамотное управление ими может значительно улучшить производительность системы.

=====================================================================
> ## Hibernate. Стратегии генерирования id

В Hibernate существует несколько **стратегий генерации идентификаторов (ID)**,
которые определяют, как создаются значения для первичных ключей сущностей. Эти
стратегии задаются с помощью аннотации `@GeneratedValue` и параметра `strategy`.

---

## 🔧 Основные стратегии генерации ID

### 1. `GenerationType.AUTO`

- 📌 **Hibernate сам выбирает стратегию** в зависимости от диалекта базы данных.
- Может выбрать `IDENTITY`, `SEQUENCE`, `TABLE`, в зависимости от СУБД.

```java

@Id
@GeneratedValue(strategy = GenerationType.AUTO)
private Long id;
```

---

### 2. `GenerationType.IDENTITY`

- Использует **автоинкремент** (`AUTO_INCREMENT`, `IDENTITY`) на уровне базы
  данных.
- Подходит для MySQL, SQL Server.

```java

@Id
@GeneratedValue(strategy = GenerationType.IDENTITY)
private Long id;
```

🟡 **Минусы**:

- ID генерируется **только при insert**, не работает с batch inserts.
- Не кэшируется Hibernate’ом.

---

### 3. `GenerationType.SEQUENCE`

- Использует **sequence** из базы данных (обычно в PostgreSQL, Oracle).
- Позволяет Hibernate **предсказывать** следующий ID и кэшировать.

```java

@Id
@GeneratedValue(strategy = GenerationType.SEQUENCE, generator = "seq_gen")
@SequenceGenerator(name = "seq_gen", sequenceName = "my_seq", allocationSize = 1)
private Long id;
```

🟢 **Плюсы**:

- Можно настраивать `allocationSize` для пакетной генерации.
- Идеально для PostgreSQL.

---

### 4. `GenerationType.TABLE`

- Создаёт **отдельную таблицу** для хранения текущего значения ID.
- Работает в любой СУБД.

```java

@Id
@GeneratedValue(strategy = GenerationType.TABLE, generator = "tbl_gen")
@TableGenerator(name = "tbl_gen", table = "id_table", pkColumnName = "key_name",
        valueColumnName = "next_val", pkColumnValue = "my_entity", allocationSize = 1)
private Long id;
```

🔴 **Минусы**:

- Самая **медленная стратегия**, потому что требует обращения к специальной
  таблице.
- Используется, если нет поддержки `SEQUENCE` или `IDENTITY`.

---

## 🧠 Альтернативы:

- **UUID / GUID**:
  ```java
  @Id
  @GeneratedValue(generator = "uuid2")
  @GenericGenerator(name = "uuid2", strategy = "uuid2")
  private UUID id;
  ```

- **Custom генераторы**:
    - Можно реализовать собственную стратегию генерации через
      `IdentifierGenerator`.

---

## 🔍 Как выбрать стратегию?

| Ситуация                              | Рекомендуемая стратегия      |
|---------------------------------------|------------------------------|
| MySQL / SQL Server                    | `IDENTITY`                   |
| PostgreSQL / Oracle                   | `SEQUENCE`                   |
| Кросс-БД совместимость                | `TABLE` или `AUTO`           |
| Используешь UUID                      | `uuid2` / `uuid`             |
| Нужен контроль / нестандартная логика | `Custom IdentifierGenerator` |

---

================================================================================

> ## Hibernate. тип загрузки (fetching strategy)** для связанных сущностей в JPA


Отлично, давай подробно разберёмся, что такое **тип загрузки (fetching strategy)
** для связанных сущностей в JPA / Hibernate — это ключевой момент для
производительности и правильной работы с данными.

---

## 📦 Что такое Fetching Strategy?

**Fetching strategy** — это способ, которым **Hibernate загружает связанные
сущности** из базы данных при обращении к основному объекту.

Есть два типа:

| Тип загрузки       | Описание                                                              |
|--------------------|-----------------------------------------------------------------------|
| **LAZY** (ленивая) | Связанная сущность загружается **только при первом обращении** к ней. |
| **EAGER** (жадная) | Связанная сущность загружается **сразу вместе с родительской**.       |

---

## 🔍 Где это используется?

В аннотациях связей:

```java
@OneToMany(fetch = FetchType.LAZY)
@ManyToOne(fetch = FetchType.EAGER)
```

---

## 🧪 Пример

```java

@Entity
public class User {
    @OneToMany(mappedBy = "user", fetch = FetchType.LAZY)
    private List<Order> orders;
}
```

- Когда ты загружаешь `User`, `orders` **не будут загружены**.
- Они загрузятся **только при вызове `user.getOrders()`**.

---

## 📊 Сравнение: LAZY vs EAGER

| Параметр                | LAZY                                               | EAGER                                      |
|-------------------------|----------------------------------------------------|--------------------------------------------|
| Когда загружается?      | При первом доступе к полю                          | Сразу, при загрузке объекта                |
| Производительность      | Лучше, если данные не нужны                        | Может тянуть ненужные данные               |
| Количество SQL-запросов | Больше (при обращении к полю)                      | Меньше (если данные нужны сразу)           |
| Возможные ошибки        | `LazyInitializationException`, если сессия закрыта | Нет ошибок, но можно грузить слишком много |

---

## 🔄 Как подгрузить связанные сущности вручную?

1. **`JOIN FETCH` в JPQL**:

```java
SELECT u
FROM User
u JOIN
FETCH u.
orders WHERE
u.id =:id
```

2. **EntityGraph**:

```java

@EntityGraph(attributePaths = {"orders"})
User user = em.find(User.class, id, hints);
```

3. **Hibernate.initialize()**:

```java
Hibernate.initialize(user.getOrders());
```

(работает только в открытой сессии)

---

## 📘 По умолчанию:

| Связь         | Тип загрузки по умолчанию |
|---------------|---------------------------|
| `@ManyToOne`  | `EAGER`                   |
| `@OneToOne`   | `EAGER`                   |
| `@OneToMany`  | `LAZY`                    |
| `@ManyToMany` | `LAZY`                    |

---

## ✅ Рекомендации

- Всегда **используй LAZY по умолчанию**, и **подгружай явно**, когда нужно.
- Используй **JOIN FETCH** или **DTO**-проекцию, чтобы избежать N+1.
- Не забывай про `@Transactional`, если используешь LAZY в сервисах.

---

Хочешь пример сервиса, где это реализовано правильно?

=========================================================================

## Сравнение EAGER и LAZY

Отличный вопрос! В контексте **Hibernate (и JPA)** термины `eager` и `lazy`
относятся к **типу загрузки (fetching strategy)** связанных сущностей.

---

## 📦 Что такое `EAGER` и `LAZY`?

Они определяют, **когда Hibernate загружает связанные данные** из базы данных:

| Стратегия | Описание                                                       |
|-----------|----------------------------------------------------------------|
| **LAZY**  | Загрузка **по требованию**, только когда реально используется. |
| **EAGER** | Загрузка **сразу**, вместе с родительским объектом.            |

---

## 📘 Пример

Представим, есть сущность `User` и у него есть список `orders`.

```java

@Entity
public class User {
    @OneToMany(mappedBy = "user", fetch = FetchType.LAZY) // или EAGER
    private List<Order> orders;
}
```

---

## 🐢 `LAZY` (ленивая загрузка)

- `orders` не загружается при загрузке `User`.
- Загружается **только при первом доступе к `getOrders()`**.
- Подходит, если тебе **не всегда нужны связанные данные**.

```java
User user = entityManager.find(User.class, 1L); // SELECT * FROM users WHERE id = 1;
List<Order> orders = user.getOrders();         // <-- В этот момент SELECT * FROM orders ...
```

---

## ⚡ `EAGER` (жадная загрузка)

- `orders` загружается **сразу** вместе с `User`.
- Даже если ты **не используешь `orders`**, Hibernate всё равно подгрузит их.

```java
User user = entityManager.find(User.class, 1L);
// Выполнится JOIN-запрос или два отдельных SELECT’а
```

---

## 📊 Сравнение

| Особенность                                               | `LAZY`                             | `EAGER`                         |
|-----------------------------------------------------------|------------------------------------|---------------------------------|
| Производительность                                        | 🔼 Лучше (если не нужна коллекция) | 🔽 Может тянуть ненужные данные |
| Управление запросами                                      | ✅ Гибко                            | ❌ Меньше контроля               |
| Риск `LazyInitializationException`                        | ❌ Есть (если сессия закрыта)       | ✅ Нет                           |
| Используется по умолчанию для `@OneToMany`, `@ManyToMany` | ✅ Да (`LAZY`)                      | ❌ Нет (`EAGER` вручную)         |

---

## ⚠️ Важные нюансы

- Hibernate **по умолчанию делает `LAZY`** для коллекций (`@OneToMany`,
  `@ManyToMany`) и **`EAGER`** для одиночных ссылок (`@ManyToOne`, `@OneToOne`).
- У **`LAZY` загрузки есть риск**: если сессия уже закрыта, доступ к полю
  вызовет `LazyInitializationException`.

---

## 🛠️ Как защититься от `LazyInitializationException`?

- Используй `JOIN FETCH` в HQL/JPQL.
- Используй DTO и `EntityGraph`.
- Загружай данные внутри открытой транзакции (например, в `@Transactional`
  методе).

---

Хочешь пример с
`JOIN FETCH` или как правильно подгрузить LAZY-поле в контроллере?
===============================================================================

> ## Стратегии связывания сущностей

Отличный вопрос! В **Hibernate / JPA** стратегии связывания сущностей
определяются через аннотации отношений между объектами, и отвечают на вопрос: *
*как одна сущность связана с другой?** И как эта связь хранится в базе данных.

---

## 🔗 Основные типы связей между сущностями

| Тип связи     | Описание         | Примеры                     |
|---------------|------------------|-----------------------------|
| `@OneToOne`   | Один к одному    | У пользователя один профиль |
| `@OneToMany`  | Один ко многим   | Один автор — много книг     |
| `@ManyToOne`  | Многие к одному  | Много заказов — один клиент |
| `@ManyToMany` | Многие ко многим | Пользователи и роли         |

---

### 📘 Примеры аннотаций

#### 1. **@OneToOne**

```java

@Entity
public class User {
    @OneToOne
    @JoinColumn(name = "profile_id")
    private Profile profile;
}
```

> 🧠 В базе: `user.profile_id → profile.id`

---

#### 2. **@OneToMany / @ManyToOne**

```java

@Entity
public class Author {
    @OneToMany(mappedBy = "author")
    private List<Book> books;
}

@Entity
public class Book {
    @ManyToOne
    @JoinColumn(name = "author_id")
    private Author author;
}
```

> В таблице `book` есть колонка `author_id`

---

#### 3. **@ManyToMany**

```java

@Entity
public class Student {
    @ManyToMany
    @JoinTable(
            name = "student_course",
            joinColumns = @JoinColumn(name = "student_id"),
            inverseJoinColumns = @JoinColumn(name = "course_id")
    )
    private List<Course> courses;
}
```

> 🧠 Связь через промежуточную таблицу `student_course(student_id, course_id)`

---

## 🧩 Стратегии каскадирования (`cascade`)

Позволяют управлять действиями над связанными сущностями:

```java
@OneToMany(cascade = CascadeType.ALL)
```

| Cascade Type        | Что делает                   |
|---------------------|------------------------------|
| `ALL`               | Применяет все действия       |
| `PERSIST`           | Сохраняет связанные сущности |
| `MERGE`             | Обновляет их                 |
| `REMOVE`            | Удаляет                      |
| `DETACH`, `REFRESH` | Прочее управление состоянием |

---

## 💾 Дополнительно: `mappedBy` vs `JoinColumn`

- `mappedBy` — на стороне **обратной связи** (не владеющей)
- `@JoinColumn` — **владеющая сторона** (где находится внешний ключ)

---

## 🧠 Советы

- Для `@OneToMany` желательно всегда указывать `mappedBy`, иначе Hibernate может
  создать **лишнюю таблицу связи**.
- При `@ManyToMany` используется **промежуточная таблица**, и `@JoinTable` нужно
  указывать явно.
- Не злоупотребляй `CascadeType.ALL` — это может привести к неожиданным
  удалениям/обновлениям.

---

Хочешь, покажу ER-диаграммы с этими связями? Или пример базы с 3–4 связанными
таблицами на Java?

=======================================>

> ## Java Core:
> - устройство памяти и сборка мусора
> - Collection Framework и внутренняя работа коллекций
> - Работа с исключениями
> - Устройство и особенности StreamAPI
>## Multithreading
> - Механизмы синхронизации: synchronized, volatile, atomic types
> - Пробелемы race condition и deadlock, способы решения
> - Optimistic и Pessimistic locking
> - Многопоточные коллекции, пулы потоков, Future и CompletableFutute
    > Java Core. HashCode, equals()
