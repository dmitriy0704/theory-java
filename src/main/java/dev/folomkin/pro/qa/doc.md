# Материал для подгоовки к собесам

> ## SOLID

### Single Responsibility Principle - Принцип единственной ответственности.

_**У класса должен быть только один мотив для изменения.**_<br>

Каждый класс должен отвечать только за одну часть функциональности программы,
причём она должна быть полностью инкапсулирована в этот класс
(читай, скрыта внутри класса).

### Open/Closed Principle - Принцип открытости/закрытости

**_Расширяйте классы, но не изменяйте их первоначальный код._**

Классы должны быть открыты для расширения, но закрыты для изменения. Главная
идея этого принципа в том, чтобы не ломать существующий код при
внесении изменений в программу.

### Liskov Substitution Principle - Принцип подстановки Барбары Лисков

**_Подклассы должны дополнять, а не замещать поведение базового класса._**

Подклассы должны создаваться таким образом, чтобы их объекты можно было бы
подставлять вместо объектов базового класса, не ломая при этом функциональности
клиентского кода.

### Interface Segregation Principle - Принцип разделения интерфейса

**_Клиенты не должны зависеть от методов, которые они не используют._**

Интерфейсы должны быть достаточно узкими, чтобы классам не приходилось
реализовывать
избыточное поведение.

Принцип разделения интерфейсов говорит о том, что слишком «толстые» интерфейсы
необходимо разделять на более маленькие и специфические, чтобы клиенты маленьких
интерфейсов знали только о методах, которые необходимы им в работе. В итоге при
изменении метода интерфей- са не должны меняться клиенты, которые этот метод не
используют.

Наследование позволяет классу иметь только один суперкласс, но не ограничивает
количество интерфейсов, которые он может реализовать. Большинство объектных
языков программирования позволяют классам реализовывать сразу несколько
интерфейсов, поэтому нет нужды заталкивать в ваш интерфейс больше поведений, чем
он того требует. Вы всегда можете присвоить классу сразу несколько интерфейсов
поменьше.

### Dependency Inversion Principle - Принцип инверсии зависимостей

**_Классы верхних уровней не должны зависеть от классов нижних уровней. Оба
должны зависеть от абстракций. Абстракции не должны зависеть от деталей. Детали
должны зависеть от абстракций._**

> ## Java Generic. Можем как-то ограничить типы (про super)

Верхний уровень обобщений (Upper Bound Wildcards)

Верхний уровень обобщений используется для ограничения типа, который может быть
использован в качестве параметра. Это делается с помощью ключевого слова
extends. Например:

```java
public void processList(List<? extends Number> list) {
    for (Number number : list) {
        System.out.println(number);
    }
}
```

Нижний уровень обобщений (Lower Bound Wildcards)

Нижний уровень обобщений используется для указания того, что параметр может быть
определён как определённый тип или любой его суперкласс. Это делается с помощью
ключевого слова super. Например:

```java
public void addNumbers(List<? super Integer> list) {
    list.add(1);
    list.add(2);
}
```

Применение

Верхние границы полезны, когда вы хотите читать данные из структуры данных и не
хотите беспокоиться о том, какой конкретный подтип вы получаете.
Нижние границы полезны, когда вы хотите добавлять данные в структуру данных и
хотите гарантировать, что вы можете добавлять элементы определенного типа или
его подтипов.  
Эти концепции позволяют создавать более гибкие и безопасные API в Java.

> ## JAVA CORE. <br> Generics. PECS

Принцип PECS (Producer Extends, Consumer Super) — это концепция, связанная с
использованием обобщений (generics) в Java, которая помогает правильно управлять
типами при работе с коллекциями и другими обобщенными структурами данных. Этот
принцип особенно полезен для понимания, как использовать wildcard-тип (неопреде-
ленный тип) в Java.

**Основные идеи PECS**

Producer Extends: Если вы хотите создать структуру данных, которая будет
производить элементы (например, возвращать элементы из коллекции), используйте
`? extends T`. Это означает, что вы можете использовать любой подтип T.

Consumer Super: Если вы хотите создать структуру данных, которая будет
потреблять элементы (например, добавлять элементы в коллекцию), используйте
`? super T`. Это означает, что вы можете использовать любой суперкласс T.

Идея принципа в следующем:

### **Producer — Extends**

Если коллекция **производит** объекты (т.е. ты **читаешь** из неё), тогда нужно
использовать `? extends T`.

```java
List<? extends Number> numbers = List.of(1, 2, 3);
Number n = numbers.get(0); // OK
// numbers.add(4);  — нельзя добавлять, неизвестно, какой именно тип
```

Пример: ты читаешь числа из списка, но не добавляешь — подойдёт
`? extends Number`.

### **Consumer — Super**

Если коллекция **потребляет** объекты (т.е. ты **записываешь** в неё), тогда
нужно использовать `? super T`.

```java
public class Demo {
    public static void main(String[] args) {
        List<? super Integer> numbers2 = new ArrayList<Number>();
        numbers2.add(42); // OK
        Object obj = numbers2.get(0);
    }
}

```

Пример: ты добавляешь `Integer` в список — подойдёт `? super Integer`.

Или проще запомнить:
**"Если достаёшь — используй `extends`, если кладёшь — используй `super`"**


> ## Java StreamApi. Вызов без терминальной операции

Промежуточные операции не выполняются немедленно — они откладываются до тех пор,
пока не будет вызвана терминальная операция.  
Именно терминальная операция запускает выполнение потока. После ее вызова
происходит анализ операций в пайплайне, и определяется эффективная стратегия его
выполнения.

> ## Java StreamApi. .parallel(), fork-join-poll

Для параллельного выполнения потоков в Stream Api collection.stream()
можно заменить на` collection.parallelStream().operation()`  
либо в общем случае для произвольного stream:
`Source.stream().parallel().operation()`.

.parallel()<br>

Для запуска потоков в параллельном режиме можно использовать методы
parallelStream() или parallel(). По умолчанию потоки выполняются
последовательно, но с явным вызовом одного из этих методов поток переключается в
параллельный режим.<br>
Для разделения коллекций на части, которые обрабатываются параллельно, Java
использует Spliterator и его метод trySplit(). Этот метод разделяет данные на
подзадачи, которые затем могут быть распределены между несколькими потоками.
Каждая часть обрабатывается независимо, и результаты объединяются после
завершения работы всех потоков.<br>

parallelStream()

Методы stream().parallel() и parallelStream() в Java представляют два разных
способа создания параллельного потока.

1. stream().parallel(): этот метод используется для преобразования
   последовательного потока в параллельный поток. Его можно вызвать для любого
   объекта последовательного потока, чтобы включить параллельную обработку этого
   потока. Например:

        List<String> list = Arrays.asList("a", "b", "c");
        Stream<String> parallelStream = list.stream().parallel();

2. parallelStream(): этот метод вызывается непосредственно для объекта коллекции
   для создания параллельного потока. Он возвращает параллельный поток,
   позволяющий выполнять параллельную обработку элементов коллекции. Например:

        List<String> list = Arrays.asList("a", "b", "c");
        Stream<String> parallelStream = list.parallelStream();

Оба метода достигают одного и того же результата создания параллельного потока,
но основное различие заключается в способе их вызова. Метод stream().parallel()
вызывается для последовательного объекта потока, тогда как метод
parallelStream() вызывается непосредственно для объекта коллекции.

ForkJoinPool<br>

Когда вы создаете параллельный поток, он использует ForkJoinPool по умолчанию,
предоставленный Java, для параллельного выполнения операций потока. Это
означает, что работа по разделению данных и их распределению по нескольким
потокам выполняется ForkJoinPool. ForkJoinPool управляет пулом рабочих потоков и
планирует выполнение подзадач параллельного потока этими потоками. Он
динамически регулирует количество потоков в зависимости от доступных ядер ЦП и
рабочей нагрузки. Таким образом обеспечивается эффективное использование
системных ресурсов и повышается общая производительность обработки параллельных
потоков. Таким образом, связь между параллельными потоками и ForkJoinPool
заключается в том, что параллельные потоки используют ForkJoinPool для
параллельного выполнения операций потока, используя возможности параллельной
обработки и эффективного распределения рабочей нагрузки.


> ## Java Core. GCRoot

В Java, GC Root (или корень сборщика мусора) — это объект, который является
начальной точкой для процесса сборки мусора (Garbage Collection, GC). Сборщик
мусора использует корни для определения, какие объекты в памяти все еще доступны
и могут быть использованы, а какие объекты больше не нужны и могут быть удалены.
GC Root — это набор объектов, которые всегда доступны и служат отправной точкой
для поиска всех достижимых объектов в памяти. Если объект не может быть
достигнут из любого из корней, он считается "мусором" и может быть удален
сборщиком мусора.

Примеры GC Root<br>
Вот несколько примеров объектов, которые считаются GC Root:<br>

- Статические поля
- Активные потоки
- Объекты в локальных переменных
- Объекты класса `java.lang.Runtime`

Как работает сборка мусора?<br>
Сборщик мусора использует алгоритмы для определения достижимости объектов:

1. Начинает с GC Roots: Сборщик начинает с объектов GC Root и проходит по всем
   ссылкам от этих объектов.
2. Обходит граф объектов: Он рекурсивно проверяет все объекты, на которые
   ссылаются корни.
3. Определяет недостижимые объекты: Все объекты, которые не могут быть
   достигнуты из корней, помечаются как "мусор" и подлежат удалению.

Как пометить объект "живым"<br>

Если объект доступен через одну или несколько ссылок, он считается живым (или "
достижимым") и не может быть удален сборщиком мусора. Вот несколько способов,
как можно пометить объект как живой:

1. Создание ссылок на объект<br>
   Чтобы объект считался живым, необходимо создать хотя бы одну ссылку на него.
   Например:

2. Использование коллекций<br>
   Объекты могут быть помечены как живые, если они хранятся в коллекциях, таких
   как списки, множества или карты:

3. Статические поля<br>
   Если объект хранится в статическом поле класса, он также будет считаться
   живым:

4. Передача объектов в методы<br>
   Когда вы передаете объект в метод, он также считается живым, пока метод
   выполняется:

5. Использование внешних библиотек или фреймворков
   Некоторые фреймворки и библиотеки могут управлять жизненным циклом объектов и
   поддерживать ссылки на них для обеспечения их доступности.

Заключение<br>
Объекты в Java считаются "живыми", если на них существуют ссылки из других
объектов или переменных. Чтобы пометить объект как живой, достаточно создать
хотя бы одну ссылку на него — это может быть локальная переменная, элемент
коллекции или статическое поле класса. Как только все ссылки на объект будут
удалены (например, переменные выйдут из области видимости или будут присвоены
null), объект станет недостижимым и может быть удален сборщиком мусора.

GC Root — это ключевая концепция в управлении памятью Java и сборке мусора. Она
определяет начальные точки для поиска достижимых объектов и помогает сборщику
мусора эффективно освобождать память от ненужных объектов.

> Java Collection. HashMap чуть лучше про то как устроен и сложности методов

### **Устройство**

HashMap в Java — это структура данных, которая реализует интерфейс Map и
использует хеш-таблицу для хранения пар "ключ-значение". Она обеспечивает
быстрый доступ к элементам по ключу, что делает её одной из самых популярных
реализаций Map.

**Основные характеристики HashMap**

1. Ключи и значения: HashMap хранит данные в виде пар "ключ-значение". Каждый
   ключ должен быть уникальным, но значения могут повторяться.
2. Неупорядоченность: Элементы в HashMap не имеют определенного порядка. Порядок
   вставки не сохраняется.
3. Допускает null: HashMap позволяет использовать один null в качестве ключа и
   любое количество null в качестве значений.
4. Не синхронизирован: HashMap не является потокобезопасным. Если несколько
   потоков одновременно изменяют его, необходимо использовать внешнюю
   синхронизацию.

**Как работает HashMap**

1. Хеширование<br>
   Когда вы добавляете пару "ключ-значение" в HashMap, ключ проходит через
   хеш-функцию, которая вычисляет хеш-код для этого ключа. Хеш-код — это целое
   число, которое используется для определения индекса (или бакета) в массиве
   (хеш-таблице), где будет храниться значение.

```java
int hash = key.hashCode();
int index = hash % array.length; // Определяем индекс в массиве
```

2. Создание бакета: Если по этому индексу еще нет других элементов, создается
   новый бакет. В Java это обычно реализуется как связный список или дерево.
3. Добавление элементов: Если по этому индексу уже есть элементы (из-за
   коллизий), новая пара "ключ-значение" добавляется в существующий бакет. В
   случае связного списка новый элемент добавляется в конец списка, а если
   используется сбалансированное дерево (например, Red-Black Tree), то элемент
   будет вставлен в соответствующее место дерева.

4. Обработка коллизий<br>
   Когда два ключа имеют одинаковый хеш-код и попадают в один и тот же индекс
   массива, HashMap создает связный список (или дерево) для хранения всех пар "
   ключ-значение", которые имеют одинаковый индекс. HashMap использует метод
   цепочек (chaining) для обработки этих коллизий. В Java 8 и выше, если
   количество элементов в цепочке превышает определенный порог (обычно 8),
   HashMap преобразует связный список в сбалансированное дерево (например,
   Red-Black Tree) для улучшения производительности.

5. Резервирование места<br>
   Когда количество элементов в HashMap превышает определенный порог (обычно 75%
   от текущей емкости), происходит увеличение емкости:
6. Время доступа<br>
   В среднем время доступа к элементам по ключу составляет O(1) благодаря
   использованию хеширования. Однако в худшем случае (например, если все
   элементы попадают в одну цепочку) время доступа может составлять O(n). Чтобы
   избежать этого, важно правильно выбирать размер начального массива и
   коэффициент загрузки.
7. Получение значения по ключу сначала вычисляется его хеш-код. Затем
   определяется индекс массива. Если по этому индексу есть несколько элементов (
   из-за коллизий), HashMap будет перебирать элементы в связанном списке или
   дереве до тех пор, пока не найдет нужный ключ.

**Бакеты**

В контексте HashMap в Java "бакеты" (или "ведра") — это структуры данных,
которые используются для хранения пар "ключ-значение". Бакеты помогают
организовать данные в HashMap и обеспечивают эффективный доступ к ним. Давайте
рассмотрим, как это работает.

**Причины Колизий**

1. Ограниченное количество индексов<br>
2. Хеш-функция<br>
3. Ограниченная длина хеша<br>
4. Сходство ключей<br>

Причины, почему два ключа могут иметь одинаковый хеш-код:<br>

1. **Ограниченное пространство значений**: Хеш-функция преобразует объект в
   целое число (хеш-код), и поскольку количество возможных объектов значительно
   больше, чем количество возможных целых чисел, разные объекты могут быть
   преобразованы в одно и то же значение.
2. **Алгоритм хеширования**: Хеш-функции не идеальны и могут создавать коллизии.
   Например, если два объекта имеют одинаковые значения для всех полей, которые
   участвуют в вычислении хеш-кода, они будут иметь одинаковый хеш-код.
3. **Пользовательские классы**: Если вы создаете собственный класс и
   переопределяете метод `hashCode()`, вы можете случайно создать коллизии, если
   не будете учитывать все важные поля объекта.

### Сложности методов

В среднем, операция добавления, удаления и поиска элемента по ключу в HashMap
имеют
временную сложность O(1).

Проверка наличия значения (containsValue), итерация по элементам - O(n).

Однако, в худшем случае, когда все элементы попадают в
одну корзину, они будут связаны в связный список или дерево, и операция может
занимать время O(n), где n - количество элементов в корзине. Таким образом,
сложность операций в HashMap зависит от количества коллизий и хеш-функции.<br>
В среднем, сложность выборки элемента также составляет O(1), но в худшем случае
может достигать O(n).

> ## Java Collection. Сложность получения последнего элемента в LinkedList (O(1))

## **ARRAYLIST**

**АЛГОРИТМИЧЕСКАЯ СЛОЖНОСТЬ**

1. **Добавление элемента**:

- В конец списка: O(1) в среднем (если массив не переполнен). Если массив
  переполнен, происходит его увеличение, что требует O(n) времени, но это
  происходит редко, поэтому в среднем сложность остается O(1).
- В начало или в произвольную позицию/середину: O(n) (необходимо сдвинуть
  элементы).
- Чтобы вставить элемент в середину списка, необходимо сначала сдвинуть все
  элементы, находящиеся после позиции вставки, на одну позицию вправо. Это
  требует O(n) времени в худшем случае, так как вам нужно пройти по всем
  элементам после вставляемого. После сдвига сам процесс вставки (изменение
  значения по индексу)
  выполняется за O(1). В итоге общая сложность вставки элемента в середину
  списка составляет O(n).

2. **Удаление элемента**:

- Из конца списка: O(1) (если не требуется уменьшение размера массива).
- Из начала или из произвольной позиции/середины: O(n) (необходимо сдвинуть
  элементы).
- Для удаления элемента из середины списка также необходимо сначала найти этот
  элемент (если у вас нет ссылки на него), что требует O(n) времени. После
  нахождения элемента необходимо сдвинуть все элементы, находящиеся после
  удаляемого, на одну позицию влево. Это также требует O(n) времени. Таким
  образом, общая сложность удаления элемента из середины списка составляет O(n).


3. **Поиск элемента**:

- O(n) (в худшем случае необходимо пройти по всему списку).

4. **Доступ к элементу по индексу**:

- O(1) (доступ к элементу по индексу осуществляется за константное время,
  так как `ArrayList` основан на массиве).

Таким образом, `ArrayList` хорошо подходит для операций доступа по индексу и
добавления элементов в конец списка, но менее эффективен для вставки и удаления
элементов в начале или середине списка из-за необходимости сдвига элементов.

Для `ArrayList` в Java сложность вставки и удаления элементов из середины
списка составляет O(n). В общем, операции вставки и удаления в середине
`ArrayList` имеют линейную сложность из-за необходимости сдвига элементов.

## **LINKEDLIST**

LinkedList\<E> является реализацией двусвязного списка для интерфейса List
который работает эффективно как для вставки элементов, так и для удаления,
используя, как издержки, более сложную структуру.

__________________________

### Принцип работы LinkedList

#### Основные операции

1. **Добавление элемента (add)**:
    - При добавлении элемента в конец списка создается новый узел, который
      ссылается на `null` (если это последний элемент).
    - Если список не пустой, новый узел связывается с текущим последним узлом, а
      последний узел обновляется для ссылки на новый узел.
    - Если элемент добавляется в начало или в середину списка, ссылки
      соответствующих узлов обновляются для поддержания связности.

Сложность:

- В LinkedList добавление нового узла в начало или конец списка осуществляется
  за константное время O(1), так как нужно просто изменить ссылки на первый или
  последний элемент.
- Чтобы добавить элемент по индексу, необходимо сначала найти нужный индекс, что
  требует линейного времени O(n). После нахождения нужного узла добавление
  нового узла происходит за O(1).

2. **Удаление элемента (remove)**:
    - При удалении элемента необходимо найти соответствующий узел.
    - После нахождения узла его предыдущий и следующий узлы обновляют свои
      ссылки так, чтобы пропустить удаляемый узел.
    - Если удаляется первый или последний элемент, необходимо обновить указатели
      на голову или хвост списка.

Сложность

- Удаление первого или последнего элемента также выполняется за O(1), так как
  нужно просто изменить ссылки на первый или последний элемент.
  Для удаления элемента по индексу необходимо сначала найти нужный индекс, что
  требует O(n). Удаление узла после его нахождения выполняется за O(1).
- Удаление элемента по значению также требует линейного времени O(n), так как
  нужно пройти через весь список для поиска элемента.

3. **Поиск элемента (get)**:
    - Для поиска элемента по индексу необходимо пройти по списку от начала до
      нужного индекса (или от конца, если индекс ближе к концу).

Сложность

- Сложность поиска составляет O(n) в худшем случае.
- Сложность поиска элемента по значению в LinkedList в Java составляет O(n)
  в худшем и среднем случаях.
- Итерация: В отличие от массивов или ArrayList, где доступ к элементам
  осуществляется за O(1) благодаря прямому индексированию, в LinkedList нет
  такого механизма. Чтобы получить элемент по индексу, необходимо пройти от
  начала списка до нужного индекса.

4. **Итерация**:
    - Итерация по элементам `LinkedList` может быть выполнена с помощью
      итератора или цикла for-each.
    - Итератор позволяет проходить по элементам без необходимости знать
      внутреннюю структуру списка.
    - В LinkedList нет прямого доступа к элементам по индексу, как в массивах
      или ArrayList. Поэтому для поиска элемента по значению необходимо
      последовательно проверять каждый узел.

> ## Отличия ArrayList и LinkedList:

`ArrayList` и `LinkedList` — это две реализации интерфейса `List` в Java, и у
них есть несколько ключевых отличий:

1. **Структура данных**:
    - `ArrayList` основан на массиве. Он использует динамический массив для
      хранения элементов, что позволяет быстро получать доступ к элементам по
      индексу.
    - `LinkedList` основан на связном списке. Каждый элемент (узел) содержит
      ссылку на следующий (и предыдущий) элемент, что позволяет легко добавлять
      и удалять элементы.

2. **Производительность**:
    - **Доступ по индексу**: В `ArrayList` доступ к элементам по индексу
      осуществляется за O(1), так как это просто обращение к массиву. В
      `LinkedList` доступ по индексу требует O(n), так как нужно пройти по
      узлам.
    - **Добавление/удаление элементов**: В `ArrayList` добавление элемента в
      конец списка обычно выполняется за O(1), но может потребовать O(n) в
      случае необходимости увеличения размера массива. Удаление элемента также
      может потребовать O(n) из-за необходимости сдвига элементов. В
      `LinkedList` добавление и удаление элементов (в начале, в конце или в
      середине) выполняется за O(1), если у вас есть ссылка на узел, но поиск
      узла требует O(n).

3. **Память**:
    - `ArrayList` использует меньше памяти на элемент, так как хранит только
      данные и индекс. Однако он может выделять больше памяти, чем фактически
      используется (из-за динамического массива).
    - `LinkedList` использует больше памяти на элемент, так как каждый узел
      хранит ссылки на следующий и предыдущий элементы.

4. **Итерация**:
    - Итерация по элементам в `ArrayList` обычно быстрее из-за лучшей
      локальности данных (элементы хранятся последовательно в памяти).
    - Итерация по `LinkedList` может быть медленнее из-за необходимости перехода
      от одного узла к другому.

5. **Использование**:
    - Используйте `ArrayList`, когда вам нужно часто получать доступ к элементам
      по индексу или когда размер списка не меняется часто.
    - Используйте `LinkedList`, когда вам нужно часто добавлять или удалять
      элементы из середины списка.

В общем, выбор между `ArrayList` и `LinkedList` зависит от конкретных требований
вашего приложения и того, какие операции вы будете выполнять чаще всего.


> ## Java multithreading. ExecutorService

`ExecutorService` в Java — это интерфейс, который является частью пакета
`java.util.concurrent` и предоставляет высокоуровневый механизм для управления
потоками. Он позволяет создавать и управлять пулом потоков, что упрощает
выполнение асинхронных задач и управление многопоточностью.

### Основные характеристики `ExecutorService`

1. **Управление потоками**: `ExecutorService` позволяет вам управлять пулом
   потоков, что означает, что вы можете повторно использовать потоки для
   выполнения нескольких задач, вместо создания нового потока для каждой задачи.
   Это значительно снижает накладные расходы на создание и уничтожение потоков.

2. **Асинхронное выполнение**: Вы можете отправлять задачи на выполнение и
   продолжать выполнять другие операции, не дожидаясь завершения этих задач.

3. **Планирование задач**: `ExecutorService` поддерживает планирование задач с
   использованием методов, таких как `schedule()` (в классе
   `ScheduledExecutorService`), что позволяет выполнять задачи через
   определенные интервалы времени или с задержкой.
4. **Разные типы задач**: Вы можете отправлять как `Runnable`, так и `Callable`
   задачи. `Callable` позволяет возвращать результат и обрабатывать исключения.

5. **Управление жизненным циклом**: `ExecutorService` предоставляет методы для
   управления жизненным циклом пула потоков, такие как `shutdown()` и
   `shutdownNow()`, которые позволяют корректно завершить выполнение задач.

4. **Фабрики для создания экземпляров**: Для создания экземпляров
   `ExecutorService` обычно используются статические методы класса `Executors`,
   такие как:
    - `Executors.newFixedThreadPool(int nThreads)`: создает пул фиксированного
      размера.
    - `Executors.newCachedThreadPool()`: создает пул, который создает новые
      потоки по мере необходимости, но повторно использует ранее созданные
      потоки.
    - `Executors.newSingleThreadExecutor()`: создает пул с одним потоком.

### Основные методы

Вот некоторые ключевые методы интерфейса `ExecutorService`:

- **submit(Callable task)**: Отправляет задачу на выполнение и возвращает объект
  `Future`, который может быть использован для получения результата выполнения
  задачи.

- **submit(Runnable task)**: Отправляет задачу на выполнение и возвращает объект
  `Future`, который не возвращает результат (т.е. результат будет равен null).

- **invokeAll(Collection<? extends Callable<T>> tasks)**: Выполняет список задач
  и возвращает список объектов `Future`, которые представляют результаты
  выполнения этих задач.

- **invokeAny(Collection<? extends Callable<T>> tasks)**: Выполняет список задач
  и возвращает результат первой успешно выполненной задачи.

- **shutdown()**: Инициирует корректное завершение работы пула потоков, не
  принимая новые задачи.

- **shutdownNow()**: Попытка немедленно остановить все активные задачи и вернуть
  список ожидающих задач.

### Что такое задачи?

В контексте `ExecutorService` и многопоточности в Java, под "задачей"
подразумевается единица работы, которую необходимо выполнить. Задачи могут быть
представлены в виде объектов, реализующих интерфейсы `Runnable` или `Callable`.

### Асинхронные задачи

**Асинхронные задачи** — это задачи, которые выполняются независимо от основного
потока выполнения программы. Это означает, что основной поток может продолжать
свою работу, не дожидаясь завершения асинхронной задачи. Асинхронное выполнение
позволяет улучшить отзывчивость приложений, особенно в тех случаях, когда
требуется выполнение длительных операций, таких как сетевые запросы, операции
ввода-вывода или сложные вычисления. Асинхронные задачи могут выполняться в
фоновом режиме, позволяя основному потоку продолжать выполнение других операций.
После завершения асинхронной задачи можно обработать результаты выполнения. В
Java для этого часто используются объекты`Future` и `Callable`, которые
позволяют получить результат выполнения задачи или обработать исключения.
Асинхронные задачи могут быть настроены на выполнение с тайм-аутами или отменой,
что позволяет избежать зависания приложения при выполнении долгих операций.

### Callable

`Callable` — это функциональный интерфейс в Java, представляющий собой
задачу, которая может быть выполнена асинхронно и возвращает результат. Он
является частью пакета `java.util.concurrent` и часто используется в сочетании с
`ExecutorService` для выполнения задач в фоновом режиме.

В отличие от интерфейса `Runnable`, который не
возвращает результат (метод `run()` имеет тип `void`), метод `call()`
интерфейса `Callable` возвращает значение. Это позволяет получать результат
выполнения задачи.

Метод `call()` может выбрасывать проверяемые
исключения (checked exceptions), что позволяет обрабатывать ошибки,
возникающие во время выполнения задачи. В случае с `Runnable`, все исключения
должны обрабатываться внутри метода `run()`.

Когда задача, реализующая интерфейс `Callable`,
отправляется на выполнение через `ExecutorService`, она возвращает объект
типа `Future`. Этот объект позволяет проверять статус выполнения задачи и
получать результат после ее завершения.

### Задачи и потоки

Задачи и потоки в контексте многопоточности в Java тесно связаны между собой,
поскольку задачи представляют собой единицы работы, которые выполняются в
потоках. 

#### 1. **Определение потоков и задач**

- **Поток**: Поток — это отдельная последовательность выполнения в программе.
  Каждый поток имеет свой собственный стек вызовов и может выполняться
  параллельно с другими потоками. В Java потоки создаются с помощью класса
  `Thread` или через интерфейсы, такие как `Runnable` и `Callable`.

- **Задача**: Задача — это конкретная работа или операция, которую нужно
  выполнить. В Java задачи могут быть реализованы через интерфейсы `Runnable` (
  для задач без результата) и `Callable` (для задач с результатом).

#### 2. **Выполнение задач в потоках**

Когда вы отправляете задачу на выполнение в `ExecutorService`, она будет
выполнена в одном из потоков пула потоков. Вот как это работает:

- **Создание пула потоков**: При создании экземпляра `ExecutorService`, вы
  определяете пул потоков, который будет использоваться для выполнения задач.
  Например, с помощью метода `Executors.newFixedThreadPool(n)` создается пул из
  `n` потоков.

- **Отправка задач**: Когда вы отправляете задачу на выполнение (например, через
  метод `submit()`), `ExecutorService` выбирает один из доступных потоков из
  пула для выполнения этой задачи.

- **Асинхронное выполнение**: Задачи могут выполняться асинхронно, что означает,
  что основной поток программы может продолжать выполнение других операций, не
  дожидаясь завершения задачи.

#### 3. **Параллелизм и многопоточность**

Использование задач и потоков позволяет реализовать параллелизм:

- **Параллельное выполнение**: Если у вас есть несколько задач, которые могут
  выполняться одновременно (например, обработка данных или выполнение сетевых
  запросов), вы можете отправить их на выполнение в пул потоков. Пул будет
  распределять задачи между доступными потоками, что позволяет выполнять их
  параллельно.

- **Управление ресурсами**: Пулы потоков помогают управлять ресурсами более
  эффективно. Вместо создания нового потока для каждой задачи (что может быть
  затратным по времени и ресурсам), вы можете повторно использовать существующие
  потоки для выполнения новых задач.

### Future

Объект `Future`, возвращаемый интерфейсом `Callable` в Java, представляет собой
результат асинхронной операции. Он предоставляет методы для проверки состояния
выполнения задачи, получения результата и обработки возможных исключений,
которые могут возникнуть во время выполнения задачи. Давайте рассмотрим основные
аспекты объекта `Future` более подробно.

#### Основные характеристики объекта `Future`

1. **Асинхронный результат**: Объект `Future` позволяет вам получить результат
   выполнения задачи, которая была отправлена на выполнение в пул потоков или
   другой механизм многопоточности. Поскольку задача выполняется асинхронно, вы
   можете продолжать выполнение других операций в основном потоке, не дожидаясь
   завершения задачи.

2. **Методы для управления состоянием**:
    - `isDone()`: Возвращает `true`, если задача завершена (независимо от того,
      была ли она выполнена успешно или завершилась с ошибкой).
    - `isCancelled()`: Возвращает `true`, если задача была отменена до ее
      завершения.
    - `cancel(boolean mayInterruptIfRunning)`: Пытается отменить выполнение
      задачи. Если задача уже выполняется и параметр `mayInterruptIfRunning`
      равен `true`, то выполнение задачи может быть прервано.

3. **Получение результата**:
    - `get()`: Блокирует текущий поток до тех пор, пока задача не завершится, и
      возвращает результат выполнения задачи. Если задача завершилась с
      исключением, метод `get()` выбросит это исключение.
    - `get(long timeout, TimeUnit unit)`: Блокирует текущий поток до тех пор,
      пока задача не завершится или не истечет указанный таймаут.

#### Пример использования объекта Future

Вот пример кода, который демонстрирует использование интерфейса `Callable` и
объекта `Future`:

```java
import java.util.concurrent.Callable;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Future;

public class FutureExample {
    public static void main(String[] args) {
        ExecutorService executor = Executors.newFixedThreadPool(2);

        // Определяем задачу Callable
        Callable<Integer> task = () -> {
            // Имитация длительной операции
            Thread.sleep(2000);
            return 42; // Возвращаем результат
        };

        // Отправляем задачу на выполнение
        Future<Integer> future = executor.submit(task);

        try {
            // Получаем результат выполнения задачи
            Integer result = future.get(); // Это блокирует текущий поток до получения результата
            System.out.println("Результат: " + result);
        } catch (InterruptedException e) {
            System.err.println("Задача была прервана");
        } catch (ExecutionException e) {
            System.err.println("Ошибка при выполнении задачи: " + e.getCause());
        } finally {
            executor.shutdown();
        }
    }
}
```

#### Объяснение примера:

1. **Создание пула потоков**: Мы создаем пул из двух потоков с помощью метода
   `Executors.newFixedThreadPool(2)`.

2. **Определение задачи**: Мы определяем задачу типа `Callable`, которая
   имитирует длительную операцию (например, задержку на 2 секунды) и возвращает
   значение 42.

3. **Отправка задачи**: Мы отправляем задачу на выполнение через метод
   `submit()`, который возвращает объект типа `Future`.

4. **Получение результата**: Мы вызываем метод `get()` у объекта `Future`, чтобы
   получить результат выполнения задачи. Этот вызов блокирует текущий поток до
   тех пор, пока задача не завершится.

5. **Обработка исключений**: Мы обрабатываем возможные исключения:
    - `InterruptedException`: Выбрасывается, если текущий поток был прерван во
      время ожидания результата.
    - `ExecutionException`: Выбрасывается, если задача завершилась с ошибкой; в
      этом случае мы можем получить причину ошибки через метод `getCause()`.

6. **Завершение работы пула**: В конце мы вызываем метод `shutdown()`, чтобы
   корректно завершить работу пула потоков.

#### Заключение

Объект `Future` является важным компонентом многопоточного программирования в
Java, позволяя управлять асинхронными задачами и получать результаты их
выполнения. Он предоставляет удобные методы для проверки состояния задач и
обработки результатов или ошибок, что делает его полезным инструментом для
работы с параллельными вычислениями.

#### Реализации Executor Service

ExecutorService – это интерфейс Java, который предоставляет удобный способ
управления потоками исполнения. Он позволяет создавать пул потоков исполнения и
выполнять задачи в этих потоках.

Существует несколько ключевых реализаций ExecutorService:

ThreadPoolExecutor
ScheduledThreadPoolExecutor
CachedThreadPoolExecutor
ForkJoinPool

#### **ThreadPoolExecutor**

ThreadPoolExecutor – это реализация интерфейса ExecutorService в Java, который
предоставляет пул потоков исполнения для выполнения задач в фоновом режиме.

ThreadPoolExecutor позволяет создать и настроить пул потоков исполнения с
определенным количеством потоков, а также управлять очередью задач. Он может
быть использован для выполнения задач в фоновом режиме, что может улучшить
производительность и реактивность вашего приложения.

#### **ScheduledThreadPoolExecutor**

ScheduledThreadPoolExecutor – это реализация интерфейса ScheduledExecutorService
в Java, который предоставляет пул потоков исполнения для выполнения задач в
определенный момент времени или с определенной периодичностью.

ScheduledThreadPoolExecutor позволяет создать и настроить пул потоков исполнения
с определенным количеством потоков, а также управлять очередью задач. Он может
быть использован для выполнения регулярных задач в фоновом режиме, что может
улучшить производительность и реактивность вашего приложения.

#### **CachedThreadPoolExecutor**

CachedThreadPoolExecutor – это реализация интерфейса ExecutorService в Java,
который предоставляет пул потоков исполнения для выполнения задач в фоновом
режиме.

CachedThreadPoolExecutor автоматически масштабирует количество потоков
исполнения в зависимости от количества задач, которые нужно выполнить. Если
задачи поступают слишком быстро и текущее количество потоков исполнения не может
справиться с ними, CachedThreadPoolExecutor создает новый поток исполнения,
чтобы обеспечить выполнение задачи. Если задачи не поступают достаточно быстро и
текущее количество потоков исполнения избыточно, CachedThreadPoolExecutor
автоматически удаляет потоки исполнения, чтобы уменьшить нагрузку на систему.

#### **ForkJoinPool**

ForkJoinPool – это реализация ExecutorService в Java, которая используется для
параллельного выполнения задач. Эти задачи могут быть разбиты на более мелкие
подзадачи. Она позволяет использовать принцип “разделяй и властвуй” для более
эффективного использования многопроцессорных и многопоточных систем.

_**Основные компоненты ForkJoinPool:**_

**Пул потоков исполнения**

ForkJoinPool управляет пулом потоков исполнения, которые используются для
выполнения задач. Количество потоков исполнения в пуле задается при создании
экземпляра ForkJoinPool. Каждый поток в пуле имеет свой собственный стек
вызовов, что позволяет ForkJoinPool улучшить производительность в случае, когда
задачи могут быть разбиты на более мелкие подзадачи.

**Разбиение и объединение задач:**

ForkJoinPool поддерживает работу с задачами типа RecursiveAction и
RecursiveTask, которые представляют собой рекурсивно делимые задачи без
возвращаемого значения и с возвращаемым значением соответственно. Когда
ForkJoinPool получает задачу типа RecursiveTask, он разбивает ее на более мелкие
подзадачи, выполняет их параллельно в разных потоках и объединяет результаты
выполнения в единую итоговую задачу.





> Java multithreading. Atomic пакет Механизм под капотом (CAS)

В Java термин "atomic" (атомарный) относится к операциям, которые выполняются
как единое целое, без возможности прерывания. Это означает, что такие операции
являются неделимыми: они либо полностью выполняются, либо не выполняются вовсе.
Атомарные операции важны в контексте многопоточности, поскольку они помогают
избежать проблем с синхронизацией и состоянием гонки.

### Основные аспекты атомарности в Java

1. **Атомарные операции**: Атомарные операции гарантируют, что данные не будут
   изменены другими потоками во время выполнения операции. Например, если один
   поток обновляет значение переменной, другой поток не сможет увидеть
   промежуточное состояние этой переменной.

2. **Классы из пакета `java.util.concurrent.atomic`**: Java предоставляет
   несколько классов для работы с атомарными переменными в пакете
   `java.util.concurrent.atomic`. Эти классы обеспечивают атомарные операции над
   примитивными типами данных и объектами. Вот некоторые из них:
    - `AtomicInteger`: Атомарная целочисленная переменная.
    - `AtomicLong`: Атомарная переменная типа `long`.
    - `AtomicBoolean`: Атомарная булева переменная.
    - `AtomicReference<T>`: Атомарная ссылка на объект типа `T`.
    - `AtomicStampedReference<V>`: Атомарная ссылка на объект с меткой (
      стампом), что позволяет избежать проблем с состоянием гонки при обновлении
      ссылок.

3. **Методы атомарных классов**: Классы из пакета `java.util.concurrent.atomic`
   предоставляют методы для выполнения атомарных операций, такие как:
    - `get()`: Получает текущее значение.
    - `set(value)`: Устанавливает новое значение.
    - `incrementAndGet()`: Увеличивает текущее значение на 1 и возвращает новое
      значение.
    - `compareAndSet(expectedValue, newValue)`: Сравнивает текущее значение с
      ожидаемым значением и устанавливает новое значение, если они равны.

### Пример использования атомарных переменных

Вот пример кода, который демонстрирует использование класса `AtomicInteger`:

```java
import java.util.concurrent.atomic.AtomicInteger;

public class AtomicExample {
    public static void main(String[] args) {
        AtomicInteger atomicCounter = new AtomicInteger(0);

        // Создаем несколько потоков для увеличения счетчика
        Thread thread1 = new Thread(() -> {
            for (int i = 0; i < 1000; i++) {
                atomicCounter.incrementAndGet(); // Атомарное увеличение
            }
        });

        Thread thread2 = new Thread(() -> {
            for (int i = 0; i < 1000; i++) {
                atomicCounter.incrementAndGet(); // Атомарное увеличение
            }
        });

        // Запускаем потоки
        thread1.start();
        thread2.start();

        // Ждем завершения потоков
        try {
            thread1.join();
            thread2.join();
        } catch (InterruptedException e) {
            e.printStackTrace();
        }

        // Выводим итоговое значение счетчика
        System.out.println("Итоговое значение счетчика: " + atomicCounter.get());
    }
}
```

### Объяснение примера:

1. **Создание атомарного счетчика**: Мы создаем экземпляр класса
   `AtomicInteger`, инициализируя его значением 0.

2. **Создание потоков**: Мы создаем два потока, каждый из которых увеличивает
   счетчик на 1000 раз с помощью метода `incrementAndGet()`, который выполняет
   атомарное увеличение.

3. **Запуск потоков**: Мы запускаем оба потока.

4. **Ожидание завершения потоков**: Мы используем метод `join()` для ожидания
   завершения обоих потоков.

5. **Вывод результата**: После завершения работы потоков мы выводим итоговое
   значение счетчика. Поскольку мы использовали атомарную переменную, итоговое
   значение будет равно 2000, независимо от порядка выполнения потоков.

### Заключение

Атомарные операции и классы в Java обеспечивают безопасный доступ к общим данным
в многопоточной среде без необходимости использования явной синхронизации (
например, через блокировки). Это делает код более простым и эффективным при
работе с конкурентными задачами. Однако важно помнить, что атомарность не
гарантирует полной безопасности при работе с более сложными структурами данных
или логикой — в таких случаях может потребоваться дополнительная синхронизация.

### CAS

В Java "CAS" (Compare-And-Swap) — это атомарная операция, которая используется
для реализации механизмов синхронизации и управления состоянием в многопоточной
среде. CAS позволяет безопасно обновлять значение переменной, проверяя, равно ли
текущее значение ожидаемому значению, и только в этом случае заменяя его на
новое значение. Это делает CAS полезным для реализации неблокирующих алгоритмов
и структур данных.

#### Как работает CAS

Операция CAS включает три параметра:

1. **Адрес переменной**: Адрес (или ссылка) на переменную, которую мы хотим
   обновить.
2. **Ожидаемое значение**: Значение, с которым мы сравниваем текущее значение
   переменной.
3. **Новое значение**: Значение, которое мы хотим установить, если текущее
   значение совпадает с ожидаемым.

Процесс работы CAS можно описать следующим образом:

1. Сравнить текущее значение переменной с ожидаемым значением.
2. Если они равны, обновить переменную новым значением.
3. Если они не равны, операция завершается без изменений.

#### Пример использования CAS в Java

Java предоставляет поддержку CAS через классы из пакета
`java.util.concurrent.atomic`, такие как `AtomicInteger`, `AtomicBoolean`,
`AtomicReference` и другие. Эти классы используют внутренние механизмы CAS для
выполнения атомарных операций.

Вот пример использования `AtomicInteger` с методом `compareAndSet()`:

```java
import java.util.concurrent.atomic.AtomicInteger;

public class AtomicCASExample {
    public static void main(String[] args) {
        AtomicInteger atomicCounter = new AtomicInteger(0);

        // Создаем несколько потоков для увеличения счетчика
        Thread thread1 = new Thread(() -> {
            for (int i = 0; i < 1000; i++) {
                int currentValue;
                do {
                    currentValue = atomicCounter.get();
                } while (!atomicCounter.compareAndSet(currentValue, currentValue + 1));
            }
        });

        Thread thread2 = new Thread(() -> {
            for (int i = 0; i < 1000; i++) {
                int currentValue;
                do {
                    currentValue = atomicCounter.get();
                } while (!atomicCounter.compareAndSet(currentValue, currentValue + 1));
            }
        });

        // Запускаем потоки
        thread1.start();
        thread2.start();

        // Ждем завершения потоков
        try {
            thread1.join();
            thread2.join();
        } catch (InterruptedException e) {
            e.printStackTrace();
        }

        // Выводим итоговое значение счетчика
        System.out.println("Итоговое значение счетчика: " + atomicCounter.get());
    }
}
```

#### Объяснение примера:

1. **Создание атомарного счетчика**: Мы создаем экземпляр класса
   `AtomicInteger`, инициализируя его значением 0.

2. **Создание потоков**: Мы создаем два потока, каждый из которых пытается
   увеличить счетчик на 1000 раз.

3. **Использование CAS**:
    - В каждом потоке мы используем цикл `do-while`, чтобы попытаться получить
      текущее значение счетчика.
    - Затем мы вызываем метод `compareAndSet(currentValue, currentValue + 1)`.
      Этот метод проверяет, равно ли текущее значение счетчика (
      `atomicCounter.get()`) ожидаемому значению (`currentValue`). Если да, то
      он устанавливает новое значение (`currentValue + 1`). Если нет — операция
      завершается без изменений, и цикл повторяется.

4. **Запуск потоков**: Мы запускаем оба потока.

5. **Ожидание завершения потоков**: Мы используем метод `join()` для ожидания
   завершения обоих потоков.

6. **Вывод результата**: После завершения работы потоков мы выводим итоговое
   значение счетчика. Поскольку мы использовали атомарную переменную с
   CAS-операцией, итоговое значение будет равно 2000.

### Преимущества и недостатки CAS

#### Преимущества:

- **Без блокировок**: CAS позволяет избежать использования блокировок (например,
  synchronized), что может улучшить производительность в многопоточных
  приложениях.
- **Простота реализации**: Многие алгоритмы могут быть реализованы проще с
  использованием CAS.

#### Недостатки:

- **Проблема "проверка-замена"**: Если несколько потоков одновременно пытаются
  обновить одно и то же значение, это может привести к частым неудачным попыткам
  обновления (потоки будут повторять операции), что может снизить
  производительность.
- **Необходимость повторных попыток**: В некоторых случаях может потребоваться
  много итераций для успешного выполнения операции из-за состояния гонки между
  потоками.

### Заключение

CAS является мощным инструментом для реализации неблокирующих алгоритмов и
структур данных в Java. Он позволяет безопасно обновлять значения переменных в
многопоточной среде без необходимости использования явных блокировок, что делает
код более эффективным и простым в понимании. Однако важно учитывать возможные
проблемы с производительностью при высокой конкуренции за ресурсы.




> Spring. Scope бинов чуть лучше



В Spring Framework "scope" (область видимости) бинов определяет, как и когда
создаются экземпляры бинов, а также как они управляются контейнером Spring.
Области видимости позволяют контролировать жизненный цикл бинов и их доступность
в приложении. В Spring есть несколько основных областей видимости бинов:

### 1. Singleton (по умолчанию)

- **Описание**: В этой области видимости контейнер Spring создает только один
  экземпляр бина на весь контекст приложения. Этот экземпляр будет
  использоваться для всех запросов к этому бину. Этот экземпляр помещается в кэш
  таких же бинов (синглтонов) и все последующие вызовы бина с таким именем будут
  возвращать объект из кэша.
- **Жизненный цикл**: Бин создается при старте приложения и уничтожается при
  завершении работы приложения.
- **Пример**:
  ```java
  @Component
  public class MySingletonBean {
      // ...
  }
  ```

### 2. Prototype

- **Описание**: При этой области видимости каждый запрос к контейнеру Spring
  создает новый экземпляр бина. Это означает, что каждый раз, когда вы
  запрашиваете бин, вы получаете новый объект.
- **Жизненный цикл**: Бин создается при каждом запросе и уничтожается, когда на
  него больше нет ссылок (сборщик мусора).
- **Пример**:
  ```java
  @Component
  @Scope("prototype")
  public class MyPrototypeBean {
      // ...
  }
  ```

### 3. Request

- **Описание**: Эта область видимости используется в веб-приложениях. Бин
  создается для каждого HTTP-запроса и уничтожается по завершении обработки
  этого запроса.
- **Жизненный цикл**: Бин существует только в течение одного HTTP-запроса.
- **Пример**:
  ```java
  @Component
  @Scope("request")
  public class MyRequestBean {
      // ...
  }
  ```

### 4. Session

- **Описание**: Также используется в веб-приложениях. Бин создается для каждой
  HTTP-сессии и уничтожается, когда сессия завершается. Это полезно для хранения
  информации, специфичной для пользователя, в течение всего времени его сессии.
- **Жизненный цикл**: Бин существует в течение одной HTTP-сессии.
- **Пример**:
  ```java
  @Component
  @Scope("session")
  public class MySessionBean {
      // ...
  }
  ```

### 5. Global Session/Application

- **Описание**: Application: Бин с данной областью видимости создается один раз
  для всего сервлет-контекста. Это полезно для данных, которые должны быть
  общими для всех пользователей и сессий в приложении.
- **Жизненный цикл**: Бин существует в течение глобальной сессии.
- **Пример**:
  ```java
  @Component
  @Scope("globalSession")
  public class MyGlobalSessionBean {
      // ...
  }
  ```

### 6. WebSocket

Бин с данной областью видимости создается для каждой сессии WebSocket. Это
полезно для работы с данными, специфичными для каждой WebSocket-сессии.

### Применение области видимости

Чтобы задать область видимости для бина, можно использовать аннотацию `@Scope`
вместе с аннотацией `@Component`, `@Service`, `@Repository` или `@Controller`.
Например:

```java
import org.springframework.context.annotation.Scope;
import org.springframework.stereotype.Component;

@Component
@Scope("prototype")
public class MyPrototypeBean {
    // ...
}
```

### Примечания

1. По умолчанию все бины имеют область видимости "singleton", если не указано
   иное.
2. Области видимости "request", "session" и "globalSession" могут использоваться
   только в контексте веб-приложений (например, при использовании Spring MVC).
3. Для использования областей видимости "request" и "session" необходимо
   убедиться, что приложение настроено как веб-приложение.

### Заключение

Области видимости бинов в Spring позволяют гибко управлять жизненным циклом
объектов и их доступностью в приложении. Понимание этих областей помогает
разработчикам правильно проектировать архитектуру приложения и эффективно
управлять ресурсами.

> ## Жизненный цикл бинов

В контексте Java и, в частности, фреймворка Spring, жизненный цикл бинов (или
компонентов) описывает последовательность этапов, через которые проходит бин от
его создания до уничтожения. Понимание этого жизненного цикла важно для
правильного управления ресурсами и поведения ваших компонентов. Давайте
рассмотрим основные этапы жизненного цикла бинов в Spring.

### 1. Создание бина

- **Инстанцирование**: Когда Spring контейнер создает бин, он использует
  конструктор класса для создания его экземпляра. Это может быть стандартный
  конструктор или конструктор с параметрами, если используется внедрение
  зависимостей.

### 2. Внедрение зависимостей

- **Внедрение зависимостей**: После создания бина Spring инжектирует все
  необходимые зависимости (например, другие бины или конфигурационные параметры)
  в созданный объект. Это может происходить через конструкторы, сеттеры или
  поля (в зависимости от конфигурации).

### 3. Инициализация

- **Методы инициализации**: После внедрения зависимостей Spring вызывает методы
  инициализации, если они определены. Это может быть:
    - Метод с аннотацией `@PostConstruct`, который будет вызван после завершения
      инъекции зависимостей.
    - Метод, указанный в атрибуте `init-method` в XML-конфигурации.

Пример использования `@PostConstruct`:

```java

@Component
public class MyBean {

    @PostConstruct
    public void init() {
        // Логика инициализации
    }
}
```

### 4. Использование

- **Использование бина**: На этом этапе бин готов к использованию в приложении.
  Он может обрабатывать запросы, выполнять бизнес-логику и взаимодействовать с
  другими компонентами.

### 5. Уничтожение

- **Методы уничтожения**: Когда контейнер Spring закрывается или бин больше не
  нужен, он проходит процесс уничтожения. На этом этапе могут быть вызваны
  методы для освобождения ресурсов или выполнения завершающих действий:
    - Метод с аннотацией `@PreDestroy`, который будет вызван перед уничтожением
      бина.
    - Метод, указанный в атрибуте `destroy-method` в XML-конфигурации.

Пример использования `@PreDestroy`:

```java

@Component
public class MyBean {

    @PreDestroy
    public void cleanup() {
        // Логика освобождения ресурсов
    }
}
```

### Полный жизненный цикл бина

1. **Создание**: Инстанцирование бина.
2. **Внедрение зависимостей**: Инъекция необходимых зависимостей.
3. **Инициализация**: Вызов методов инициализации.
4. **Использование**: Бин готов к использованию.
5. **Уничтожение**: Вызов методов для освобождения ресурсов перед уничтожением.

### Заключение

Понимание жизненного цикла бинов в Spring позволяет разработчикам эффективно
управлять ресурсами и поведением своих компонентов. Знание о том, когда
происходят различные этапы жизненного цикла, помогает избежать утечек памяти и
других проблем с производительностью приложения.



> Hibernate. Проблема n+1

Проблема N+1 в Hibernate (и в других ORM, таких как JPA) — это распространенная
проблема производительности, которая возникает при выполнении запросов к базе
данных. Она связана с тем, как ORM загружает связанные сущности.

## ЧТО ТАКОЕ ПРОБЛЕМА N+1?

Проблема N+1 возникает, когда для загрузки коллекции связанных сущностей
выполняется один запрос для основной сущности и затем отдельный запрос для
каждой из связанных сущностей. Это может привести к значительному увеличению
количества запросов к базе данных, что негативно сказывается на
производительности приложения.

### Пример

Предположим, у вас есть две сущности: `Author` и `Book`, где один автор может
иметь много книг. Если вы хотите получить список всех авторов и их книг, вы
можете написать следующий код:

```java
class Demo {
    public void demo() {
        List<Author> authors = session
                .createQuery("FROM Author", Author.class)
                .getResultList();
        for (Author author : authors) {
            System.out.println(author.getName());
            for (Book book : author.getBooks()) {
                System.out.println(book.getTitle());
            }
        }
    }
}

```

В этом примере происходит следующее:

1. Выполняется один запрос для получения всех авторов (это 1 запрос).
2. Для каждого автора выполняется отдельный запрос для получения его книг (это N
   запросов, где N — количество авторов).

Таким образом, общее количество запросов к базе данных составляет 1 + N, что и
приводит к проблеме N+1.

## ПОЧЕМУ ЭТО ПРОБЛЕМА?

Проблема N+1 может значительно ухудшить производительность приложения по
следующим причинам:

- **Увеличение времени выполнения**: Каждый дополнительный запрос требует
  времени на выполнение и обработку.
- **Нагрузка на базу данных**: Большое количество запросов может привести к
  увеличению нагрузки на базу данных и ухудшению ее производительности.
- **Сложность отладки**: Увеличение количества запросов может затруднить отладку
  и анализ производительности приложения.

## ПРИЧИНЫ ВОЗНИКНОВЕНИЯ

1. **Ленивая загрузка (Lazy Loading) по умолчанию**  
   По умолчанию многие ассоциации в Hibernate (например, `@OneToMany`,
   `@ManyToOne`) настроены на ленивую загрузку (`FetchType.LAZY`). Это значит,
   что связанные объекты не загружаются сразу вместе с основным объектом, а
   подгружаются при первом обращении к ним. Если в коде происходит итерация по
   коллекции связанных объектов, то для каждого из них Hibernate выполнит
   отдельный SQL-запрос.

2. **Отсутствие явного указания жадной загрузки (Eager Fetching)**  
   Если не использовать `FetchType.EAGER` или не применять `JOIN FETCH` в
   JPQL/HQL-запросах, Hibernate не будет загружать связанные сущности одним
   запросом с использованием JOIN.

3. **Использование коллекций с ленивой загрузкой без оптимизации**  
   При работе с коллекциями (`List`, `Set`) связанных сущностей без применения
   специальных техник (например, batch fetching или fetch join) каждый элемент
   коллекции может быть загружен отдельным запросом.

4. **Отсутствие batch fetching**  
   Batch fetching — это механизм Hibernate, который позволяет загружать
   несколько связанных сущностей одним запросом с помощью IN-подобных
   конструкций. Если он не настроен или не используется, то для каждой связанной
   сущности будет отдельный запрос.

5. **Неправильное использование ORM-запросов**  
   Например, если в цикле выполняется обращение к связанным объектам без
   предварительной выборки через JOIN FETCH, то каждый вызов приведёт к
   отдельному SQL-запросу.

### Кратко:

| Причина                          | Описание                                                                                 |
|----------------------------------|------------------------------------------------------------------------------------------|
| Ленивый fetch (`FetchType.LAZY`) | Связанные объекты загружаются по требованию, что приводит к множеству отдельных запросов |
| Отсутствие `JOIN FETCH`          | Запросы без join fetch не объединяют выборку связанных сущностей                         |
| Отсутствие batch fetching        | Нет групповой подгрузки связанных объектов                                               |
| Итерация по ленивым коллекциям   | При обходе коллекций происходит множество отдельных запросов                             |

## Как исправить проблемы N+1?

Проблему **N+1** в Hibernate можно исправить несколькими способами, в
зависимости от конкретного сценария и требований к производительности. Ниже
перечислены основные подходы с примерами.

1. Использовать `JOIN FETCH` в JPQL/HQL-запросах

Это самый распространённый способ загрузить связанные сущности одним запросом с
помощью SQL JOIN.

**Пример:**

```java

class Demo() {
    void demo() {
        // Без JOIN FETCH — возникнет N+1
        List<Author> authors = entityManager.createQuery("SELECT a FROM Author a", Author.class).getResultList();

        for (
                Author author : authors) {
            // При обращении к author.getBooks() будет отдельный запрос для каждой книги
            System.out.

                    println(author.getBooks().

                            size());
        }

// С JOIN FETCH — все книги загружаются вместе с авторами одним запросом
        List<Author> authors = entityManager.createQuery(
                "SELECT a FROM Author a JOIN FETCH a.books", Author.class).getResultList();
    }
}

```

2. Настроить batch fetching (пакетную загрузку)

Batch fetching позволяет Hibernate загружать связанные сущности пакетами, а не
по одной.

**Настройка в `hibernate.cfg.xml` или `application.properties`:**

```properties
hibernate.default_batch_fetch_size=16
```

**Аннотация на коллекции или связях:**

```java

@OneToMany(fetch = FetchType.LAZY)
@BatchSize(size = 16)
private Set<Book> books;
```

Hibernate при обращении к коллекции загрузит сразу 16 связанных объектов одним
запросом с `IN (...)`.

3. Использовать жадную загрузку (`FetchType.EAGER`)

Можно указать, что связанные сущности должны загружаться сразу вместе с основной
сущностью.

```java

@OneToMany(fetch = FetchType.EAGER)
private Set<Book> books;
```

**Однако:**  
Жадная загрузка может привести к избыточной выборке данных и ухудшению
производительности, если связи большие или не всегда нужны.

4. Использовать Entity Graphs (JPA 2.1+)

Entity Graph позволяет динамически указывать, какие связи нужно подгружать.

```java
EntityGraph<Author> graph = entityManager.createEntityGraph(Author.class);
graph.

addAttributeNodes("books");

Map<String, Object> props = new HashMap<>();
props.

put("javax.persistence.fetchgraph",graph);

Author author = entityManager.find(Author.class, authorId, props);
```

5. Оптимизировать структуру запросов и логику приложения

- Избегать обращения к ленивым коллекциям в циклах без предварительной выборки.
- Загружать данные пакетами.
- Использовать DTO и проекции для выборки только нужных данных.

Итог

| Способ                    | Когда использовать                                  | Преимущества                  | Недостатки                          |
|---------------------------|-----------------------------------------------------|-------------------------------|-------------------------------------|
| `JOIN FETCH`              | При необходимости загрузить связанные объекты сразу | Один запрос вместо N+1        | Может привести к дублированию строк |
| Batch fetching            | При работе с большими коллекциями                   | Уменьшает количество запросов | Требует настройки и понимания       |
| Жадная загрузка (`EAGER`) | Когда всегда нужны связанные данные                 | Простота использования        | Может грузить лишние данные         |
| Entity Graphs             | Для динамического управления загрузкой              | Гибкость                      | Сложнее в настройке                 |

> HIBERNATE. ENTITY GRAPHS

Entity Graphs (графы сущностей) — это механизм в JPA (Java Persistence API),
который позволяет разработчикам управлять загрузкой связанных сущностей более
гибко и эффективно. С помощью графов сущностей можно указать, какие связанные
объекты должны быть загружены вместе с основной сущностью, что помогает избежать
проблемы N+1 и оптимизировать производительность запросов.

### Основные характеристики Entity Graphs:

1. **Определение графа:** Граф сущностей определяет, какие атрибуты (сущности)
   должны быть загружены при выполнении запроса. Это позволяет вам
   контролировать стратегию выборки данных.

2. **Динамическое создание:** Графы могут быть созданы динамически в коде или
   определены статически с помощью аннотаций.

3. **Поддержка различных стратегий загрузки:** Вы можете использовать графы для
   указания, какие связанные сущности должны быть загружены с использованием
   `FetchType.EAGER` или `FetchType.LAZY`, в зависимости от ваших потребностей.

## ПРИМЕР

Есть две сущности: `Author` и `Book`. У автора может быть много книг.

```java

@Entity
public class Author {
    @Id
    private Long id;

    private String name;

    @OneToMany(mappedBy = "author", fetch = FetchType.LAZY)
    private List<Book> books;

    // геттеры и сеттеры
}

@Entity
public class Book {
    @Id
    private Long id;

    private String title;

    @ManyToOne(fetch = FetchType.LAZY)
    private Author author;

    // геттеры и сеттеры
}
```

### Проблема N+1

Если вы просто сделаете:

```java
class Demo {
    void demo() {
        List<Author> authors = entityManager
                .createQuery("SELECT a FROM Author a", Author.class)
                .getResultList();
        for (Author author : authors) {
            System.out.println(
                    author.getBooks()
                            .size()
            );  // тут будет отдельный запрос на каждую коллекцию books!
        }
    }
}

```

Hibernate выполнит 1 запрос на авторов + N запросов на книги каждого автора —
это и есть проблема N+1.

### Решение с Entity Graph

Создадим Entity Graph, который укажет JPA подгрузить книги вместе с авторами:

```java
class Demo {
    void demo() {
        EntityGraph<Author> graph = entityManager.createEntityGraph(Author.class);
        graph.addAttributeNodes("books");
    }
}
```

Теперь используем этот граф при выполнении запроса:

```java
class Demo {
    void demo() {
        List<Author> authors = entityManager
                .createQuery("SELECT a FROM Author a", Author.class)
                .setHint("javax.persistence.fetchgraph", graph)
                .getResultList();
        for (Author author : authors) {
            System.out
                    .println(author.getBooks()
                            .size());  // книги уже загружены одним запросом!
        }
    }
}
```

### Что происходит?

- JPA подставляет в SQL `JOIN` для связи `books`.
- Все данные загружаются одним запросом.
- При обращении к `author.getBooks()` дополнительных запросов не будет.


1. Определение графа с помощью аннотаций

Вы можете определить граф сущностей с помощью аннотации `@EntityGraph` на уровне
класса или метода репозитория:

```java

@Entity
@NamedEntityGraph(name = "Author.books",
        attributePaths = {"books"})
public class Author {
    @Id
    private Long id;

    @OneToMany(mappedBy = "author")
    private Set<Book> books;
}
```

2. Использование графа в запросе

Затем вы можете использовать этот граф при выполнении запроса:

```java
class Demo {
    void demo() {
        EntityGraph entityGraph = entityManager.getEntityGraph("Author.books");
        Map<String, Object> properties = new HashMap<>();
        properties.put("javax.persistence.fetchgraph", entityGraph);
        Author author = entityManager.find(Author.class, authorId, properties);
    }
}
```

3. Динамическое создание графа

Вы также можете создавать графы динамически в коде:

```java

class Demo {
    void demo() {
        EntityGraph graph = entityManager.createEntityGraph(Author.class);
        graph.addAttributeNodes("books");
        Map<String, Object> hints = new HashMap<>();
        hints.put("javax.persistence.fetchgraph", graph);
        List<Author> authors = entityManager
                .createQuery("SELECT a FROM Author a", Author.class)
                .setHint("javax.persistence.fetchgraph", graph)
                .getResultList();
    }
}
```

### Преимущества использования Entity Graphs

- **Гибкость:** Позволяют динамически управлять тем, какие данные загружаются.
- **Улучшение производительности:** Помогают избежать проблемы N+1 и избыточных
  запросов к базе данных.
- **Читаемость кода:** Упрощают понимание того, какие данные будут загружены при
  выполнении запроса.

Использование Entity Graphs — это мощный инструмент для оптимизации работы с JPA
и управления загрузкой связанных данных в приложениях на Java.



> ## Жадная загрузка

**Жадная загрузка (Eager Loading)** — это стратегия загрузки связанных данных,
при которой связанные сущности загружаются **сразу вместе с основной сущностью**
в момент выполнения запроса к базе данных.

### Что это значит?

Если у вас есть, например, сущность `Author` и связанная с ней коллекция
`books`, то при жадной загрузке:

- Когда вы загружаете автора из базы, сразу же подгружаются и все его книги.
- Это обычно реализуется через SQL JOIN или дополнительные запросы, которые
  выполняются сразу.

### Пример

```java

@Entity
public class Author {
    @OneToMany(fetch = FetchType.EAGER)
    private List<Book> books;
}
```

При таком объявлении, когда вы получите автора из базы, Hibernate сразу же
загрузит и все связанные книги.

### Плюсы жадной загрузки

- Избегает проблему N+1 запросов, если вам точно нужны связанные данные.
- Удобно, когда вы всегда используете связанные объекты вместе с основной
  сущностью.

### Минусы жадной загрузки

- Может привести к избыточной нагрузке на базу и сети, если связанные данные не
  нужны.
- При большом количестве связанных объектов может сильно замедлить запрос.

### В противоположность — **ленивая загрузка (Lazy Loading)**

- Связанные данные загружаются только при первом обращении к ним.
- Позволяет экономить ресурсы, но может вызвать проблему N+1 запросов.

### Итог

**Жадная загрузка** — это когда связанные объекты подгружаются сразу вместе с
основной сущностью, чтобы избежать дополнительных запросов позже. Это удобно для
часто используемых связей, но может быть неэффективно при больших объемах
данных.


> ## Criteria api

**Criteria API** — это часть спецификации JPA (Java Persistence API), которая
предоставляет типобезопасный, объектно-ориентированный способ построения
динамических запросов к базе данных.

### Основные особенности Criteria API:

- **Типобезопасность**  
  Запросы строятся с помощью Java-кода, а не строк JPQL, что позволяет избежать
  ошибок в синтаксисе и типах на этапе компиляции.

- **Динамическое построение запросов**  
  Удобно создавать запросы с условиями, которые зависят от логики приложения (
  например, если параметры фильтрации могут меняться).

- **Объектно-ориентированный подход**  
  Запросы строятся через объекты `CriteriaBuilder`, `CriteriaQuery`, `Root` и
  т.д., что облегчает чтение и поддержку кода.

### Пример использования Criteria API

```java
CriteriaBuilder cb = entityManager.getCriteriaBuilder();
CriteriaQuery<Author> cq = cb.createQuery(Author.class);
Root<Author> author = cq.from(Author.class);

cq.

select(author)
  .

where(cb.like(author.get("name"), "Иван%"));

List<Author> authors = entityManager.createQuery(cq).getResultList();
```

### Когда использовать Criteria API?

- Когда нужно строить сложные или динамические запросы.
- Когда важна типобезопасность и удобство поддержки кода.
- В случаях, когда использование строковых JPQL-запросов неудобно или
  рискованно.

### Кратко

**Criteria API** — это инструмент для программного построения запросов к базе
данных в JPA, который помогает создавать гибкие, безопасные и удобочитаемые
запросы без использования строковых выражений.

### Пример кода с Criteria API

Допустим, у нас есть сущность `Author` с полями `id`, `name` и связью `books` (
список книг). Мы хотим получить всех авторов с именем, начинающимся на "Иван".

```java
import javax.persistence.criteria.CriteriaBuilder;
import javax.persistence.criteria.CriteriaQuery;
import javax.persistence.criteria.Root;
import javax.persistence.EntityManager;
import java.util.List;

public List<Author> findAuthorsByNamePrefix(EntityManager entityManager, String prefix) {
    // Получаем объект CriteriaBuilder из EntityManager
    CriteriaBuilder cb = entityManager.getCriteriaBuilder();

    // Создаем запрос для сущности Author
    CriteriaQuery<Author> cq = cb.createQuery(Author.class);

    // Определяем корень запроса (FROM Author a)
    Root<Author> authorRoot = cq.from(Author.class);

    // Добавляем условие WHERE a.name LIKE 'prefix%'
    cq.select(authorRoot)
            .where(cb.like(authorRoot.get("name"), prefix + "%"));

    // Выполняем запрос и получаем результат
    List<Author> authors = entityManager.createQuery(cq).getResultList();

    return authors;
}
```

### Объяснение:

- `CriteriaBuilder` — фабрика для создания частей запроса.
- `CriteriaQuery<T>` — сам запрос, где `T` — тип результата.
- `Root<T>` — корень запроса, указывает на основную сущность.
- Метод `cb.like()` создаёт условие LIKE.
- В итоге мы получаем список авторов, чьё имя начинается с заданного префикса.

### Как использовать вместе с Entity Graph?

Можно комбинировать Criteria API и Entity Graph:

```java
EntityGraph<Author> graph = entityManager.createEntityGraph(Author.class);
graph.

addAttributeNodes("books");

List<Author> authors = entityManager.createQuery(cq)
        .setHint("javax.persistence.fetchgraph", graph)
        .getResultList();
```

Так вы получите авторов с подгруженными книгами в одном запросе.


> ## EntityManager

**EntityManager** — это основной интерфейс в JPA (Java Persistence API), который
отвечает за взаимодействие с базой данных и управляет жизненным циклом
сущностей.

### Основные функции EntityManager:

- **Создание, чтение, обновление и удаление (CRUD) сущностей**  
  Например, сохранение нового объекта в базу или получение объекта по его
  идентификатору.

- **Управление состоянием сущностей**  
  Сущности могут быть в разных состояниях: новые, управляемые (attached),
  отсоединённые (detached), удалённые. EntityManager следит за этими
  состояниями.

- **Выполнение запросов к базе данных**  
  Через JPQL (Java Persistence Query Language) или Criteria API.

- **Транзакционное управление**  
  Обычно EntityManager работает внутри транзакций, обеспечивая атомарность
  операций.

### Пример использования EntityManager:

```java

class Demo {
    void demo() {
        // Получение сущности по ID
        Author author = entityManager.find(Author.class, 1L);

        // Создание новой сущности
        Author newAuthor = new Author();
        newAuthor.setName("Иван Иванов").entityManager.persist(newAuthor);

        // Обновление сущности
        author.setName("Пётр Петров");
        entityManager.merge(author);

        // Удаление сущности
        entityManager.remove(author);
    }
}
```

### Где берётся EntityManager?

- В Java EE / Jakarta EE контейнере его обычно внедряют через
  `@PersistenceContext`.
- В Spring Boot можно получить через `@Autowired` или использовать
  `EntityManagerFactory`.

### Кратко

EntityManager — это объект, который позволяет работать с базой данных на уровне
объектов (сущностей), управлять их состояниями и выполнять запросы. Это основной
инструмент для работы с JPA.




> Hibernate. Уровни кеширования в Hibernate лучше изучить

Hibernate предоставляет несколько уровней кеширования, которые помогают
оптимизировать производительность приложения, уменьшая количество обращений к
базе данных.

### 1. Первичный кеш (First-Level Cache)

- **Описание:** Это кэш, который связан с сессией Hibernate. Он хранит объекты,
  загруженные в рамках текущей сессии.
- **Область видимости:** Действует только в пределах одной сессии. Когда сессия
  закрывается, все данные в первичном кэше теряются.
- **Применение:** Если вы запрашиваете одну и ту же сущность несколько раз в
  рамках одной сессии, Hibernate будет возвращать объект из первичного кэша
  вместо выполнения нового запроса к базе данных.

- **Описание**: Первичный кеш является неотъемлемой частью сессии Hibernate. Он
  хранит объекты, загруженные в текущей сессии, и обеспечивает их повторное
  использование без необходимости повторного запроса к базе данных.
- **Область видимости**: Первичный кеш существует только в пределах одной
  сессии. Как только сессия закрывается, все объекты в первичном кеше становятся
  недоступными.
- **Поведение**: Если вы запрашиваете один и тот же объект несколько раз в
  рамках одной сессии, Hibernate будет возвращать его из первичного кеша вместо
  того, чтобы выполнять новый запрос к базе данных.
- **Пример**:
  ```java
  Session session = sessionFactory.openSession();
  Author author1 = session.get(Author.class, 1); // Запрос к БД
  Author author2 = session.get(Author.class, 1); // Возвращается из первичного кеша
  ```

### 2. Вторичный кеш (Second-Level Cache)

- **Описание:** Это опциональный кэш, который может быть настроен для хранения
  объектов между сессиями. Он позволяет делиться данными между разными сессиями.
- **Область видимости:** Действует на уровне сессии-фабрики (SessionFactory).
  Данные остаются в этом кэше даже после закрытия сессий.
- **Применение:** Вторичный кэш может быть использован для хранения часто
  запрашиваемых сущностей или коллекций, что позволяет уменьшить количество
  запросов к базе данных.
- **Описание**: Вторичный кеш является опциональным и может быть настроен для
  хранения объектов между сессиями. Он позволяет кэшировать данные на уровне
  всей сессии фабрики (SessionFactory), что позволяет использовать одни и те же
  данные в разных сессиях.
- **Область видимости**: Вторичный кеш доступен для всех сессий, использующих
  одну и ту же фабрику сессий.
- **Настройка**: Для использования второго уровня кеша необходимо включить его в
  конфигурации Hibernate и выбрать провайдер кеша (например, Ehcache, Infinispan
  и т.д.).
- **Пример настройки**:
  ```xml
  <property name="hibernate.cache.use_second_level_cache">true</property>
  <property name="hibernate.cache.region.factory_class">org.hibernate.cache.ehcache.EhCacheRegionFactory</property>
  ```

#### Конфигурация вторичного кэша:

Для использования вторичного кэша необходимо:

1. Включить его в конфигурации Hibernate.
2. Настроить провайдер кеша (например, Ehcache, Infinispan и т.д.).
3. Аннотировать сущности или коллекции, которые должны использовать вторичный
   кэш.

Пример аннотации для включения вторичного кэша:

```java

@Entity
@Cacheable
@Cache(usage = CacheConcurrencyStrategy.READ_WRITE)
public class Author {
    @Id
    private Long id;

    // другие поля и методы
}
```

#### Кеширование коллекций

Вторичный кеш также может использоваться для кэширования коллекций. Вы можете
настроить стратегию кэширования для отдельных сущностей или коллекций через
аннотации или XML-конфигурацию.

#### Пример аннотации для вторичного кеша:

```java

@Entity
@Cacheable
@Cache(usage = CacheConcurrencyStrategy.READ_WRITE)
public class Author {
    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;

    private String name;

    @OneToMany(mappedBy = "author")
    @Cache(usage = CacheConcurrencyStrategy.READ_WRITE)
    private Set<Book> books;
}
```

### Стратегии кэширования

Hibernate поддерживает несколько стратегий кэширования для второго уровня:

1. **READ_ONLY**: Используется для объектов, которые не изменяются после их
   создания. Это наиболее эффективная стратегия.
2. **READ_WRITE**: Используется для объектов, которые могут изменяться.
   Hibernate управляет блокировками при записи.
3. **NONSTRICT_READ_WRITE**: Позволяет более высокую производительность за счет
   менее строгого контроля за изменениями.
4. **TRANSACTIONAL**: Поддерживает транзакционное поведение.

### 3. **Кэш запросов (Query Cache)**

- **Описание:** Это дополнительный уровень кеширования, который позволяет
  кешировать результаты запросов.
- **Область видимости:** Работает совместно со вторичным кэшем и может
  использоваться для кеширования результатов HQL или Criteria запросов.
- **Применение:** Если вы выполняете один и тот же запрос несколько раз,
  результаты могут быть извлечены из кеша вместо выполнения запроса к базе
  данных.

#### Конфигурация кеша запросов:

Чтобы использовать кеш запросов, необходимо:

1. Включить его в конфигурации Hibernate.
2. Аннотировать запросы или использовать методы API для указания использования
   кеша.

Пример использования кеша запросов:

```java
List<Author> authors = session.createQuery("FROM Author")
        .setHint("org.hibernate.cacheable", true)
        .getResultList();
```

### Заключение

Кеширование в Hibernate — это мощный инструмент для повышения производительности
приложений за счет уменьшения количества обращений к базе данных. Понимание
уровней кеширования и их правильная настройка могут значительно улучшить время
отклика вашего приложения и снизить нагрузку на базу данных.


> ## Сессия Hibernate

Сессия в Hibernate — это основной интерфейс для взаимодействия с базой данных.
Она представляет собой единицу работы с данными и обеспечивает механизм для
выполнения операций с сущностями, таких как создание, чтение, обновление и
удаление (CRUD). Сессия управляет состоянием объектов и их жизненным циклом, а
также обеспечивает кэширование на уровне первого уровня.

### Основные характеристики сессии Hibernate:

1. **Управление состоянием объектов:**
    - Сессия отслеживает изменения в сущностях, которые она загружает. Когда вы
      загружаете сущность из базы данных, она становится "управляемой" (managed)
      и находится в состоянии "приложения" (persistent).
    - Если вы изменяете управляемую сущность, Hibernate автоматически
      отслеживает эти изменения и может синхронизировать их с базой данных при
      вызове метода `session.flush()` или при закрытии сессии.

2. **Первичный кэш:**
    - Сессия имеет свой собственный первичный кэш (first-level cache), который
      хранит загруженные объекты. Если вы запрашиваете одну и ту же сущность
      несколько раз в рамках одной сессии, Hibernate будет возвращать объект из
      этого кэша вместо выполнения нового запроса к базе данных.

3. **Жизненный цикл:**
    - Сессия создается через `SessionFactory` и должна быть закрыта после
      завершения работы. Это можно сделать вручную или с помощью блока
      `try-with-resources`, чтобы гарантировать закрытие.
    - Сессия может быть открыта в начале транзакции и закрыта после завершения
      всех операций.

4. **Транзакции:**
    - Сессия обычно используется в контексте транзакций. Вы можете начать
      транзакцию, выполнять операции с сущностями и затем зафиксировать или
      откатить изменения.
    - Пример использования транзакций:

```java
      Session session = sessionFactory.openSession();
Transaction transaction = null;
 
      try{
transaction =session.

beginTransaction();
// операции с сущностями
          transaction.

commit();
      }catch(
Exception e){
        if(transaction !=null){
        transaction.

rollback();
          }
                  e.

printStackTrace();
      }finally{
              session.

close();
      }
```

5. **Потокобезопасность:**
    - Сессии не являются потокобезопасными. Каждая сессия должна использоваться
      только одним потоком одновременно. Для многопоточных приложений
      рекомендуется использовать `SessionFactory` для создания новых экземпляров
      `Session`.

### Заключение

Сессия в Hibernate является ключевым компонентом для работы с базой данных,
обеспечивая управление состоянием объектов, кэширование и поддержку транзакций.
Правильное использование сессий позволяет эффективно взаимодействовать с базой
данных и оптимизировать производительность приложения.

### Фабрика сессий

Фабрика сессий (SessionFactory) в Hibernate — это интерфейс, который отвечает за
создание и управление сессиями (Session). Она является основным компонентом,
который настраивается один раз при запуске приложения и используется для
получения экземпляров сессий. В контексте второго уровня кэширования (Second
Level Cache) фабрика сессий играет важную роль в управлении кэшированием данных
между различными сессиями.

### Основные аспекты фабрики сессий в контексте второго уровня кэширования:

1. **Управление вторичным кэшем:**
    - Фабрика сессий отвечает за настройку и управление вторичным кэшем. Она
      может быть сконфигурирована для использования различных провайдеров кэша,
      таких как Ehcache, Infinispan, Hazelcast и другие.
    - Вторичный кэш позволяет хранить данные между сессиями, что уменьшает
      количество обращений к базе данных и повышает производительность
      приложения.

2. **Конфигурация:**
    - При создании `SessionFactory` вы можете указать параметры конфигурации для
      включения второго уровня кэширования. Это включает в себя указание
      провайдера кэша, настройки его параметров и определение того, какие
      сущности или коллекции должны использовать второй уровень кэша.
    - Пример конфигурации в `hibernate.cfg.xml`:

      ```xml
      <property name="hibernate.cache.use_second_level_cache">true</property>
      <property name="hibernate.cache.region.factory_class">org.hibernate.cache.ehcache.EhCacheRegionFactory</property>
      ```

3. **Кэширование сущностей и коллекций:**
    - Вы можете аннотировать ваши сущности или коллекции для использования
      второго уровня кэша. Это позволяет Hibernate сохранять их состояние в
      кэше, что ускоряет доступ к данным.
    - Пример аннотации для включения второго уровня кэша:

```java

@Entity
@Cacheable
@Cache(usage = CacheConcurrencyStrategy.READ_WRITE)
public class Author {
    @Id
    private Long id;
    // другие поля и методы
}
```

4. **Производительность:**
    - Использование второго уровня кэширования может значительно улучшить
      производительность приложения, особенно если у вас есть часто
      запрашиваемые данные или данные, которые редко изменяются.
    - Однако важно правильно настроить стратегию кеширования (например,
      `READ_ONLY`, `READ_WRITE`, `NONSTRICT_READ_WRITE`, `TRANSACTIONAL`) в
      зависимости от требований вашего приложения.

5. **Создание и закрытие:**
    - Фабрика сессий создается один раз при запуске приложения и обычно
      закрывается при завершении работы приложения. Это позволяет избежать
      накладных расходов на создание новых экземпляров фабрики при каждом
      запросе.

### Заключение

Фабрика сессий в Hibernate является ключевым компонентом для управления сессиями
и вторичным кэшированием. Она обеспечивает возможность настройки и использования
различных стратегий кеширования, что позволяет оптимизировать производительность
приложений за счет уменьшения количества обращений к базе данных. Правильная
конфигурация фабрики сессий и использование второго уровня кэширования могут
существенно повысить эффективность работы вашего приложения.

> ## HQL, native, JPQL, Criteria запросы

### HQL

HQL (Hibernate Query Language) и native SQL (нативные SQL-запросы) — это два
способа выполнения запросов к базе данных в контексте Hibernate, ORM (
Object-Relational Mapping) фреймворка для Java. Оба подхода имеют свои
особенности, преимущества и недостатки. Давайте рассмотрим основные отличия
между ними.

#### 1. Уровень абстракции

- **HQL**:
    - HQL является объектно-ориентированным языком запросов, который работает с
      сущностями и их свойствами, а не с таблицами и столбцами базы данных.
    - Запросы в HQL пишутся с использованием имен классов и их полей, что делает
      код более читаемым и понятным для разработчиков, знакомых с
      объектно-ориентированным программированием.

- **Native SQL**:
    - Native SQL использует стандартный SQL-синтаксис, который напрямую
      взаимодействует с базой данных.
    - Запросы пишутся с использованием имен таблиц и столбцов, что может быть
      менее удобно при работе с объектами.

#### 2. Портируемость

- **HQL**:
    - HQL более портативен между различными СУБД (системами управления базами
      данных), так как он абстрагирует детали реализации конкретной базы данных.
    - Это позволяет легко менять СУБД без необходимости переписывать запросы.

- **Native SQL**:
    - Native SQL зависит от конкретной СУБД и ее диалекта. Это может привести к
      проблемам при переносе приложения на другую СУБД, так как могут
      потребоваться изменения в запросах.

#### 3. Поддержка функций

- **HQL**:
    - HQL поддерживает большинство стандартных операций SQL, но может не
      поддерживать специфические функции или операторы некоторых СУБД.
    - Некоторые сложные запросы могут быть труднее реализовать в HQL.

- **Native SQL**:
    - Native SQL позволяет использовать все возможности конкретной СУБД, включая
      специфические функции и оптимизации.
    - Это может быть полезно для выполнения сложных запросов или оптимизации
      производительности.

#### 4. Производительность

- **HQL**:
    - HQL может иметь накладные расходы из-за дополнительного уровня абстракции,
      но в большинстве случаев это незначительно.

- **Native SQL**:
    - Native SQL может быть более производительным для сложных запросов или
      операций, так как он напрямую взаимодействует с базой данных без
      дополнительных преобразований.

#### Примеры

##### Пример HQL:

```java
    String hql = "FROM Author WHERE name = :authorName";
Query query = session.createQuery(hql);
    query.

setParameter("authorName","John Doe");

List<Author> authors = query.list();
```

##### Пример Native SQL:

```java
    String sql = "SELECT * FROM authors WHERE name = :authorName";
Query query = session.createSQLQuery(sql).addEntity(Author.class);
    query.

setParameter("authorName","John Doe");

List<Author> authors = query.list();
```

### Заключение

Выбор между HQL и native SQL зависит от конкретных требований вашего приложения.
Если вам нужна высокая портируемость и удобство работы с объектами, лучше
использовать HQL. Если же вам нужны специфические функции базы данных или вы
работаете с очень сложными запросами, то native SQL может быть более подходящим
выбором.

### JPQL

JPQL (Java Persistence Query Language) — это объектно-ориентированный язык
запросов, используемый в Java Persistence API (JPA) для выполнения запросов к
базе данных. JPQL позволяет разработчикам писать запросы, которые работают с
объектами и их свойствами, а не с таблицами и столбцами базы данных. Это делает
JPQL более удобным и интуитивно понятным для работы с объектно-ориентированными
приложениями.

#### Основные характеристики JPQL:

1. **Объектно-ориентированный подход:**
    - JPQL работает с сущностями (объектами), а не с таблицами. Запросы
      формулируются на основе классов сущностей и их атрибутов.
    - Например, вместо того чтобы писать SQL-запрос к таблице `Author`, вы
      пишете запрос к сущности `Author`.

2. **Синтаксис:**
    - Синтаксис JPQL похож на SQL, но он ориентирован на объекты. Например,
      вместо `SELECT * FROM Author` вы пишете `SELECT a FROM Author a`.
    - Вы можете использовать такие конструкции, как `WHERE`, `ORDER BY`,
      `GROUP BY` и другие.

3. **Поддержка наследования:**
    - JPQL поддерживает концепции наследования, что позволяет выполнять запросы
      к родительским и дочерним сущностям.

4. **Динамические запросы:**
    - JPQL позволяет создавать динамические запросы с использованием параметров,
      что делает его гибким для различных сценариев.

5. **Портативность:**
    - Запросы на JPQL являются независимыми от конкретной базы данных, что
      делает код более переносимым между различными СУБД.

### Пример использования JPQL:

Вот пример того, как можно использовать JPQL для выполнения запроса к базе
данных:

```java
class Demo {
    void demo() {
        // Получение EntityManager
        EntityManager entityManager = entityManagerFactory.createEntityManager();

        // Начало транзакции
        entityManager.getTransaction().begin();

        // Пример JPQL запроса
        String jpql = "SELECT a FROM Author a WHERE a.name = :name";
        TypedQuery<Author> query = entityManager.createQuery(jpql, Author.class);
        query.setParameter("name", "John Doe");

        // Выполнение запроса
        List<Author> authors = query.getResultList();

        // Завершение транзакции
        entityManager.getTransaction().commit();

        // Закрытие EntityManager
        entityManager.close();
    }

```

### Основные компоненты JPQL:

1. **Сущности:**
    - Запросы формулируются на основе классов-сущностей, которые соответствуют
      таблицам в базе данных.

2. **Атрибуты:**
    - Вы обращаетесь к атрибутам сущностей так же, как вы обращаетесь к полям
      объекта в Java.

3. **Параметры:**
    - Вы можете использовать именованные или позиционные параметры для передачи
      значений в запрос.

4. **Типизированные запросы:**
    - Использование `TypedQuery` позволяет получить результаты определенного
      типа, что обеспечивает безопасность типов во время компиляции.

### Заключение

JPQL является мощным инструментом для работы с базами данных в Java-приложениях,
позволяя разработчикам писать понятные и поддерживаемые запросы на основе
объектов и их свойств. Он сочетает в себе простоту SQL с преимуществами
объектно-ориентированного программирования, что делает его идеальным выбором для
работы с JPA и Hibernate.

### Отличия HQL от JPQL

#### Что такое HQL и JPQL?

- **HQL (Hibernate Query Language)** — это собственный язык запросов,
  разработанный командой Hibernate. Он похож на SQL, но работает с объектами и
  их свойствами, а не с таблицами и столбцами.

- **JPQL (Java Persistence Query Language)** — это стандартный язык запросов,
  определённый спецификацией JPA. Он тоже похож на SQL и работает с сущностями и
  их полями.

---

### Основные отличия

| Характеристика                       | HQL                                                            | JPQL                                  |
|--------------------------------------|----------------------------------------------------------------|---------------------------------------|
| **Стандарт**                         | Собственный язык Hibernate                                     | Стандарт JPA (часть спецификации JPA) |
| **Совместимость**                    | Работает только с Hibernate                                    | Работает с любыми JPA-провайдерами    |
| **Функциональность**                 | Может содержать расширения Hibernate                           | Более ограниченный набор возможностей |
| **Поддержка специфичных функций БД** | Может поддерживать специфичные функции Hibernate и диалекты БД | Стандартизирован, без расширений      |
| **Использование**                    | Используется в проектах с Hibernate напрямую                   | Используется в любых JPA-проектах     |

---

### Пример запроса

**HQL:**

```hql
from Author a where a.name like 'Иван%'
```

**JPQL:**

```jpql
SELECT a FROM Author a WHERE a.name LIKE 'Иван%'
```

---

### Итог

- **JPQL** — это стандартный, переносимый язык запросов для JPA.
- **HQL** — расширенный язык запросов Hibernate, который включает все
  возможности JPQL плюс дополнительные функции.

Если вы используете только JPA без Hibernate, то работаете с JPQL. Если же
используете Hibernate напрямую, то можете использовать HQL и его расширения.

## Criteria запросы

Criteria запросы в Hibernate — это способ создания запросов к базе данных с
использованием объектно-ориентированного подхода. Они позволяют строить запросы
программно, используя API, вместо написания SQL или HQL (Hibernate Query
Language). Это особенно полезно для динамического построения запросов, когда
условия могут изменяться в зависимости от логики приложения.

### Основные характеристики Criteria запросов:

1. **Объектно-ориентированный подход:**
    - Criteria API позволяет работать с сущностями и их свойствами как с
      объектами, что делает код более читаемым и поддерживаемым.
    - Вместо написания строкового запроса вы создаете объекты и связываете их.

2. **Динамическое построение запросов:**
    - Criteria API позволяет добавлять условия, сортировку и другие параметры
      запроса динамически, что удобно для создания сложных фильтров.
    - Например, вы можете добавлять условия на основе пользовательского ввода
      или других факторов.

3. **Типобезопасность:**
    - Использование Criteria API обеспечивает типобезопасность, так как
      компилятор может проверять правильность типов на этапе компиляции.

4. **Поддержка различных операций:**
    - Criteria API поддерживает различные операции, такие как выборка (select),
      фильтрация (where), сортировка (order by) и группировка (group by).

### Пример использования Criteria API:

Вот пример того, как можно использовать Criteria API для выполнения запроса к
базе данных:

```java

class Demo {
    void demo() {

        // Получение сессии
        Session session = sessionFactory.openSession();

        // Создание CriteriaBuilder
        CriteriaBuilder criteriaBuilder = session.getCriteriaBuilder();

        // Создание CriteriaQuery
        CriteriaQuery<Author> criteriaQuery = criteriaBuilder
                .createQuery(Author.class);

        // Определение корня запроса (из какой сущности мы выбираем)
        Root<Author> root = criteriaQuery.from(Author.class);

        // Добавление условий (например, выбор авторов с определенным именем)
        criteriaQuery.
                select(root).
                where(criteriaBuilder.equal(root.get("name"), "John Doe"));

        // Выполнение запроса
        List<Author> authors = session.createQuery(criteriaQuery).getResultList();

        // Закрытие сессии
        session.close();
    }
}

```

### Основные компоненты Criteria API:

1. **CriteriaBuilder:**
    - Интерфейс для создания объектов `CriteriaQuery`, `Predicate` и других
      компонентов запроса.

2. **CriteriaQuery:**
    - Представляет сам запрос. Вы можете указать, какие сущности вы хотите
      выбрать и какие условия применить.

3. **Root:**
    - Корень запроса, который представляет сущность, из которой вы выбираете
      данные.

4. **Predicate:**
    - Условия фильтрации данных. Вы можете комбинировать несколько предикатов с
      помощью логических операторов (AND, OR).

5. **TypedQuery:**
    - Позволяет выполнять запрос и получать результаты в виде списка объектов
      определенного типа.

### Заключение

Criteria API в Hibernate предоставляет мощный инструмент для построения
динамических и типобезопасных запросов к базе данных. Он упрощает работу с
данными и делает код более чистым и понятным по сравнению с использованием
строковых SQL-запросов или HQL.


> SQL. Оптимистические/Пессимистические блокировки
> Spring. Self injection и как работать с аннотациями в спринге. Например,
> Transaction, Уровни транзакции, ACID, проблемы
> Kafka про патриции чуть лучше
> SQL. Индексы в SQL
> Java Core:
> - устройство памяти и сборка мусора
> - Collection Framework и внутренняя работа коллекций
> - Работа с исключениями
> - Устройство и особенности StreamAPI
    > Multithreading
> - Механизмы синхронизации: synchronized, volatile, atomic types
> - Пробелемы race condition и deadlock, способы решения
> - Optimistic и Pessimistic locking
> - Многопоточные коллекции, пулы потоков, Future и CompletableFutute
    > Java Core. HashCode, equals()
