Что подучить/повторить:

> 1. SOLID (чуть лучше про D)

Принцип инверсии зависимостей (Dependency Inversion Principle, DIP) — это один
из пяти принципов SOLID, которые помогают разработчикам создавать гибкие и
поддерживаемые программные системы. DIP гласит:

Модули верхнего уровня не должны зависеть от модулей нижнего уровня. Оба типа
модулей должны зависеть от абстракций.
Абстракции не должны зависеть от деталей. Детали должны зависеть от абстракций.

**Объяснение принципа**<br>

Модули верхнего уровня — это те, которые содержат бизнес-логику и
высокоуровневые функции приложения.
Модули нижнего уровня — это те, которые реализуют конкретные детали, такие как
работа с базами данных, сетевыми запросами и т.д.
Согласно принципу инверсии зависимостей, модули верхнего уровня не должны
напрямую зависеть от конкретных реализаций модулей нижнего уровня. Вместо этого
они должны взаимодействовать через абстракции (например, интерфейсы или
абстрактные классы). Это позволяет уменьшить связанность между компонентами
системы и облегчает их тестирование и замену.

Пример
Рассмотрим простой пример без применения DIP:

```java
class Database {
    public void saveData(String data) {
        // Сохранение данных в базу
    }
}

class UserService {
    private Database database;

    public UserService() {
        this.database = new Database(); // Прямое создание зависимости
    }

    public void saveUser(String user) {
        database.saveData(user);
    }

}
```

В этом примере UserService напрямую зависит от класса Database. Если мы захотим
изменить способ хранения данных (например, использовать файл или удаленный
сервис), нам придется изменять код UserService.

Теперь применим принцип инверсии зависимостей:

```java
interface DataStorage {
    void saveData(String data);
}

class Database implements DataStorage {
    public void saveData(String data) {
        // Сохранение данных в базу
    }
}

class FileStorage implements DataStorage {
    public void saveData(String data) {
        // Сохранение данных в файл
    }
}

class UserService {
    private DataStorage dataStorage;

    public UserService(DataStorage dataStorage) { // Внедрение зависимости через конструктор
        this.dataStorage = dataStorage;
    }

    public void saveUser(String user) {
        dataStorage.saveData(user);
    }

}

```

В этом примере `UserService` зависит от абстракции DataStorage, а не от
конкретной реализации. Теперь мы можем легко заменить Database на FileStorage
или любую другую реализацию без изменения кода `UserService`.

**Преимущества применения DIP**

- Уменьшение связанности: Компоненты системы становятся менее зависимыми друг от
  друга.
- Упрощение тестирования: Легче подменять зависимости на моки или стабы при
  тестировании.
- Гибкость и расширяемость: Легко добавлять новые реализации без изменения
  существующего кода.
- Улучшение читаемости кода: Код становится более понятным благодаря четкому
  разделению интерфейсов и реализаций.
- Принцип инверсии зависимостей является важным инструментом для создания
  качественного программного обеспечения и способствует соблюдению других
  принципов SOLID.

> 2. Можем как-то ограничить типы (про super)

В Java, как и в других языках программирования, концепция уровней обобщений (или
обобщенных типов) позволяет создавать классы, интерфейсы и методы, которые
работают с различными типами данных. Это достигается с помощью параметров типа (
type parameters). В контексте обобщений можно выделить верхний и нижний уровни
обобщений.

Верхний уровень обобщений (Upper Bound Wildcards)

Верхний уровень обобщений используется для ограничения типа, который может быть
использован в качестве параметра. Это делается с помощью ключевого слова
extends. Например:

```java
public void processList(List<? extends Number> list) {
    for (Number number : list) {
        System.out.println(number);
    }
}
```

В этом примере метод processList принимает список, содержащий объекты любого
типа, который является подтипом Number (например, Integer, Double и т.д.). Это
позволяет работать с различными типами данных, сохраняя при этом безопасность
типов.

Нижний уровень обобщений (Lower Bound Wildcards)

Нижний уровень обобщений используется для указания того, что параметр может быть
определён как определённый тип или любой его суперкласс. Это делается с помощью
ключевого слова super. Например:

```java
public void addNumbers(List<? super Integer> list) {
    list.add(1);
    list.add(2);
}
```

В этом примере метод addNumbers принимает список, который может содержать
объекты типа Integer или любого его суперкласса (например, Number или Object).
Это позволяет добавлять элементы в список без необходимости знать точный тип
списка.

Применение

Верхние границы полезны, когда вы хотите читать данные из структуры данных и не
хотите беспокоиться о том, какой конкретный подтип вы получаете.
Нижние границы полезны, когда вы хотите добавлять данные в структуру данных и
хотите гарантировать, что вы можете добавлять элементы определенного типа или
его подтипов.  
Эти концепции позволяют создавать более гибкие и безопасные API в Java.

> 3. PECS

Принцип PECS (Producer Extends, Consumer Super) — это концепция, связанная с
использованием обобщений (generics) в Java, которая помогает правильно управлять
типами при работе с коллекциями и другими обобщенными структурами данных. Этот
принцип особенно полезен для понимания того, как использовать wildcard-тип (
неопределенный тип) в Java.

**Основные идеи PECS**

Producer Extends: Если вы хотите создать структуру данных, которая будет
производить элементы (например, возвращать элементы из коллекции), используйте
`? extends T`. Это означает, что вы можете использовать любой подтип T.

Consumer Super: Если вы хотите создать структуру данных, которая будет
потреблять элементы (например, добавлять элементы в коллекцию), используйте
`? super T`. Это означает, что вы можете использовать любой суперкласс T.

_Примеры_

**Producer Extends**

Предположим, у вас есть класс Animal и его подклассы Dog и Cat. Если у вас есть
метод, который возвращает список животных:

```java
class Animal {
}

class Dog extends Animal {
}

class Cat extends Animal {
}

public void printAnimals(List<? extends Animal> animals) {
    for (Animal animal : animals) {
        System.out.println(animal);
    }
}
```

В этом примере метод printAnimals принимает список животных `(List<? extends
Animal>)`. Это позволяет передавать списки как List<Dog>, так и List<Cat>,
поскольку оба класса являются подтипами Animal. Метод может безопасно читать
объекты из списка и обрабатывать их как объекты типа Animal.

**Consumer Super**

Теперь рассмотрим ситуацию, когда вам нужно добавить животных в коллекцию:

```java
public void addDogs(List<? super Dog> dogs) {
    dogs.add(new Dog());
    // dogs.add(new Animal()); // Ошибка компиляции
}
```

В этом примере метод addDogs принимает список, который может содержать объекты
типа Dog или любого его суперкласса (например, Animal или даже Object). Это
позволяет добавлять объекты типа Dog в список. Однако вы не можете добавлять
объекты типа Animal, потому что это может привести к нарушению типов.

В Java, когда вы используете обобщения (generics) с `? super T`, важно понимать,
как работает механизм типов и что именно разрешено добавлять в коллекцию.

Объяснение

Тип ? super T:

Когда вы используете `List<? super Dog>`, это означает, что вы можете передать
список, который может содержать объекты типа Dog или любого его суперкласса (
например, Animal или даже Object).  
Однако это также означает, что вы не можете добавлять объекты типа Animal,
потому что компилятор не может гарантировать, что этот список предназначен для
хранения объектов типа Animal. Он может быть списком, который предназначен
только для хранения объектов типа Dog.
Добавление объектов:

Когда вы добавляете объект типа Dog, это безопасно, потому что Dog является
подклассом и совместим с любым суперклассом.  
Однако если бы вы попытались добавить объект типа Animal, компилятор не смог бы
гарантировать, что это допустимо. Например, если у вас есть список типа
List<Animal>, он может содержать объекты других подклассов (например, Cat). Если
бы вы добавили объект типа Animal, это могло бы привести к ситуации, когда в
списке окажутся объекты разных типов (например, и Dog, и Cat), что нарушает
типизацию.

Пример

Рассмотрим следующий код:

```java
import java.util.ArrayList;
import java.util.List;

class Animal {
}

class Dog extends Animal {
}

class Cat extends Animal {
}

public class ConsumerSuperExample {
    public void addDogs(List<? super Dog> dogs) {
        dogs.add(new Dog()); // Это допустимо
        // dogs.add(new Animal()); // Ошибка компиляции
    }

    public static void main(String[] args) {
        List<Animal> animalList = new ArrayList<>();
        List<Dog> dogList = new ArrayList<>();

        ConsumerSuperExample example = new ConsumerSuperExample();

        example.addDogs(animalList); // Это допустимо
        // example.addDogs(dogList); // Ошибка компиляции
    }

}
```

Почему это происходит:  
Добавление объекта типа Dog:

Когда вы вызываете dogs.add(new Dog()), это безопасно, потому что метод ожидает
список, который может содержать объекты типа Dog или его суперклассы. Таким
образом, добавление объекта типа Dog всегда будет допустимо.
Попытка добавить объект типа Animal:

Если бы вы попытались добавить объект типа Animal, компилятор выдаст ошибку. Это
связано с тем, что метод не знает точно, какой именно тип данных хранится в
списке. Например:

```java
List<Animal> animalList = new ArrayList<>();
List<Cat> catList = new ArrayList<>();example.

addDogs(catList);
// Это вызвало бы ошибку компиляции
```

В этом случае метод не может гарантировать безопасность добавления объекта типа
Animal, так как он может быть несовместим с типом данных в списке.

Заключение<br>
Таким образом, использование обобщений с типом ? super T позволяет вам добавлять
объекты определенного подкласса (в данном случае — объекты класса Dog), но не
позволяет добавлять объекты базового класса (Animal) из-за ограничений типизации
и обеспечения безопасности типов в Java.

**Применение PECS**<br>  
Принцип PECS помогает разработчикам правильно выбирать между использованием
верхних (extends) и нижних (super) границ при работе с обобщениями. Вот
несколько рекомендаций:

- Используйте ? extends T, когда:
    - Вы читаете данные из структуры данных.
    - Вам нужно получить элементы из коллекции.

- Используйте ? super T, когда:
    - Вы записываете данные в структуру данных.
    - Вам нужно добавлять элементы в коллекцию.

Заключение<br>
Принцип PECS является важным инструментом для работы с обобщениями в Java. Он
помогает избежать ошибок компиляции и делает код более безопасным и понятным.
Понимание этого принципа позволяет разработчикам более эффективно использовать
возможности языка Java и создавать гибкие архитектуры программного обеспечения.

> 4. Вызов без терминальной операции

Промежуточные операции не выполняются немедленно — они откладываются до тех пор,
пока не будет вызвана терминальная операция.  
Именно терминальная операция запускает выполнение потока. После ее вызова
происходит анализ операций в пайплайне, и определяется эффективная стратегия его
выполнения.

> 5. .parallel(), fork-join-poll

.parallel()<br>
Для запуска потоков в параллельном режиме можно использовать методы
parallelStream() или parallel(). По умолчанию потоки выполняются
последовательно, но с явным вызовом одного из этих методов поток переключается в
параллельный режим.<br>
Для разделения коллекций на части, которые обрабатываются параллельно, Java
использует Spliterator и его метод trySplit(). Этот метод разделяет данные на
подзадачи, которые затем могут быть распределены между несколькими потоками.
Каждая часть обрабатывается независимо, и результаты объединяются после
завершения работы всех потоков.<br>

ForkJoinPool<br>
Java использует ForkJoinPool для распределения задач параллельных потоков. Это
общий пул потоков, где задачи разбиваются на более мелкие фрагменты и
распределяются между потоками. Такой же подход применяется и в
CompletableFuture. При необходимости можно указать свой пул потоков, если
текущий пул перегружен или необходимо изменить его поведение.

> 6. GCRoot

В Java, GC Root (или корень сборщика мусора) — это объект, который является
начальной точкой для процесса сборки мусора (Garbage Collection, GC). Сборщик
мусора использует корни для определения, какие объекты в памяти все еще доступны
и могут быть использованы, а какие объекты больше не нужны и могут быть удалены.

Что такое GC Root?<br>
GC Root — это набор объектов, которые всегда доступны и служат отправной точкой
для поиска всех достижимых объектов в памяти. Если объект не может быть
достигнут из любого из корней, он считается "мусором" и может быть удален
сборщиком мусора.

Примеры GC Root<br>
Вот несколько примеров объектов, которые считаются GC Root:<br>

- Статические поля:<br>
  Объекты, на которые ссылаются статические поля классов. Например, если у вас
  есть статическое поле в классе, которое ссылается на объект, этот объект будет
  являться корнем.
- Активные потоки:<br>
  Объекты, связанные с активными потоками (например, текущий поток выполнения).
- Объекты в локальных переменных:<br>
  Объекты, на которые ссылаются локальные переменные методов. Пока метод
  выполняется и локальные переменные находятся в стеке вызовов, эти объекты
  считаются достижимыми.
- JNI ссылки:<br>
  Объекты, на которые ссылаются нативные методы через Java Native Interface (
  JNI).
- Объекты класса java.lang.Runtime:<br>
  Объект Runtime, который предоставляет информацию о среде выполнения Java.

Как работает сборка мусора?<br>
Сборщик мусора использует алгоритмы для определения достижимости объектов:

1. Начинает с GC Roots: Сборщик начинает с объектов GC Root и проходит по всем
   ссылкам от этих объектов.
2. Обходит граф объектов: Он рекурсивно проверяет все объекты, на которые
   ссылаются корни.
3. Определяет недостижимые объекты: Все объекты, которые не могут быть
   достигнуты из корней, помечаются как "мусор" и подлежат удалению.

Важность GC Root<br>
Понимание концепции GC Root важно для оптимизации работы приложения и управления
памятью:<br>

1. Помогает разработчикам избегать утечек памяти.
2. Позволяет лучше понимать поведение сборщика мусора.
3. Способствует более эффективному управлению ресурсами в приложениях.

Как пометить объект "живым"<br>
В Java объекты помечаются как "живые" (или "достижимые") в контексте сборки
мусора (Garbage Collection) на основе ссылок на них. Если объект доступен через
одну или несколько ссылок, он считается живым и не может быть удален сборщиком
мусора. Вот несколько способов, как можно пометить объект как живой:

1. Создание ссылок на объект<br>
   Чтобы объект считался живым, необходимо создать хотя бы одну ссылку на него.
   Например:

```java
class MyObject {
// Поля и методы
}

public class Main {
    public static void main(String[] args) {
        MyObject obj = new MyObject(); // Создаем объект и сохраняем ссылку на него
// Объект obj считается "живым", пока существует ссылка на него
    }
}
```

В этом примере obj является ссылкой на экземпляр MyObject, и пока эта ссылка
существует, объект будет считаться живым.

2. Использование коллекций<br>
   Объекты могут быть помечены как живые, если они хранятся в коллекциях, таких
   как списки, множества или карты:

```java
import java.util.ArrayList;
import java.util.List;

class MyObject {
    // Поля и методы
}

public class Main {
    public static void main(String[] args) {
        List<MyObject> list = new ArrayList<>();
        MyObject obj = new MyObject();
        list.add(obj); // Объект obj теперь считается "живым", так как он хранится в списке
    }
}
```

3. Статические поля<br>
   Если объект хранится в статическом поле класса, он также будет считаться
   живым:

```java
class MyClass {
    static MyObject staticObj = new MyObject(); // Статическое поле хранит ссылку на объект
}

public class Main {
    public static void main(String[] args) {
        // Объект staticObj считается "живым" благодаря статической ссылке
    }
}
```

4. Передача объектов в методы<br>
   Когда вы передаете объект в метод, он также считается живым, пока метод
   выполняется:

```java
class MyObject {
    // Поля и методы
}

public class Main {
    public static void process(MyObject obj) {
        // Объект obj считается "живым" внутри этого метода
    }

    public static void main(String[] args) {
        MyObject myObj = new MyObject();
        process(myObj); // Передаем объект в метод
    }
}

```

5. Использование внешних библиотек или фреймворков
   Некоторые фреймворки и библиотеки могут управлять жизненным циклом объектов и
   поддерживать ссылки на них для обеспечения их доступности.

Заключение<br>
Объекты в Java считаются "живыми", если на них существуют ссылки из других
объектов или переменных. Чтобы пометить объект как живой, достаточно создать
хотя бы одну ссылку на него — это может быть локальная переменная, элемент
коллекции или статическое поле класса. Как только все ссылки на объект будут
удалены (например, переменные выйдут из области видимости или будут присвоены
null), объект станет недостижимым и может быть удален сборщиком мусора.

GC Root — это ключевая концепция в управлении памятью Java и сборке мусора. Она
определяет начальные точки для поиска достижимых объектов и помогает сборщику
мусора эффективно освобождать память от ненужных объектов.

> 7. HashMap чуть лучше про то как устроен, и сложности методов

### Устройство

HashMap в Java — это структура данных, которая реализует интерфейс Map и
использует хеш-таблицу для хранения пар "ключ-значение". Она обеспечивает
быстрый доступ к элементам по ключу, что делает её одной из самых популярных
реализаций Map. Давайте рассмотрим, как работает HashMap, его основные
характеристики и внутренние механизмы.

Основные характеристики HashMap

1. Ключи и значения: HashMap хранит данные в виде пар "ключ-значение". Каждый
   ключ должен быть уникальным, но значения могут повторяться.
2. Неупорядоченность: Элементы в HashMap не имеют определенного порядка. Порядок
   вставки не сохраняется.
3. Допускает null: HashMap позволяет использовать один null в качестве ключа и
   любое количество null в качестве значений.
4. Не синхронизирован: HashMap не является потокобезопасным. Если несколько
   потоков одновременно изменяют его, необходимо использовать внешнюю
   синхронизацию.

Как работает HashMap

1. Хеширование
   Когда вы добавляете пару "ключ-значение" в HashMap, ключ проходит через
   хеш-функцию, которая вычисляет хеш-код для этого ключа. Хеш-код — это целое
   число, которое используется для определения индекса в массиве (хеш-таблице),
   где будет храниться значение.

```java
int hash = key.hashCode();
int index = hash % array.length; // Определяем индекс в массиве
```

2. Обработка коллизий<br>
   Коллизия происходит, когда два разных ключа имеют одинаковый хеш-код и,
   следовательно, попадают в один и тот же индекс массива. Для обработки
   коллизий HashMap использует метод цепочек (chaining):
    1. Каждый элемент массива представляет собой связный список (или дерево с
       Java 8 и выше), который хранит все пары "ключ-значение", имеющие
       одинаковый индекс.
    2. Если возникает коллизия, новая пара добавляется в конец связного списка
       или дерева.
3. Резервирование места<br>
   Когда количество элементов в HashMap превышает определенный порог (обычно 75%
   от текущей емкости), происходит увеличение емкости:
    1. Создается новый массив большего размера.
    2. Все существующие элементы перераспределяются по новому массиву на основе
       их хеш-кодов.
4. Время доступа<br>
   В среднем время доступа к элементам по ключу составляет O(1) благодаря
   использованию хеширования. Однако в худшем случае (например, если все
   элементы попадают в одну цепочку) время доступа может составлять O(n). Чтобы
   избежать этого, важно правильно выбирать размер начального массива и
   коэффициент загрузки.

Пример использования HashMap

```java
import java.util.HashMap;

public class Main {
    public static void main(String[] args) {
        HashMap<String, Integer> map = new HashMap<>();

        // Добавление элементов
        map.put("Alice", 30);
        map.put("Bob", 25);
        map.put("Charlie", 35);

        // Получение элемента
        System.out.println("Age of Alice: " + map.get("Alice"));

        // Проверка наличия ключа
        if (map.containsKey("Bob")) {
            System.out.println("Bob is in the map.");
        }

        // Удаление элемента
        map.remove("Charlie");

        // Итерация по элементам
        for (String key : map.keySet()) {
            System.out.println(key + ": " + map.get(key));
        }
    }
}
```

Заключение
HashMap — это мощная структура данных для хранения пар "ключ-значение" с быстрым
доступом к элементам по ключу. Она использует хеширование для обеспечения
высокой производительности и обрабатывает коллизии с помощью цепочек. Понимание
работы HashMap поможет вам эффективно использовать её в ваших Java-приложениях.

___
**Добавление нескольких значений к одному ключу**

В HashMap в Java ключи должны быть уникальными. Если вы попытаетесь добавить
пару "ключ-значение" с уже существующим ключом, новое значение заменит старое.
Однако, если вам нужно хранить несколько значений для одного ключа, вы можете
использовать несколько подходов.

1. Использование HashMap с List или Set
   Один из самых распространенных способов обработки одинаковых ключей — это
   использование HashMap, где значениями являются коллекции (например, List или
   Set). Это позволяет хранить несколько значений для одного ключа.

Пример с использованием ArrayList

```java
public class Main {
    public static void main(String[] args) {
        HashMap<String, List<Integer>> map = new HashMap<>();

        // Добавление значений
        addValue(map, "Alice", 30);
        addValue(map, "Alice", 31);
        addValue(map, "Bob", 25);
        addValue(map, "Charlie", 35);
        addValue(map, "Alice", 32);

        // Вывод значений
        for (String key : map.keySet()) {
            System.out.println(key + ": " + map.get(key));
        }
    }

    private static void addValue(HashMap<String, List<Integer>> map, String key, Integer value) {
        // Получаем список значений по ключу
        List<Integer> values = map.get(key);

        // Если список не существует, создаем новый
        if (values == null) {
            values = new ArrayList<>();
            map.put(key, values);
        }

        // Добавляем новое значение в список
        values.add(value);
    }
}
```

2. Использование HashMap с Set

Если вам нужно хранить уникальные значения для каждого ключа (без дубликатов),
вы можете использовать HashSet вместо ArrayList.

```java
import java.util.HashMap;
import java.util.HashSet;
import java.util.Set;

public class Main {
    public static void main(String[] args) {
        HashMap<String, Set<Integer>> map = new HashMap<>();

        // Добавление значений
        addValue(map, "Alice", 30);
        addValue(map, "Alice", 31);
        addValue(map, "Bob", 25);
        addValue(map, "Charlie", 35);
        addValue(map, "Alice", 30); // Дубликат не будет добавлен

        // Вывод значений
        for (String key : map.keySet()) {
            System.out.println(key + ": " + map.get(key));
        }
    }

    private static void addValue(HashMap<String, Set<Integer>> map, String key, Integer value) {
        // Получаем множество значений по ключу
        Set<Integer> values = map.get(key);

        // Если множество не существует, создаем новое
        if (values == null) {
            values = new HashSet<>();
            map.put(key, values);
        }

        // Добавляем новое значение в множество
        values.add(value);
    }
}
```

Заключение
Если вам нужно обрабатывать одинаковые пары ключ-значение в Java с
использованием HashMap, вы можете использовать коллекции (например, List или
Set) в качестве значений. Это позволит вам хранить несколько значений для одного
ключа и управлять ими более гибко. Выбор между списком и множеством зависит от
ваших требований к уникальности значений.

___

_**Как работает обработка коллизий в HashMap**_

Когда два ключа имеют одинаковый хеш-код и попадают в один и тот же индекс
массива, HashMap создает связный список (или дерево) для хранения всех пар "
ключ-значение", которые имеют одинаковый индекс. В Java 8 и выше, если
количество элементов в цепочке превышает определенный порог (обычно 8), HashMap
преобразует связный список в сбалансированное дерево (например, Red-Black Tree)
для улучшения производительности.

Пример обработки коллизий<br>
Вот пример, который демонстрирует, как HashMap обрабатывает коллизии:

```java
import java.util.HashMap;

public class Main {
    public static void main(String[] args) {
        HashMap<Key, String> map = new HashMap<>();

        // Создаем ключи с одинаковым хеш-кодом
        Key key1 = new Key(1);
        Key key2 = new Key(2);

        // Добавляем пары "ключ-значение"
        map.put(key1, "Value for key 1");
        map.put(key2, "Value for key 2");

        // Вывод значений
        System.out.println("Key 1: " + map.get(key1));
        System.out.println("Key 2: " + map.get(key2));
    }
}

class Key {
    private int id;

    public Key(int id) {
        this.id = id;
    }

    @Override
    public int hashCode() {
        return 1; // Оба ключа будут иметь одинаковый хеш-код
    }

    @Override
    public boolean equals(Object obj) {
        if (this == obj) return true;
        if (!(obj instanceof Key)) return false;
        Key other = (Key) obj;
        return this.id == other.id;
    }
}
```

Объяснение кода<br>

1. Класс Key: Мы создаем класс Key, который имеет метод hashCode(), возвращающий
   одно и то же значение (в данном случае 1). Это означает, что все экземпляры
   этого класса будут иметь одинаковый хеш-код.
2. Добавление пар: Мы добавляем два разных ключа (key1 и key2) в HashMap.
   Несмотря на то что они разные объекты, они имеют одинаковый хеш-код.
3. Обработка коллизий: Когда мы добавляем оба ключа в HashMap, они будут
   храниться в одной цепочке (связанном списке или дереве), так как их хеш-коды
   совпадают.
4. Получение значений: Мы можем получить значения по каждому из ключей без
   проблем, так как метод equals() также переопределен для сравнения объектов по
   их идентификатору.

Заключение<br>
В случае коллизий в HashMap, структура данных автоматически обрабатывает их с
помощью связных списков или деревьев. Вам не нужно беспокоиться о том, как
именно это происходит — просто используйте уникальные ключи для хранения
значений. Если вам нужно хранить несколько значений для одного ключа,
рассмотрите возможность использования коллекций (например, List или Set) как
значений.


___

**Бакеты**

В контексте HashMap в Java "бакеты" (или "ведра") — это структуры данных,
которые используются для хранения пар "ключ-значение". Бакеты помогают
организовать данные в HashMap и обеспечивают эффективный доступ к ним. Давайте
рассмотрим, как это работает.

Основные концепции

1. Хеширование: Когда вы добавляете пару "ключ-значение" в HashMap, сначала
   вычисляется хеш-код ключа с помощью метода hashCode(). Этот хеш-код затем
   используется для определения индекса (или бакета) в массиве, который хранит
   все бакеты.
2. Массив бакетов: HashMap использует массив для хранения бакетов. Каждый
   элемент массива может содержать один или несколько объектов (пары "
   ключ-значение"). Индекс массива определяется на основе хеш-кода ключа.
3. Обработка коллизий: Если два или более ключа имеют одинаковый хеш-код и,
   следовательно, попадают в один и тот же индекс массива (это называется
   коллизией), HashMap использует метод цепочек (chaining) для обработки этих
   коллизий. В этом случае все пары "ключ-значение", которые имеют одинаковый
   индекс, будут храниться в связанном списке или дереве внутри соответствующего
   бакета.

Пример работы с бакетами

```java
import java.util.HashMap;

public class Main {
    public static void main(String[] args) {
        HashMap<String, String> map = new HashMap<>();

        // Добавление пар "ключ-значение"
        map.put("key1", "value1");
        map.put("key2", "value2");
        map.put("key3", "value3");

        // Получение значения по ключу
        System.out.println(map.get("key1")); // Вывод: value1
    }
}
```

Как это выглядит под капотом<br>

1. Добавление элемента:
    1. При добавлении "key1" вычисляется его хеш-код.
    2. На основе этого хеш-кода определяется индекс в массиве.
    3. Если по этому индексу еще нет других элементов, создается новый бакет и
       добавляется пара "key1" : "value1".
2. Обработка коллизий:
    1. Если вы добавите другой ключ, который имеет тот же хеш-код (например, "
       key4"), он попадет в тот же индекс.
    2. В этом случае HashMap создаст связанный список или дерево внутри этого
       бакета и добавит пару "key4" : "value4" туда.
3. Получение элемента:
    1. При получении значения по ключу сначала вычисляется его хеш-код.
    2. Затем определяется индекс массива.
    3. Если по этому индексу есть несколько элементов (из-за коллизий), HashMap
       будет перебирать элементы в связанном списке или дереве до тех пор, пока
       не найдет нужный ключ.

Заключение<br>
Бакеты в HashMap — это важная часть структуры данных, которая позволяет
эффективно хранить и извлекать пары "ключ-значение". Они обеспечивают обработку
коллизий и позволяют поддерживать производительность операций вставки и поиска
на высоком уровне.

___ 

_**Метод цепочек для обработки колизий**_

Метод цепочек (chaining) — это один из способов обработки коллизий в
хеш-таблицах, таких как HashMap в Java. Когда два или более ключа имеют
одинаковый хеш-код и, следовательно, попадают в один и тот же индекс массива (
бакета), метод цепочек позволяет хранить все эти пары "ключ-значение" в одной
структуре данных, связанной с этим индексом.

Как работает метод цепочек

1. Хеширование: Когда вы добавляете пару "ключ-значение" в HashMap, сначала
   вычисляется хеш-код ключа с помощью метода hashCode(). Этот хеш-код
   используется для определения индекса в массиве бакетов.
2. Создание бакета: Если по этому индексу еще нет других элементов, создается
   новый бакет. В Java это обычно реализуется как связный список или дерево.
3. Добавление элементов: Если по этому индексу уже есть элементы (из-за
   коллизий), новая пара "ключ-значение" добавляется в существующий бакет. В
   случае связного списка новый элемент добавляется в конец списка, а если
   используется сбалансированное дерево (например, Red-Black Tree), то элемент
   будет вставлен в соответствующее место дерева.
4. Поиск элементов: При поиске значения по ключу сначала вычисляется его хеш-код
   и индекс массива. Затем HashMap проверяет бакет по этому индексу:
    1. Если бакет представляет собой связный список, он перебирает элементы
       списка до тех пор, пока не найдет нужный ключ.
    2. Если бакет представляет собой дерево, поиск выполняется с использованием
       алгоритма поиска дерева.

Пример работы метода цепочек

```java
import java.util.LinkedList;

class HashMapWithChaining<K, V> {
    private static class Entry<K, V> {
        K key;
        V value;

        Entry(K key, V value) {
            this.key = key;
            this.value = value;
        }
    }

    private LinkedList<Entry<K, V>>[] buckets;
    private int capacity;

    @SuppressWarnings("unchecked")
    public HashMapWithChaining(int capacity) {
        this.capacity = capacity;
        buckets = new LinkedList[capacity];
        for (int i = 0; i < capacity; i++) {
            buckets[i] = new LinkedList<>();
        }
    }

    public void put(K key, V value) {
        int index = getIndex(key);
        LinkedList<Entry<K, V>> bucket = buckets[index];

        // Проверяем наличие ключа и обновляем значение
        for (Entry<K, V> entry : bucket) {
            if (entry.key.equals(key)) {
                entry.value = value;
                return;
            }
        }

        // Если ключ не найден, добавляем новую пару
        bucket.add(new Entry<>(key, value));
    }

    public V get(K key) {
        int index = getIndex(key);
        LinkedList<Entry<K, V>> bucket = buckets[index];

        for (Entry<K, V> entry : bucket) {
            if (entry.key.equals(key)) {
                return entry.value;
            }
        }

        return null; // Ключ не найден
    }

    private int getIndex(K key) {
        return Math.abs(key.hashCode()) % capacity; // Вычисление индекса
    }
}
```

Преимущества метода цепочек<br>

1. Простота реализации: Метод цепочек легко реализовать с использованием
   стандартных структур данных (например, списков или деревьев).
2. Гибкость: Он позволяет хранить несколько значений для одного и того же
   индекса без необходимости перераспределения памяти.
3. Устойчивость к коллизиям: Даже если количество коллизий увеличивается,
   производительность операций вставки и поиска остается приемлемой.

Недостатки метода цепочек<br>

1. Память: Использование дополнительных структур данных для хранения элементов
   может привести к увеличению потребления памяти.
2. Производительность: В худшем случае (например, если все элементы попадают в
   один бакет) производительность операций может ухудшиться до O(n), где n —
   количество элементов в бакете.
3. Необходимость управления размером: При увеличении количества элементов может
   потребоваться перераспределение памяти и увеличение размера массива бакетов
   для поддержания производительности.

Заключение<br>
Метод цепочек — это эффективный способ обработки коллизий в хеш-таблицах. Он
позволяет сохранять производительность операций вставки и поиска на высоком
уровне даже при наличии коллизий за счет использования связанных списков или
деревьев для хранения пар "ключ-значение".

___
**Колизии**

Коллизия в контексте хеш-таблиц возникает, когда два или более ключа имеют
одинаковый хеш-код, что приводит к тому, что они попадают в один и тот же индекс
массива (бакета). Это может произойти по нескольким причинам:<br>

1. Ограниченное количество индексов<br>
   Хеш-таблицы используют фиксированный размер массива для хранения данных. Если
   количество возможных ключей превышает количество доступных индексов, то
   неизбежно будут коллизии. Например, если у вас есть 10 возможных индексов и
   15 различных ключей, то как минимум 5 ключей будут иметь одинаковый индекс.
2. Хеш-функция<br>
   Хеш-функция преобразует ключ в целое число (хеш-код), которое затем
   используется для определения индекса в массиве. Если хеш-функция не
   распределяет ключи равномерно по всем возможным индексам, это может привести
   к большому количеству коллизий. Например, если хеш-функция возвращает одно и
   то же значение для разных ключей или если она слишком проста (например,
   просто возвращает последний символ строки), это может привести к частым
   коллизиям.
3. Ограниченная длина хеша<br>
   Некоторые хеш-функции могут генерировать хеш-коды с ограниченной длиной (
   например, 32 бита), что также увеличивает вероятность коллизий. В этом случае
   множество различных входных данных будет отображаться на ограниченное
   количество выходных значений.
4. Сходство ключей<br>
   Если ключи имеют схожие характеристики (например, строки с одинаковыми
   префиксами или числа с одинаковыми значащими цифрами), это может привести к
   тому, что они будут генерировать одинаковые хеш-коды.

Примеры<br>

1. Простая хеш-функция: Если у вас есть строка "abc" и "cba", и ваша хеш-функция
   просто суммирует ASCII-коды символов, то обе строки могут дать один и тот же
   результат.
2. Ограниченный диапазон: Если вы используете целые числа в качестве ключей и
   ваша хеш-функция просто берет остаток от деления на 10 (например, key % 10),
   то все числа, заканчивающиеся на одну и ту же цифру (например, 12 и 22),
   будут иметь одинаковый индекс.
   Заключение<br>
   Коллизии — это естественная часть работы с хеш-таблицами из-за ограниченного
   количества индексов и особенностей хеш-функций. Эффективные алгоритмы
   обработки
   коллизий (такие как метод цепочек или открытая адресация) помогают
   минимизировать их влияние на производительность операций вставки и поиска в
   хеш-таблицах.

___
**Одинаковый hashcode**

В Java `HashMap` использует хеш-функцию для распределения ключей по "корзинам" (
buckets) в зависимости от их хеш-кода. Однако, разные объекты могут иметь
одинаковый хеш-код из-за особенностей хеширования. Это явление называется
коллизией.

Вот несколько причин, почему два ключа могут иметь одинаковый хеш-код:<br>

1. **Ограниченное пространство значений**: Хеш-функция преобразует объект в
   целое число (хеш-код), и поскольку количество возможных объектов значительно
   больше, чем количество возможных целых чисел, разные объекты могут быть
   преобразованы в одно и то же значение.
2. **Алгоритм хеширования**: Хеш-функции не идеальны и могут создавать коллизии.
   Например, если два объекта имеют одинаковые значения для всех полей, которые
   участвуют в вычислении хеш-кода, они будут иметь одинаковый хеш-код.
3. **Пользовательские классы**: Если вы создаете собственный класс и
   переопределяете метод `hashCode()`, вы можете случайно создать коллизии, если
   не будете учитывать все важные поля объекта.

Когда происходит коллизия (т.е. два ключа имеют одинаковый хеш-код), `HashMap`
использует дополнительную структуру данных (обычно связный список или дерево)
для хранения всех элементов с одинаковым хеш-кодом в одной корзине. При поиске
элемента по ключу `HashMap` сначала вычисляет хеш-код ключа, находит
соответствующую корзину и затем сравнивает ключи внутри этой корзины с помощью
метода `equals()`, чтобы найти нужный элемент.

Таким образом, хотя коллизии возможны, `HashMap` эффективно обрабатывает их,
обеспечивая корректное поведение при добавлении и поиске элементов.

### Сложности методов

В среднем, операция добавления, удаления и поиска элемента в HashMap имеют
временную сложность O(1). Однако, в худшем случае, когда все элементы попадают в
одну корзину, они будут связаны в связный список или дерево, и операция может
занимать время O(n), где n - количество элементов в корзине. Таким образом,
сложность операций в HashMap зависит от количества коллизий и хеш-функции.<br>
В среднем, сложность выборки элемента также составляет O(1), но в худшем случае
может достигать O(n).


> 8. Сложность получения элементов в ArrayList и LinkedList

**ARRAYLIST**

**ПРИНЦИП РАБОТЫ**

Каждый экземпляр ArrayList имеет емкость (CAPACITY). Емкость – это размер
массива, который используется для хранения элементов. По мере добавления
элементов в ArrayList его емкость автоматически увеличивается.

Когда массив заполняется, его ёмкость увеличивается. Новая ёмкость вычисляется
по формуле: старая ёмкость * 1.5 + 1. Например, если начальная ёмкость была 10,
то после расширения она станет 16.

При увеличении ёмкости создаётся новый массив, и все элементы из старого
копируются в новый, что является затратной операцией. Поэтому, если заранее
известно, что список будет большим, лучше сразу задать достаточную начальную
ёмкость.

Начальный размер capacity равен 10. Можно передать свое значение capacity
используя конструктор public ArrayList(int initialCapacity).

Удаление элементов из середины списка может быть затратной операцией, так как
все последующие элементы смещаются влево, что требует копирования данных. Также
стоит отметить, что размер внутреннего массива автоматически не уменьшается
после удаления элементов.

Метод trimToSize() позволяет уменьшить ёмкость ArrayList до фактического
количества элементов. Он полезен, если список часто изменяется и его размер
значительно сократился. Этот метод отсутствует в интерфейсе List, он доступен
только в ArrayList.

**АЛГОРИТМИЧЕСКАЯ СЛОЖНОСТЬ**

Алгоритмическая сложность операций с `ArrayList` в Java зависит от
конкретной операции. Вот основные операции и их сложности:

1. **Добавление элемента**:

- В конец списка: O(1) в среднем (если массив не переполнен). Если массив
  переполнен, происходит его увеличение, что требует O(n) времени, но это
  происходит редко, поэтому в среднем сложность остается O(1).
- В начало или в произвольную позицию: O(n) (необходимо сдвинуть элементы).

2. **Удаление элемента**:

- Из конца списка: O(1) (если не требуется уменьшение размера массива).
- Из начала или из произвольной позиции: O(n) (необходимо сдвинуть
  элементы).

3. **Поиск элемента**:

- O(n) (в худшем случае необходимо пройти по всему списку).

4. **Доступ к элементу по индексу**:

- O(1) (доступ к элементу по индексу осуществляется за константное время,
  так как `ArrayList` основан на массиве).

Таким образом, `ArrayList` хорошо подходит для операций доступа по индексу и
добавления элементов в конец списка, но менее эффективен для вставки и удаления
элементов в начале или середине списка из-за необходимости сдвига элементов.

Для `ArrayList` в Java сложность вставки и удаления элементов из середины списка
составляет O(n).

Вот подробности:

1. **Вставка элемента в середину**:

- Чтобы вставить элемент в середину списка, необходимо сначала сдвинуть все
  элементы, находящиеся после позиции вставки, на одну позицию вправо. Это
  требует O(n) времени в худшем случае, так как вам нужно пройти по всем
  элементам после вставляемого.
- После сдвига сам процесс вставки (изменение значения по индексу)
  выполняется за O(1).
- В итоге общая сложность вставки элемента в середину списка составляет O(
  n).

2. **Удаление элемента из середины**:

- Для удаления элемента из середины списка также необходимо сначала найти
  этот элемент (если у вас нет ссылки на него), что требует O(n) времени.
- После нахождения элемента необходимо сдвинуть все элементы, находящиеся
  после удаляемого, на одну позицию влево. Это также требует O(n) времени.
- Таким образом, общая сложность удаления элемента из середины списка
  составляет O(n).

В общем, операции вставки и удаления в середине `ArrayList` имеют линейную
сложность из-за необходимости сдвига элементов.

**LINKEDLIST**

LinkedList\<E> является реализацией двусвязного списка для интерфейса List
который работает эффективно как для вставки элементов, так и для удаления,
используя, как издержки, более сложную структуру.

**Принцип работы**

Добавление элементов в конец списка

- Создаётся новый узел (Node).
- Устанавливается значение (item) для нового узла.
- Ссылки узла добавляются в конец списка.
- Устанавливаются ссылки на предыдущий и следующий узлы (для нового и соседних
  узлов).

Добавление элемента в середину списка

- Проверяется индекс. Если он отрицательный или превышает размер списка,
  выбрасывается исключение IndexOutOfBoundsException.
- Если индекс равен размеру списка, элемент добавляется в конец.
- Вставка в середину происходит перед элементом с указанным индексом:
    - Метод node(index) находит узел по индексу.
    - Определяется место вставки (поиск узла идёт с начала или конца списка в
      зависимости от индекса).
    - Создаётся новый узел, и его ссылки устанавливаются между соседними узлами.
- Обновляются ссылки на предыдущие и следующие узлы для нового элемента и его
  соседей.
- Увеличивается размер списка.

Удаление элемента из связного списка по значению:

- Последовательно сравниваются элементы списка с заданным значением, начиная с
  первого узла.
- Когда найден узел с соответствующим значением, элемент сохраняется в отдельную
  переменную.
- Ссылки соседних узлов перенаправляются так, чтобы исключить удаляемый элемент.
- Очищаются ссылки и данные узла, который содержал удалённый элемент, и
  уменьшается размер списка.

**СЛОЖНОСТЬ**

Добавление и удаление из середины, доступ по индексу, значению происходит за
линейное время O(n), а из начала и конца за константное O(1). Так же, ввиду
реализации, данную коллекцию можно использовать как стек или очередь. Для этого
в ней реализованы соответствующие методы.

Алгоритмическая сложность операций с `LinkedList` в Java зависит от конкретной
операции. Вот основные операции и их сложности:

1. **Добавление элемента**:

    - В конец списка: O(1) (если у вас есть ссылка на последний элемент).
    - В начало списка: O(1).
    - В произвольную позицию: O(n) (необходимо пройти до нужной позиции).

2. **Удаление элемента**:

    - Из конца списка: O(1) (если у вас есть ссылка на последний элемент).
    - Из начала списка: O(1).
    - Из произвольной позиции: O(n) (необходимо пройти до нужной позиции).

3. **Поиск элемента**:

    - O(n) (необходимо пройти по всему списку в худшем случае).

4. **Доступ к элементу по индексу**:

    - O(n) (необходимо пройти по списку до нужного индекса).

Таким образом, `LinkedList` хорошо подходит для операций добавления и удаления
элементов в начале или конце списка, но неэффективен для доступа по индексу и
поиска элементов.

Для `LinkedList` в Java сложность вставки и удаления элемента из середины списка
составляет O(n).

Вот подробности:

1. **Вставка элемента в середину**:

    - Чтобы вставить элемент в середину списка, необходимо сначала найти
      позицию, куда вы хотите вставить элемент. Это требует O(n) времени, так
      как вам нужно пройти по списку до нужного индекса.
    - После того как вы нашли нужную позицию, сама операция вставки (изменение
      ссылок) выполняется за O(1).
    - В итоге общая сложность вставки элемента в середину списка - O(n).

2. **Удаление элемента из середины**:

    - Аналогично, для удаления элемента из середины списка сначала нужно найти
      этот элемент, что также требует O(n) времени.
    - После нахождения элемента операция удаления (изменение ссылок) выполняется
      за O(1).
    - Таким образом, общая сложность удаления элемента из середины списка также
      составляет O(n).

В общем, операции вставки и удаления в середине `LinkedList` имеют линейную
сложность из-за необходимости поиска нужной позиции.

Самый быстрый метод класса add(E element). Главным же достоинством
класса является скорость работы метода remove() на Iterator, после получения
его из LinkedList. Также очень быстро работает метод add(E element) на
ListIterator. Операция удаления из начала и конца списка выполняется достаточно
быстро, в отличие от операций поиска и извлечения.

Используется когда необходимо часто добавлять или удалять элементы, особенно в
начало списка. Либо когда нужна вставка элемента в конец за гарантированное
время.

Для манипуляций с первым и последним элементами списка в LinkedList\<E>
реализованы методы:

- **void addFirst(E e), void addLast(E e)** - добавление элементов в начало и
  конец списка;
- **E getFirst(), E getLast()** — извлекающие элементы;
- **E removeFirst(), E removeLast()** — удаляющие и извлекающие элементы;
- **E removeLastOccurrence(E elem), E removeFirstOccurrence(E elem)** —
  удаляющие и извлекающие элемент, первый или последний раз встречаемый
  в списке.

**_Отличия ArrayList и LinkedList:_**

`ArrayList` и `LinkedList` — это две реализации интерфейса `List` в Java, и у
них есть несколько ключевых отличий:

1. **Структура данных**:
    - `ArrayList` основан на массиве. Он использует динамический массив для
      хранения элементов, что позволяет быстро получать доступ к элементам по
      индексу.
    - `LinkedList` основан на связном списке. Каждый элемент (узел) содержит
      ссылку на следующий (и предыдущий) элемент, что позволяет легко добавлять
      и удалять элементы.

2. **Производительность**:
    - **Доступ по индексу**: В `ArrayList` доступ к элементам по индексу
      осуществляется за O(1), так как это просто обращение к массиву. В
      `LinkedList` доступ по индексу требует O(n), так как нужно пройти по
      узлам.
    - **Добавление/удаление элементов**: В `ArrayList` добавление элемента в
      конец списка обычно выполняется за O(1), но может потребовать O(n) в
      случае необходимости увеличения размера массива. Удаление элемента также
      может потребовать O(n) из-за необходимости сдвига элементов. В
      `LinkedList` добавление и удаление элементов (в начале, в конце или в
      середине) выполняется за O(1), если у вас есть ссылка на узел, но поиск
      узла требует O(n).

3. **Память**:
    - `ArrayList` использует меньше памяти на элемент, так как хранит только
      данные и индекс. Однако он может выделять больше памяти, чем фактически
      используется (из-за динамического массива).
    - `LinkedList` использует больше памяти на элемент, так как каждый узел
      хранит ссылки на следующий и предыдущий элементы.

4. **Итерация**:
    - Итерация по элементам в `ArrayList` обычно быстрее из-за лучшей
      локальности данных (элементы хранятся последовательно в памяти).
    - Итерация по `LinkedList` может быть медленнее из-за необходимости перехода
      от одного узла к другому.

5. **Использование**:
    - Используйте `ArrayList`, когда вам нужно часто получать доступ к элементам
      по индексу или когда размер списка не меняется часто.
    - Используйте `LinkedList`, когда вам нужно часто добавлять или удалять
      элементы из середины списка.

В общем, выбор между `ArrayList` и `LinkedList` зависит от конкретных требований
вашего приложения и того, какие операции вы будете выполнять чаще всего.

> 9. ExecutorService

`ExecutorService` в Java — это интерфейс, который является частью пакета
`java.util.concurrent` и предоставляет высокоуровневый механизм для управления
потоками. Он позволяет выполнять асинхронные задачи, управлять пулом потоков и
упрощает работу с многопоточностью.

### Основные характеристики `ExecutorService`:

1. **Управление потоками**: `ExecutorService` управляет пулом потоков, что
   позволяет повторно использовать потоки для выполнения задач, тем самым
   уменьшая накладные расходы на создание и уничтожение потоков.

2. **Асинхронное выполнение**: Вы можете отправлять задачи на выполнение и
   продолжать выполнять другие операции, не дожидаясь завершения этих задач.

3. **Разные типы задач**: Вы можете отправлять как `Runnable`, так и `Callable`
   задачи. `Callable` позволяет возвращать результат и обрабатывать исключения.

4. **Управление жизненным циклом**: `ExecutorService` предоставляет методы для
   управления жизненным циклом пула потоков, такие как `shutdown()` и
   `shutdownNow()`, которые позволяют корректно завершить выполнение задач.

5. **Фабрики для создания экземпляров**: Для создания экземпляров
   `ExecutorService` обычно используются статические методы класса `Executors`,
   такие как:
    - `Executors.newFixedThreadPool(int nThreads)`: создает пул фиксированного
      размера.
    - `Executors.newCachedThreadPool()`: создает пул, который создает новые
      потоки по мере необходимости, но повторно использует ранее созданные
      потоки.
    - `Executors.newSingleThreadExecutor()`: создает пул с одним потоком.

### Пример использования:

Вот простой пример использования `ExecutorService`:

```java
public class ExecutorServiceExample {
    public static void main(String[] args) {
        // Создаем ExecutorService с фиксированным количеством потоков
        ExecutorService executor = Executors.newFixedThreadPool(3);

        // Отправляем задачи на выполнение
        for (int i = 0; i < 5; i++) {
            final int taskId = i;
            executor.submit(() -> {
                System.out.println("Task " + taskId + " is running in "
                        + Thread.currentThread().getName());
                try {
                    Thread.sleep(1000); // Имитация работы
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                }
            });
        }

        // Завершаем ExecutorService
        executor.shutdown();
    }
}
```

В этом примере создается пул из трех потоков, и в него отправляются пять задач.
Каждая задача выполняется в одном из доступных потоков пула.

___

## Что такое задачи?

В контексте `ExecutorService` и многопоточности в Java, под "задачей"
подразумевается единица работы, которую необходимо выполнить. Задачи могут быть
представлены в виде объектов, реализующих интерфейсы `Runnable` или `Callable`.

### Основные характеристики задач:

1. **Единица работы**: Задача — это конкретная работа или операция, которую
   нужно выполнить. Это может быть что угодно: от простого вычисления до сложной
   обработки данных.

2. **Асинхронность**: Задачи могут выполняться асинхронно, что позволяет
   основному потоку продолжать выполнение других операций, не дожидаясь
   завершения задачи.

3. **Возврат результата**:
    - **Runnable**: Задачи, реализующие интерфейс `Runnable`, не возвращают
      результат. Метод `run()` этого интерфейса имеет тип `void`.
    - **Callable**: Задачи, реализующие интерфейс `Callable`, могут возвращать
      результат и могут выбрасывать проверяемые исключения. Метод `call()` этого
      интерфейса возвращает значение.

4. **Управление состоянием**: Каждая задача может находиться в одном из
   нескольких состояний (например, ожидает выполнения, выполняется или
   завершена). Это состояние можно отслеживать с помощью объекта типа `Future`,
   который возвращается при отправке задачи на выполнение.

### Примеры задач

Вот несколько примеров задач:

- **Вычислительные задачи**: Например, задача по вычислению факториала числа или
  сложению чисел в массиве.
- **Задачи ввода-вывода**: Чтение данных из файла или отправка HTTP-запроса.
- **Обработка данных**: Например, фильтрация списка объектов или преобразование
  данных.

### Пример использования задач

Вот пример создания и выполнения задач с использованием интерфейсов `Runnable` и
`Callable`:

```java
import java.util.concurrent.Callable;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Future;

public class TaskExample {
    public static void main(String[] args) {
        ExecutorService executor = Executors.newFixedThreadPool(2);

        // Задача Runnable
        Runnable runnableTask = () -> {
            System.out.println("Выполнение задачи Runnable");
        };

        // Задача Callable
        Callable<Integer> callableTask = () -> {
            System.out.println("Выполнение задачи Callable");
            return 42; // Возвращаем результат
        };

        // Отправляем задачи на выполнение
        executor.submit(runnableTask); // Для Runnable
        Future<Integer> future = executor.submit(callableTask); // Для Callable

        try {
            // Получаем результат выполнения задачи Callable
            Integer result = future.get();
            System.out.println("Результат задачи Callable: " + result);
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            executor.shutdown();
        }
    }
}
```

### Объяснение примера:

1. **Создание пула потоков**: Мы создаем пул из двух потоков с помощью метода
   `Executors.newFixedThreadPool(2)`.

2. **Определение задач**:
    - Мы определяем задачу типа `Runnable`, которая просто выводит сообщение.
    - Мы также определяем задачу типа `Callable`, которая выводит сообщение и
      возвращает значение 42.

3. **Отправка задач на выполнение**: Мы отправляем обе задачи на выполнение
   через метод `submit()`. Для задачи типа `Runnable` мы просто вызываем метод
   без ожидания результата, а для задачи типа `Callable` мы получаем объект типа
   `Future`.

4. **Получение результата**: Мы используем метод `get()` объекта `Future`, чтобы
   получить результат выполнения задачи типа `Callable`.

5. **Завершение работы пула**: В конце мы вызываем метод `shutdown()`, чтобы
   корректно завершить работу пула потоков.

### Заключение

Таким образом, под "задачей" в контексте многопоточности и использования
`ExecutorService` понимается конкретная работа или операция, которую необходимо
выполнить асинхронно. Задачи могут быть реализованы через интерфейсы `Runnable`
и `Callable`, что позволяет гибко управлять выполнением кода в многопоточной
среде.


___

### Асинхронные задачи

**Асинхронные задачи** — это задачи, которые выполняются независимо от основного
потока выполнения программы. Это означает, что основной поток может продолжать
свою работу, не дожидаясь завершения асинхронной задачи. Асинхронное выполнение
позволяет улучшить отзывчивость приложений, особенно в тех случаях, когда
требуется выполнение длительных операций, таких как сетевые запросы, операции
ввода-вывода или сложные вычисления.

### Основные характеристики асинхронных задач:

1. **Независимость**: Асинхронные задачи могут выполняться в фоновом режиме,
   позволяя основному потоку продолжать выполнение других операций. Это особенно
   полезно в пользовательских интерфейсах, где блокировка основного потока может
   привести к зависанию приложения.

2. **Обработка результатов**: После завершения асинхронной задачи можно
   обработать результаты выполнения. В Java для этого часто используются объекты
   `Future` и `Callable`, которые позволяют получить результат выполнения задачи
   или обработать исключения.

3. **Параллелизм**: Асинхронные задачи могут выполняться параллельно с другими
   задачами, что позволяет более эффективно использовать ресурсы системы и
   сокращать общее время выполнения.

4. **Управление временем ожидания**: Асинхронные задачи могут быть настроены на
   выполнение с тайм-аутами или отменой, что позволяет избежать зависания
   приложения при выполнении долгих операций.

### Примеры использования асинхронных задач:

1. **Сетевые запросы**: При выполнении HTTP-запросов к удаленному серверу можно
   использовать асинхронные задачи для того, чтобы не блокировать основной поток
   приложения во время ожидания ответа.

2. **Долгие вычисления**: Если приложение выполняет сложные вычисления (
   например, обработка больших объемов данных), эти операции можно вынести в
   асинхронные задачи, чтобы основной поток оставался отзывчивым.

3. **Работа с файлами**: Чтение и запись файлов может занять значительное время;
   использование асинхронных задач позволяет избежать блокировки
   пользовательского интерфейса во время этих операций.

### Пример в Java:

Вот пример использования асинхронной задачи с помощью `ExecutorService` и
`Callable`:

```java
import java.util.concurrent.Callable;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Future;

public class AsyncTaskExample {
    public static void main(String[] args) {
        ExecutorService executor = Executors.newSingleThreadExecutor();

        // Создаем асинхронную задачу
        Callable<Integer> task = () -> {
            Thread.sleep(2000); // Имитация долгой работы
            return 42; // Возвращаем результат
        };

        Future<Integer> future = executor.submit(task);

        // Основной поток продолжает выполнять другие операции
        System.out.println("Основной поток продолжает работу...");

        try {
            // Получаем результат выполнения асинхронной задачи
            Integer result = future.get(); // Это блокирует поток до получения результата
            System.out.println("Результат асинхронной задачи: " + result);
        } catch (InterruptedException | ExecutionException e) {
            e.printStackTrace();
        } finally {
            executor.shutdown();
        }
    }
}
```

В этом примере создается асинхронная задача, которая имитирует длительную
работу (с помощью `Thread.sleep`). Основной поток продолжает выполнение и
выводит сообщение на экран. После этого он ожидает завершения асинхронной задачи
и получает результат.

### Заключение

Асинхронные задачи являются важным инструментом для разработки отзывчивых и
эффективных приложений. Они позволяют выполнять длительные операции без
блокировки основного потока выполнения и обеспечивают более плавный
пользовательский опыт.
___

### Callable

`Callable` — это функциональный интерфейс в Java, представляющий собой
задачу, которая может быть выполнена асинхронно и возвращает результат. Он
является частью пакета `java.util.concurrent` и часто используется в сочетании с
`ExecutorService` для выполнения задач в фоновом режиме.

### Основные характеристики `Callable`:

1. **Возврат результата**: В отличие от интерфейса `Runnable`, который не
   возвращает результат (метод `run()` имеет тип `void`), метод `call()`
   интерфейса `Callable` возвращает значение. Это позволяет получать результат
   выполнения задачи.

2. **Обработка исключений**: Метод `call()` может выбрасывать проверяемые
   исключения (checked exceptions), что позволяет обрабатывать ошибки,
   возникающие во время выполнения задачи. В случае с `Runnable`, все исключения
   должны обрабатываться внутри метода `run()`.

3. **Использование с `Future`**: Когда задача, реализующая интерфейс `Callable`,
   отправляется на выполнение через `ExecutorService`, она возвращает объект
   типа `Future`. Этот объект позволяет проверять статус выполнения задачи и
   получать результат после ее завершения.

### Синтаксис

Интерфейс `Callable` имеет следующий синтаксис:

```java

@FunctionalInterface
public interface Callable<V> {
    V call() throws Exception;
}
```

Где `<V>` — это тип результата, который будет возвращен методом `call()`.

### Пример использования

Вот пример использования интерфейса `Callable` вместе с `ExecutorService`:

```java
import java.util.concurrent.Callable;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Future;

public class CallableExample {
    public static void main(String[] args) {
        ExecutorService executor = Executors.newFixedThreadPool(2);

        // Создаем задачу, реализующую Callable
        Callable<Integer> task = () -> {
            // Имитация длительной работы
            Thread.sleep(2000);
            return 42; // Возвращаем результат
        };

        // Отправляем задачу на выполнение
        Future<Integer> future = executor.submit(task);

        try {
            // Получаем результат выполнения задачи
            Integer result = future.get(); // Это блокирует поток до получения результата
            System.out.println("Результат асинхронной задачи: " + result);
        } catch (InterruptedException | ExecutionException e) {
            e.printStackTrace();
        } finally {
            executor.shutdown();
        }
    }
}
```

### Объяснение примера:

1. **Создание пула потоков**: Мы создаем пул из двух потоков с помощью метода
   `Executors.newFixedThreadPool(2)`.

2. **Определение задачи**: Мы определяем задачу, реализующую интерфейс
   `Callable`, которая имитирует длительную работу (с помощью метода
   `Thread.sleep`) и возвращает значение 42.

3. **Отправка задачи на выполнение**: Задача отправляется на выполнение через
   метод `submit()`, который возвращает объект типа `Future`.

4. **Получение результата**: Мы используем метод `get()` объекта `Future`, чтобы
   получить результат выполнения задачи. Этот метод блокирует текущий поток до
   тех пор, пока задача не завершится.

5. **Обработка исключений**: Мы обрабатываем возможные исключения, которые могут
   возникнуть при выполнении задачи или при получении результата.

6. **Завершение работы пула**: В конце мы вызываем метод `shutdown()`, чтобы
   корректно завершить работу пула потоков.

### Заключение

Интерфейс `Callable` является мощным инструментом для создания асинхронных задач
в Java, позволяя разработчикам выполнять фоновые операции и получать результаты
их выполнения. Он обеспечивает более гибкий подход по сравнению с интерфейсом
`Runnable`, особенно когда требуется обработка результатов или исключений.
___

## Задачи и потоки

Задачи и потоки в контексте многопоточности в Java тесно связаны между собой,
поскольку задачи представляют собой единицы работы, которые выполняются в
потоках. Давайте рассмотрим, как именно они связаны:

### 1. **Определение потоков и задач**

- **Поток**: Поток — это отдельная последовательность выполнения в программе.
  Каждый поток имеет свой собственный стек вызовов и может выполняться
  параллельно с другими потоками. В Java потоки создаются с помощью класса
  `Thread` или через интерфейсы, такие как `Runnable` и `Callable`.

- **Задача**: Задача — это конкретная работа или операция, которую нужно
  выполнить. В Java задачи могут быть реализованы через интерфейсы `Runnable` (
  для задач без результата) и `Callable` (для задач с результатом).

### 2. **Выполнение задач в потоках**

Когда вы отправляете задачу на выполнение в `ExecutorService`, она будет
выполнена в одном из потоков пула потоков. Вот как это работает:

- **Создание пула потоков**: При создании экземпляра `ExecutorService`, вы
  определяете пул потоков, который будет использоваться для выполнения задач.
  Например, с помощью метода `Executors.newFixedThreadPool(n)` создается пул из
  `n` потоков.

- **Отправка задач**: Когда вы отправляете задачу на выполнение (например, через
  метод `submit()`), `ExecutorService` выбирает один из доступных потоков из
  пула для выполнения этой задачи.

- **Асинхронное выполнение**: Задачи могут выполняться асинхронно, что означает,
  что основной поток программы может продолжать выполнение других операций, не
  дожидаясь завершения задачи.

### 3. **Параллелизм и многопоточность**

Использование задач и потоков позволяет реализовать параллелизм:

- **Параллельное выполнение**: Если у вас есть несколько задач, которые могут
  выполняться одновременно (например, обработка данных или выполнение сетевых
  запросов), вы можете отправить их на выполнение в пул потоков. Пул будет
  распределять задачи между доступными потоками, что позволяет выполнять их
  параллельно.

- **Управление ресурсами**: Пулы потоков помогают управлять ресурсами более
  эффективно. Вместо создания нового потока для каждой задачи (что может быть
  затратным по времени и ресурсам), вы можете повторно использовать существующие
  потоки для выполнения новых задач.

### 4. **Пример связи задач и потоков**

Вот пример кода, который демонстрирует связь между задачами и потоками:

```java
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

public class TaskAndThreadExample {
    public static void main(String[] args) {
        // Создаем пул из 3 потоков
        ExecutorService executor = Executors.newFixedThreadPool(3);

        // Определяем несколько задач
        Runnable task1 = () -> {
            System.out.println("Задача 1 выполняется в потоке: " + Thread.currentThread().getName());
        };

        Runnable task2 = () -> {
            System.out.println("Задача 2 выполняется в потоке: " + Thread.currentThread().getName());
        };

        Runnable task3 = () -> {
            System.out.println("Задача 3 выполняется в потоке: " + Thread.currentThread().getName());
        };

        // Отправляем задачи на выполнение
        executor.submit(task1);
        executor.submit(task2);
        executor.submit(task3);

        // Завершаем работу пула
        executor.shutdown();
    }
}
```

### Объяснение примера:

1. **Создание пула**: Мы создаем пул из трех потоков.

2. **Определение задач**: Мы определяем три задачи типа `Runnable`, выводящих
   имя потока, в котором она выполняется.

3. **Отправка задач**: Мы отправляем все три задачи на выполнение через метод
   `submit()`. Пул распределяет эти задачи между доступными потоками.

4. **Вывод информации о потоке**: Каждая задача выводит имя потока, который ее
   выполняет. Это демонстрирует, что одна и та же задача может выполняться в
   разных потоках.

5. **Завершение работы пула**: В конце мы вызываем метод `shutdown()`, чтобы
   корректно завершить работу пула.

### Заключение

Таким образом, задачи и потоки являются основными компонентами многопоточного
программирования в Java. Задачи представляют собой единицы работы, которые
необходимо выполнить, а потоки — это механизмы выполнения этих задач.
Использование пула потоков позволяет эффективно управлять выполнением множества
задач одновременно, обеспечивая параллелизм и оптимизацию использования ресурсов
системы.
___

### Future

Объект `Future`, возвращаемый интерфейсом `Callable` в Java, представляет собой
результат асинхронной операции. Он предоставляет методы для проверки состояния
выполнения задачи, получения результата и обработки возможных исключений,
которые могут возникнуть во время выполнения задачи. Давайте рассмотрим основные
аспекты объекта `Future` более подробно.

### Основные характеристики объекта `Future`

1. **Асинхронный результат**: Объект `Future` позволяет вам получить результат
   выполнения задачи, которая была отправлена на выполнение в пул потоков или
   другой механизм многопоточности. Поскольку задача выполняется асинхронно, вы
   можете продолжать выполнение других операций в основном потоке, не дожидаясь
   завершения задачи.

2. **Методы для управления состоянием**:
    - `isDone()`: Возвращает `true`, если задача завершена (независимо от того,
      была ли она выполнена успешно или завершилась с ошибкой).
    - `isCancelled()`: Возвращает `true`, если задача была отменена до ее
      завершения.
    - `cancel(boolean mayInterruptIfRunning)`: Пытается отменить выполнение
      задачи. Если задача уже выполняется и параметр `mayInterruptIfRunning`
      равен `true`, то выполнение задачи может быть прервано.

3. **Получение результата**:
    - `get()`: Блокирует текущий поток до тех пор, пока задача не завершится, и
      возвращает результат выполнения задачи. Если задача завершилась с
      исключением, метод `get()` выбросит это исключение.
    - `get(long timeout, TimeUnit unit)`: Блокирует текущий поток до тех пор,
      пока задача не завершится или не истечет указанный таймаут.

### Пример использования объекта Future

Вот пример кода, который демонстрирует использование интерфейса `Callable` и
объекта `Future`:

```java
import java.util.concurrent.Callable;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Future;

public class FutureExample {
    public static void main(String[] args) {
        ExecutorService executor = Executors.newFixedThreadPool(2);

        // Определяем задачу Callable
        Callable<Integer> task = () -> {
            // Имитация длительной операции
            Thread.sleep(2000);
            return 42; // Возвращаем результат
        };

        // Отправляем задачу на выполнение
        Future<Integer> future = executor.submit(task);

        try {
            // Получаем результат выполнения задачи
            Integer result = future.get(); // Это блокирует текущий поток до получения результата
            System.out.println("Результат: " + result);
        } catch (InterruptedException e) {
            System.err.println("Задача была прервана");
        } catch (ExecutionException e) {
            System.err.println("Ошибка при выполнении задачи: " + e.getCause());
        } finally {
            executor.shutdown();
        }
    }
}
```

### Объяснение примера:

1. **Создание пула потоков**: Мы создаем пул из двух потоков с помощью метода
   `Executors.newFixedThreadPool(2)`.

2. **Определение задачи**: Мы определяем задачу типа `Callable`, которая
   имитирует длительную операцию (например, задержку на 2 секунды) и возвращает
   значение 42.

3. **Отправка задачи**: Мы отправляем задачу на выполнение через метод
   `submit()`, который возвращает объект типа `Future`.

4. **Получение результата**: Мы вызываем метод `get()` у объекта `Future`, чтобы
   получить результат выполнения задачи. Этот вызов блокирует текущий поток до
   тех пор, пока задача не завершится.

5. **Обработка исключений**: Мы обрабатываем возможные исключения:
    - `InterruptedException`: Выбрасывается, если текущий поток был прерван во
      время ожидания результата.
    - `ExecutionException`: Выбрасывается, если задача завершилась с ошибкой; в
      этом случае мы можем получить причину ошибки через метод `getCause()`.

6. **Завершение работы пула**: В конце мы вызываем метод `shutdown()`, чтобы
   корректно завершить работу пула потоков.

### Заключение

Объект `Future` является важным компонентом многопоточного программирования в
Java, позволяя управлять асинхронными задачами и получать результаты их
выполнения. Он предоставляет удобные методы для проверки состояния задач и
обработки результатов или ошибок, что делает его полезным инструментом для
работы с параллельными вычислениями.
___

ExecutorService – это интерфейс Java, который предоставляет удобный способ
управления потоками исполнения. Он позволяет создавать пул потоков исполнения и
выполнять задачи в этих потоках.

Существует несколько ключевых реализаций ExecutorService:

ThreadPoolExecutor
ScheduledThreadPoolExecutor
CachedThreadPoolExecutor
ForkJoinPool

### **ThreadPoolExecutor**

ThreadPoolExecutor – это реализация интерфейса ExecutorService в Java, который
предоставляет пул потоков исполнения для выполнения задач в фоновом режиме.

ThreadPoolExecutor позволяет создать и настроить пул потоков исполнения с
определенным количеством потоков, а также управлять очередью задач. Он может
быть использован для выполнения задач в фоновом режиме, что может улучшить
производительность и реактивность вашего приложения.

### **ScheduledThreadPoolExecutor**

ScheduledThreadPoolExecutor – это реализация интерфейса ScheduledExecutorService
в Java, который предоставляет пул потоков исполнения для выполнения задач в
определенный момент времени или с определенной периодичностью.

ScheduledThreadPoolExecutor позволяет создать и настроить пул потоков исполнения
с определенным количеством потоков, а также управлять очередью задач. Он может
быть использован для выполнения регулярных задач в фоновом режиме, что может
улучшить производительность и реактивность вашего приложения.

### **CachedThreadPoolExecutor**

CachedThreadPoolExecutor – это реализация интерфейса ExecutorService в Java,
который предоставляет пул потоков исполнения для выполнения задач в фоновом
режиме.

CachedThreadPoolExecutor автоматически масштабирует количество потоков
исполнения в зависимости от количества задач, которые нужно выполнить. Если
задачи поступают слишком быстро и текущее количество потоков исполнения не может
справиться с ними, CachedThreadPoolExecutor создает новый поток исполнения,
чтобы обеспечить выполнение задачи. Если задачи не поступают достаточно быстро и
текущее количество потоков исполнения избыточно, CachedThreadPoolExecutor
автоматически удаляет потоки исполнения, чтобы уменьшить нагрузку на систему.

### **ForkJoinPool**

ForkJoinPool – это реализация ExecutorService в Java, которая используется для
параллельного выполнения задач. Эти задачи могут быть разбиты на более мелкие
подзадачи. Она позволяет использовать принцип “разделяй и властвуй” для более
эффективного использования многопроцессорных и многопоточных систем.

_**Основные компоненты ForkJoinPool:**_

**Пул потоков исполнения**

ForkJoinPool управляет пулом потоков исполнения, которые используются для
выполнения задач. Количество потоков исполнения в пуле задается при создании
экземпляра ForkJoinPool. Каждый поток в пуле имеет свой собственный стек
вызовов, что позволяет ForkJoinPool улучшить производительность в случае, когда
задачи могут быть разбиты на более мелкие подзадачи.

**Разбиение и объединение задач:**

ForkJoinPool поддерживает работу с задачами типа RecursiveAction и
RecursiveTask, которые представляют собой рекурсивно делимые задачи без
возвращаемого значения и с возвращаемым значением соответственно. Когда
ForkJoinPool получает задачу типа RecursiveTask, он разбивает ее на более мелкие
подзадачи, выполняет их параллельно в разных потоках и объединяет результаты
выполнения в единую итоговую задачу.


> 10. Atomic пакет Механизм под капотом (CAS)

В Java термин "atomic" (атомарный) относится к операциям, которые выполняются
как единое целое, без возможности прерывания. Это означает, что такие операции
являются неделимыми: они либо полностью выполняются, либо не выполняются вовсе.
Атомарные операции важны в контексте многопоточности, поскольку они помогают
избежать проблем с синхронизацией и состоянием гонки.

### Основные аспекты атомарности в Java

1. **Атомарные операции**: Атомарные операции гарантируют, что данные не будут
   изменены другими потоками во время выполнения операции. Например, если один
   поток обновляет значение переменной, другой поток не сможет увидеть
   промежуточное состояние этой переменной.

2. **Классы из пакета `java.util.concurrent.atomic`**: Java предоставляет
   несколько классов для работы с атомарными переменными в пакете
   `java.util.concurrent.atomic`. Эти классы обеспечивают атомарные операции над
   примитивными типами данных и объектами. Вот некоторые из них:
    - `AtomicInteger`: Атомарная целочисленная переменная.
    - `AtomicLong`: Атомарная переменная типа `long`.
    - `AtomicBoolean`: Атомарная булева переменная.
    - `AtomicReference<T>`: Атомарная ссылка на объект типа `T`.
    - `AtomicStampedReference<V>`: Атомарная ссылка на объект с меткой (
      стампом), что позволяет избежать проблем с состоянием гонки при обновлении
      ссылок.

3. **Методы атомарных классов**: Классы из пакета `java.util.concurrent.atomic`
   предоставляют методы для выполнения атомарных операций, такие как:
    - `get()`: Получает текущее значение.
    - `set(value)`: Устанавливает новое значение.
    - `incrementAndGet()`: Увеличивает текущее значение на 1 и возвращает новое
      значение.
    - `compareAndSet(expectedValue, newValue)`: Сравнивает текущее значение с
      ожидаемым значением и устанавливает новое значение, если они равны.

### Пример использования атомарных переменных

Вот пример кода, который демонстрирует использование класса `AtomicInteger`:

```java
import java.util.concurrent.atomic.AtomicInteger;

public class AtomicExample {
    public static void main(String[] args) {
        AtomicInteger atomicCounter = new AtomicInteger(0);

        // Создаем несколько потоков для увеличения счетчика
        Thread thread1 = new Thread(() -> {
            for (int i = 0; i < 1000; i++) {
                atomicCounter.incrementAndGet(); // Атомарное увеличение
            }
        });

        Thread thread2 = new Thread(() -> {
            for (int i = 0; i < 1000; i++) {
                atomicCounter.incrementAndGet(); // Атомарное увеличение
            }
        });

        // Запускаем потоки
        thread1.start();
        thread2.start();

        // Ждем завершения потоков
        try {
            thread1.join();
            thread2.join();
        } catch (InterruptedException e) {
            e.printStackTrace();
        }

        // Выводим итоговое значение счетчика
        System.out.println("Итоговое значение счетчика: " + atomicCounter.get());
    }
}
```

### Объяснение примера:

1. **Создание атомарного счетчика**: Мы создаем экземпляр класса
   `AtomicInteger`, инициализируя его значением 0.

2. **Создание потоков**: Мы создаем два потока, каждый из которых увеличивает
   счетчик на 1000 раз с помощью метода `incrementAndGet()`, который выполняет
   атомарное увеличение.

3. **Запуск потоков**: Мы запускаем оба потока.

4. **Ожидание завершения потоков**: Мы используем метод `join()` для ожидания
   завершения обоих потоков.

5. **Вывод результата**: После завершения работы потоков мы выводим итоговое
   значение счетчика. Поскольку мы использовали атомарную переменную, итоговое
   значение будет равно 2000, независимо от порядка выполнения потоков.

### Заключение

Атомарные операции и классы в Java обеспечивают безопасный доступ к общим данным
в многопоточной среде без необходимости использования явной синхронизации (
например, через блокировки). Это делает код более простым и эффективным при
работе с конкурентными задачами. Однако важно помнить, что атомарность не
гарантирует полной безопасности при работе с более сложными структурами данных
или логикой — в таких случаях может потребоваться дополнительная синхронизация.

## CAS

В Java "CAS" (Compare-And-Swap) — это атомарная операция, которая используется
для реализации механизмов синхронизации и управления состоянием в многопоточной
среде. CAS позволяет безопасно обновлять значение переменной, проверяя, равно ли
текущее значение ожидаемому значению, и только в этом случае заменяя его на
новое значение. Это делает CAS полезным для реализации неблокирующих алгоритмов
и структур данных.

### Как работает CAS

Операция CAS включает три параметра:

1. **Адрес переменной**: Адрес (или ссылка) на переменную, которую мы хотим
   обновить.
2. **Ожидаемое значение**: Значение, с которым мы сравниваем текущее значение
   переменной.
3. **Новое значение**: Значение, которое мы хотим установить, если текущее
   значение совпадает с ожидаемым.

Процесс работы CAS можно описать следующим образом:

1. Сравнить текущее значение переменной с ожидаемым значением.
2. Если они равны, обновить переменную новым значением.
3. Если они не равны, операция завершается без изменений.

### Пример использования CAS в Java

Java предоставляет поддержку CAS через классы из пакета
`java.util.concurrent.atomic`, такие как `AtomicInteger`, `AtomicBoolean`,
`AtomicReference` и другие. Эти классы используют внутренние механизмы CAS для
выполнения атомарных операций.

Вот пример использования `AtomicInteger` с методом `compareAndSet()`:

```java
import java.util.concurrent.atomic.AtomicInteger;

public class AtomicCASExample {
    public static void main(String[] args) {
        AtomicInteger atomicCounter = new AtomicInteger(0);

        // Создаем несколько потоков для увеличения счетчика
        Thread thread1 = new Thread(() -> {
            for (int i = 0; i < 1000; i++) {
                int currentValue;
                do {
                    currentValue = atomicCounter.get();
                } while (!atomicCounter.compareAndSet(currentValue, currentValue + 1));
            }
        });

        Thread thread2 = new Thread(() -> {
            for (int i = 0; i < 1000; i++) {
                int currentValue;
                do {
                    currentValue = atomicCounter.get();
                } while (!atomicCounter.compareAndSet(currentValue, currentValue + 1));
            }
        });

        // Запускаем потоки
        thread1.start();
        thread2.start();

        // Ждем завершения потоков
        try {
            thread1.join();
            thread2.join();
        } catch (InterruptedException e) {
            e.printStackTrace();
        }

        // Выводим итоговое значение счетчика
        System.out.println("Итоговое значение счетчика: " + atomicCounter.get());
    }
}
```

### Объяснение примера:

1. **Создание атомарного счетчика**: Мы создаем экземпляр класса
   `AtomicInteger`, инициализируя его значением 0.

2. **Создание потоков**: Мы создаем два потока, каждый из которых пытается
   увеличить счетчик на 1000 раз.

3. **Использование CAS**:
    - В каждом потоке мы используем цикл `do-while`, чтобы попытаться получить
      текущее значение счетчика.
    - Затем мы вызываем метод `compareAndSet(currentValue, currentValue + 1)`.
      Этот метод проверяет, равно ли текущее значение счетчика (
      `atomicCounter.get()`) ожидаемому значению (`currentValue`). Если да, то
      он устанавливает новое значение (`currentValue + 1`). Если нет — операция
      завершается без изменений, и цикл повторяется.

4. **Запуск потоков**: Мы запускаем оба потока.

5. **Ожидание завершения потоков**: Мы используем метод `join()` для ожидания
   завершения обоих потоков.

6. **Вывод результата**: После завершения работы потоков мы выводим итоговое
   значение счетчика. Поскольку мы использовали атомарную переменную с
   CAS-операцией, итоговое значение будет равно 2000.

### Преимущества и недостатки CAS

#### Преимущества:

- **Без блокировок**: CAS позволяет избежать использования блокировок (например,
  synchronized), что может улучшить производительность в многопоточных
  приложениях.
- **Простота реализации**: Многие алгоритмы могут быть реализованы проще с
  использованием CAS.

#### Недостатки:

- **Проблема "проверка-замена"**: Если несколько потоков одновременно пытаются
  обновить одно и то же значение, это может привести к частым неудачным попыткам
  обновления (потоки будут повторять операции), что может снизить
  производительность.
- **Необходимость повторных попыток**: В некоторых случаях может потребоваться
  много итераций для успешного выполнения операции из-за состояния гонки между
  потоками.

### Заключение

CAS является мощным инструментом для реализации неблокирующих алгоритмов и
структур данных в Java. Он позволяет безопасно обновлять значения переменных в
многопоточной среде без необходимости использования явных блокировок, что делает
код более эффективным и простым в понимании. Однако важно учитывать возможные
проблемы с производительностью при высокой конкуренции за ресурсы.


> 11. Scope бинов

В Spring Framework "scope" (область видимости) бинов определяет, как и когда
создаются экземпляры бинов, а также как они управляются контейнером Spring.
Области видимости позволяют контролировать жизненный цикл бинов и их доступность
в приложении. В Spring есть несколько основных областей видимости бинов:

### 1. Singleton (по умолчанию)

- **Описание**: В этой области видимости контейнер Spring создает только один
  экземпляр бина на весь контекст приложения. Этот экземпляр будет
  использоваться для всех запросов к этому бину. Этот экземпляр помещается в кэш
  таких же бинов (синглтонов) и все последующие вызовы бина с таким именем будут
  возвращать объект из кэша.
- **Жизненный цикл**: Бин создается при старте приложения и уничтожается при
  завершении работы приложения.
- **Пример**:
  ```java
  @Component
  public class MySingletonBean {
      // ...
  }
  ```

### 2. Prototype

- **Описание**: При этой области видимости каждый запрос к контейнеру Spring
  создает новый экземпляр бина. Это означает, что каждый раз, когда вы
  запрашиваете бин, вы получаете новый объект.
- **Жизненный цикл**: Бин создается при каждом запросе и уничтожается, когда на
  него больше нет ссылок (сборщик мусора).
- **Пример**:
  ```java
  @Component
  @Scope("prototype")
  public class MyPrototypeBean {
      // ...
  }
  ```

### 3. Request

- **Описание**: Эта область видимости используется в веб-приложениях. Бин
  создается для каждого HTTP-запроса и уничтожается по завершении обработки
  этого запроса.
- **Жизненный цикл**: Бин существует только в течение одного HTTP-запроса.
- **Пример**:
  ```java
  @Component
  @Scope("request")
  public class MyRequestBean {
      // ...
  }
  ```

### 4. Session

- **Описание**: Также используется в веб-приложениях. Бин создается для каждой
  HTTP-сессии и уничтожается, когда сессия завершается. Это полезно для хранения
  информации, специфичной для пользователя, в течение всего времени его сессии.
- **Жизненный цикл**: Бин существует в течение одной HTTP-сессии.
- **Пример**:
  ```java
  @Component
  @Scope("session")
  public class MySessionBean {
      // ...
  }
  ```

### 5. Global Session/Application

- **Описание**: Application: Бин с данной областью видимости создается один раз
  для всего сервлет-контекста. Это полезно для данных, которые должны быть
  общими для всех пользователей и сессий в приложении.
- **Жизненный цикл**: Бин существует в течение глобальной сессии.
- **Пример**:
  ```java
  @Component
  @Scope("globalSession")
  public class MyGlobalSessionBean {
      // ...
  }
  ```

### 6. WebSocket

Бин с данной областью видимости создается для каждой сессии WebSocket. Это
полезно для работы с данными, специфичными для каждой WebSocket-сессии.

### Применение области видимости

Чтобы задать область видимости для бина, можно использовать аннотацию `@Scope`
вместе с аннотацией `@Component`, `@Service`, `@Repository` или `@Controller`.
Например:

```java
import org.springframework.context.annotation.Scope;
import org.springframework.stereotype.Component;

@Component
@Scope("prototype")
public class MyPrototypeBean {
    // ...
}
```

### Примечания

1. По умолчанию все бины имеют область видимости "singleton", если не указано
   иное.
2. Области видимости "request", "session" и "globalSession" могут использоваться
   только в контексте веб-приложений (например, при использовании Spring MVC).
3. Для использования областей видимости "request" и "session" необходимо
   убедиться, что приложение настроено как веб-приложение.

### Заключение

Области видимости бинов в Spring позволяют гибко управлять жизненным циклом
объектов и их доступностью в приложении. Понимание этих областей помогает
разработчикам правильно проектировать архитектуру приложения и эффективно
управлять ресурсами.


> 12. Жизненный цикл бинов

В контексте Java и, в частности, фреймворка Spring, жизненный цикл бинов (или
компонентов) описывает последовательность этапов, через которые проходит бин от
его создания до уничтожения. Понимание этого жизненного цикла важно для
правильного управления ресурсами и поведения ваших компонентов. Давайте
рассмотрим основные этапы жизненного цикла бинов в Spring.

### 1. Создание бина

- **Инстанцирование**: Когда Spring контейнер создает бин, он использует
  конструктор класса для создания его экземпляра. Это может быть стандартный
  конструктор или конструктор с параметрами, если используется внедрение
  зависимостей.

### 2. Внедрение зависимостей

- **Внедрение зависимостей**: После создания бина Spring инжектирует все
  необходимые зависимости (например, другие бины или конфигурационные параметры)
  в созданный объект. Это может происходить через конструкторы, сеттеры или
  поля (в зависимости от конфигурации).

### 3. Инициализация

- **Методы инициализации**: После внедрения зависимостей Spring вызывает методы
  инициализации, если они определены. Это может быть:
    - Метод с аннотацией `@PostConstruct`, который будет вызван после завершения
      инъекции зависимостей.
    - Метод, указанный в атрибуте `init-method` в XML-конфигурации.

Пример использования `@PostConstruct`:

```java

@Component
public class MyBean {

    @PostConstruct
    public void init() {
        // Логика инициализации
    }
}
```

### 4. Использование

- **Использование бина**: На этом этапе бин готов к использованию в приложении.
  Он может обрабатывать запросы, выполнять бизнес-логику и взаимодействовать с
  другими компонентами.

### 5. Уничтожение

- **Методы уничтожения**: Когда контейнер Spring закрывается или бин больше не
  нужен, он проходит процесс уничтожения. На этом этапе могут быть вызваны
  методы для освобождения ресурсов или выполнения завершающих действий:
    - Метод с аннотацией `@PreDestroy`, который будет вызван перед уничтожением
      бина.
    - Метод, указанный в атрибуте `destroy-method` в XML-конфигурации.

Пример использования `@PreDestroy`:

```java

@Component
public class MyBean {

    @PreDestroy
    public void cleanup() {
        // Логика освобождения ресурсов
    }
}
```

### Полный жизненный цикл бина

1. **Создание**: Инстанцирование бина.
2. **Внедрение зависимостей**: Инъекция необходимых зависимостей.
3. **Инициализация**: Вызов методов инициализации.
4. **Использование**: Бин готов к использованию.
5. **Уничтожение**: Вызов методов для освобождения ресурсов перед уничтожением.

### Заключение

Понимание жизненного цикла бинов в Spring позволяет разработчикам эффективно
управлять ресурсами и поведением своих компонентов. Знание о том, когда
происходят различные этапы жизненного цикла, помогает избежать утечек памяти и
других проблем с производительностью приложения.

> 13. Проблема n+1

Проблема N+1 в Hibernate (и в других ORM, таких как JPA) — это распространенная
проблема производительности, которая возникает при выполнении запросов к базе
данных. Она связана с тем, как ORM загружает связанные сущности.

### Что такое проблема N+1?

Проблема N+1 возникает, когда для загрузки коллекции связанных сущностей
выполняется один запрос для основной сущности и затем отдельный запрос для
каждой из связанных сущностей. Это может привести к значительному увеличению
количества запросов к базе данных, что негативно сказывается на
производительности приложения.

#### Пример

Предположим, у вас есть две сущности: `Author` и `Book`, где один автор может
иметь много книг. Если вы хотите получить список всех авторов и их книг, вы
можете написать следующий код:

```java
class Demo {
    public void demo() {
        List<Author> authors = session
                .createQuery("FROM Author", Author.class)
                .getResultList();
        for (Author author : authors) {
            System.out.println(author.getName());
            for (Book book : author.getBooks()) {
                System.out.println(book.getTitle());
            }
        }
    }
}

```

В этом примере происходит следующее:

1. Выполняется один запрос для получения всех авторов (это 1 запрос).
2. Для каждого автора выполняется отдельный запрос для получения его книг (это N
   запросов, где N — количество авторов).

Таким образом, общее количество запросов к базе данных составляет 1 + N, что и
приводит к проблеме N+1.

### Почему это проблема?

Проблема N+1 может значительно ухудшить производительность приложения по
следующим причинам:

- **Увеличение времени выполнения**: Каждый дополнительный запрос требует
  времени на выполнение и обработку.
- **Нагрузка на базу данных**: Большое количество запросов может привести к
  увеличению нагрузки на базу данных и ухудшению ее производительности.
- **Сложность отладки**: Увеличение количества запросов может затруднить отладку
  и анализ производительности приложения.

### Как избежать проблемы N+1?

Существует несколько способов избежать проблемы N+1 в Hibernate:

1. **Использование `JOIN FETCH`**:
   Вы можете использовать `JOIN FETCH` в вашем HQL-запросе для загрузки
   связанных сущностей вместе с основной сущностью в одном запросе.

```java
class Demo {
    public void demo() {
        List<Author> authors = session
                .createQuery("SELECT a FROM Author a JOIN FETCH a.books", Author.class)
                .getResultList();
    }
}
```

2. **Использование `Entity Graphs`**:
   Вы можете определить графы сущностей, чтобы указать, какие связанные сущности
   загружать вместе с основной.

```java
class Demo {
    public void demo() {
        EntityGraph graph = entityManager.createEntityGraph(Author.class);
        graph.addAttributeNodes("books");
        Map<String, Object> properties = new HashMap<>();
        properties.put("javax.persistence.fetchgraph", graph);
        List<Author> authors = entityManager.find(Author.class, id, properties);
    }
}
```

3. **Настройка `FetchType`**:
   Вы можете настроить стратегию загрузки для коллекций в ваших сущностях с
   помощью аннотаций `@OneToMany`, `@ManyToMany` и т.д., указав
   `FetchType.EAGER` или `FetchType.LAZY`. Однако будьте осторожны с
   использованием `EAGER`, так как это может привести к другим проблемам с
   производительностью.

4. **Использование пакетной загрузки (Batch Fetching)**:
   Hibernate поддерживает пакетную загрузку связанных сущностей. Вы можете
   настроить размер пакета через конфигурацию или аннотации.
   ```java
   @BatchSize(size = 10)
   private Set<Book> books;
   ```

### Заключение

Проблема N+1 является распространенной проблемой при работе с ORM и может
значительно повлиять на производительность вашего приложения. Понимание этой
проблемы и использование подходящих стратегий загрузки поможет вам
оптимизировать взаимодействие с базой данных и улучшить общую производительность
вашего приложения.

> 13. Уровни кеширования в Hibernate

Hibernate предоставляет несколько уровней кеширования, которые помогают
оптимизировать производительность приложения, уменьшая количество обращений к
базе данных. Кеширование в Hibernate делится на два основных уровня: **первичный
кеш** и **вторичный кеш**. Давайте рассмотрим каждый из них подробнее.

### 1. Первичный кеш (First-Level Cache)

- **Описание**: Первичный кеш является неотъемлемой частью сессии Hibernate. Он
  хранит объекты, загруженные в текущей сессии, и обеспечивает их повторное
  использование без необходимости повторного запроса к базе данных.
- **Область видимости**: Первичный кеш существует только в пределах одной
  сессии. Как только сессия закрывается, все объекты в первичном кеше становятся
  недоступными.
- **Поведение**: Если вы запрашиваете один и тот же объект несколько раз в
  рамках одной сессии, Hibernate будет возвращать его из первичного кеша вместо
  того, чтобы выполнять новый запрос к базе данных.
- **Пример**:
  ```java
  Session session = sessionFactory.openSession();
  Author author1 = session.get(Author.class, 1); // Запрос к БД
  Author author2 = session.get(Author.class, 1); // Возвращается из первичного кеша
  ```

### 2. Вторичный кеш (Second-Level Cache)

- **Описание**: Вторичный кеш является опциональным и может быть настроен для
  хранения объектов между сессиями. Он позволяет кэшировать данные на уровне
  всей сессии фабрики (SessionFactory), что позволяет использовать одни и те же
  данные в разных сессиях.
- **Область видимости**: Вторичный кеш доступен для всех сессий, использующих
  одну и ту же фабрику сессий.
- **Настройка**: Для использования второго уровня кеша необходимо включить его в
  конфигурации Hibernate и выбрать провайдер кеша (например, Ehcache, Infinispan
  и т.д.).
- **Пример настройки**:
  ```xml
  <property name="hibernate.cache.use_second_level_cache">true</property>
  <property name="hibernate.cache.region.factory_class">org.hibernate.cache.ehcache.EhCacheRegionFactory</property>
  ```

### Кеширование коллекций

Вторичный кеш также может использоваться для кэширования коллекций. Вы можете
настроить стратегию кэширования для отдельных сущностей или коллекций через
аннотации или XML-конфигурацию.

#### Пример аннотации для вторичного кеша:

```java

@Entity
@Cacheable
@Cache(usage = CacheConcurrencyStrategy.READ_WRITE)
public class Author {
    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;

    private String name;

    @OneToMany(mappedBy = "author")
    @Cache(usage = CacheConcurrencyStrategy.READ_WRITE)
    private Set<Book> books;
}
```

### Стратегии кэширования

Hibernate поддерживает несколько стратегий кэширования для второго уровня:

1. **READ_ONLY**: Используется для объектов, которые не изменяются после их
   создания. Это наиболее эффективная стратегия.
2. **READ_WRITE**: Используется для объектов, которые могут изменяться.
   Hibernate управляет блокировками при записи.
3. **NONSTRICT_READ_WRITE**: Позволяет более высокую производительность за счет
   менее строгого контроля за изменениями.
4. **TRANSACTIONAL**: Поддерживает транзакционное поведение.

### Заключение

Кеширование в Hibernate — это мощный инструмент для повышения производительности
приложений за счет уменьшения количества обращений к базе данных. Понимание
уровней кеширования и их правильная настройка могут значительно улучшить время
отклика вашего приложения и снизить нагрузку на базу данных.


> Отличие HQL - запросов от native запросов

HQL (Hibernate Query Language) и native SQL (нативные SQL-запросы) — это два
способа выполнения запросов к базе данных в контексте Hibernate, ORM (
Object-Relational Mapping) фреймворка для Java. Оба подхода имеют свои
особенности, преимущества и недостатки. Давайте рассмотрим основные отличия
между ними.

### 1. Уровень абстракции

- **HQL**:
    - HQL является объектно-ориентированным языком запросов, который работает с
      сущностями и их свойствами, а не с таблицами и столбцами базы данных.
    - Запросы в HQL пишутся с использованием имен классов и их полей, что делает
      код более читаемым и понятным для разработчиков, знакомых с
      объектно-ориентированным программированием.

- **Native SQL**:
    - Native SQL использует стандартный SQL-синтаксис, который напрямую
      взаимодействует с базой данных.
    - Запросы пишутся с использованием имен таблиц и столбцов, что может быть
      менее удобно при работе с объектами.

### 2. Портируемость

- **HQL**:
    - HQL более портативен между различными СУБД (системами управления базами
      данных), так как он абстрагирует детали реализации конкретной базы данных.
    - Это позволяет легко менять СУБД без необходимости переписывать запросы.

- **Native SQL**:
    - Native SQL зависит от конкретной СУБД и ее диалекта. Это может привести к
      проблемам при переносе приложения на другую СУБД, так как могут
      потребоваться изменения в запросах.

### 3. Поддержка функций

- **HQL**:
    - HQL поддерживает большинство стандартных операций SQL, но может не
      поддерживать специфические функции или операторы некоторых СУБД.
    - Некоторые сложные запросы могут быть труднее реализовать в HQL.

- **Native SQL**:
    - Native SQL позволяет использовать все возможности конкретной СУБД, включая
      специфические функции и оптимизации.
    - Это может быть полезно для выполнения сложных запросов или оптимизации
      производительности.

### 4. Производительность

- **HQL**:
    - HQL может иметь накладные расходы из-за дополнительного уровня абстракции,
      но в большинстве случаев это незначительно.

- **Native SQL**:
    - Native SQL может быть более производительным для сложных запросов или
      операций, так как он напрямую взаимодействует с базой данных без
      дополнительных преобразований.

### Примеры

#### Пример HQL:

```java
String hql = "FROM Author WHERE name = :authorName";
Query query = session.createQuery(hql);
query.

setParameter("authorName","John Doe");

List<Author> authors = query.list();
```

#### Пример Native SQL:

```java
String sql = "SELECT * FROM authors WHERE name = :authorName";
Query query = session.createSQLQuery(sql).addEntity(Author.class);
query.

setParameter("authorName","John Doe");

List<Author> authors = query.list();
```

### Заключение

Выбор между HQL и native SQL зависит от конкретных требований вашего приложения.
Если вам нужна высокая портируемость и удобство работы с объектами, лучше
использовать HQL. Если же вам нужны специфические функции базы данных или вы
работаете с очень сложными запросами, то native SQL может быть более подходящим
выбором.

> 14. Оптимистические/Пессимистические блокировки

Оптимистические и пессимистические блокировки — это два подхода к управлению
конкурентным доступом к данным в многопользовательских системах, таких как базы
данных. Эти подходы помогают избежать конфликтов при одновременном изменении
данных несколькими пользователями.

### 1. Оптимистическая блокировка

**Описание**: Оптимистическая блокировка предполагает, что конфликты между
транзакциями происходят редко. Вместо того чтобы блокировать данные на время их
изменения, система позволяет пользователям изменять данные без блокировок, а
затем проверяет наличие конфликтов перед завершением транзакции.

**Как это работает**:

- При загрузке данных в приложение не устанавливаются блокировки.
- Пользователь вносит изменения и пытается сохранить их.
- Перед сохранением система проверяет, были ли данные изменены другими
  транзакциями с момента их загрузки.
- Если данные были изменены, транзакция отклоняется, и пользователь получает
  уведомление о конфликте. В противном случае изменения сохраняются.

**Преимущества**:

- Высокая производительность при низком уровне конфликтов.
- Меньше времени ожидания для пользователей, так как нет блокировок.

**Недостатки**:

- Возможность возникновения конфликтов и необходимость повторной попытки
  выполнения транзакции.
- Сложность обработки ошибок и управления состоянием приложения.

**Пример в Hibernate**:
В Hibernate оптимистическая блокировка может быть реализована с помощью версии (
version) поля:

```java

@Entity
public class Author {
    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;

    private String name;

    @Version
    private int version; // Поле версии для оптимистической блокировки
}
```

### 2. Пессимистическая блокировка

**Описание**: Пессимистическая блокировка предполагает, что конфликты между
транзакциями происходят часто. Поэтому система блокирует данные на время их
изменения, чтобы предотвратить доступ других транзакций к этим данным.

**Как это работает**:

- При загрузке данных в приложение устанавливаются блокировки на уровне базы
  данных.
- Другие транзакции не могут получить доступ к заблокированным данным до тех
  пор, пока текущая транзакция не завершится (не будет зафиксирована или
  отменена).

**Преимущества**:

- Гарантия целостности данных при высоком уровне конфликтов.
- Упрощение логики обработки ошибок, так как конфликты предотвращаются заранее.

**Недостатки**:

- Потенциально низкая производительность из-за ожидания освобождения блокировок.
- Возможность возникновения взаимных блокировок (deadlocks).

**Пример в Hibernate**:
В Hibernate пессимистическая блокировка может быть реализована с помощью
аннотации `@Lock`:

```java
class Demo {
    void demo() {
        Session session = sessionFactory.openSession();
        Transaction tx = session.beginTransaction();
        Author author = session.get(Author.class, 1, LockMode.PESSIMISTIC_WRITE);
        // Здесь author будет заблокирован для других транзакций

        // Изменения...
        author.setName("New Name");
        tx.commit();
        session.close();


    }
}

```

### Заключение

Выбор между оптимистической и пессимистической блокировкой зависит от конкретных
требований вашего приложения и ожидаемого уровня конкуренции за ресурсы.
Оптимистическая блокировка лучше подходит для сценариев с низким уровнем
конфликтов, тогда как пессимистическая — для сценариев с высокой конкуренцией за
данные. Правильное понимание этих подходов поможет вам эффективно управлять
доступом к данным и обеспечивать целостность вашей системы.

> 15. self injection и как работать с аннотациями в спринге, например
      Transaction
>16. Kafka про патриции чуть лучше
>17. Индексы в SQL
>18. Уровни транзакции
>19. ACID, проблемы
>20. Java Core:
     >

- устройство памяти и сборка мусора

> - Collection Framework и внутренняя работа коллекций
    >

- Работа с исключениями

> - Устройство и особенности StreamAPI
>21. Multithreading
     >

- Механизмы синхронизации: synchronized, volatile, atomic types

> - Пробелемы race condition и deadlock, способы решения
    >

- Optimistic и Pessimistic locking
  >

- Многопоточные коллекции, пулы потоков, Future и CompletableFutute

> 22. HashCode, equals()
