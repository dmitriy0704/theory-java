Что подучить/повторить:

> 1. SOLID (чуть лучше про D)

Принцип инверсии зависимостей (Dependency Inversion Principle, DIP) — это один
из пяти принципов SOLID, которые помогают разработчикам создавать гибкие и
поддерживаемые программные системы. DIP гласит:

Модули верхнего уровня не должны зависеть от модулей нижнего уровня. Оба типа
модулей должны зависеть от абстракций.
Абстракции не должны зависеть от деталей. Детали должны зависеть от абстракций.

**Объяснение принципа**<br>

Модули верхнего уровня — это те, которые содержат бизнес-логику и
высокоуровневые функции приложения.
Модули нижнего уровня — это те, которые реализуют конкретные детали, такие как
работа с базами данных, сетевыми запросами и т.д.
Согласно принципу инверсии зависимостей, модули верхнего уровня не должны
напрямую зависеть от конкретных реализаций модулей нижнего уровня. Вместо этого
они должны взаимодействовать через абстракции (например, интерфейсы или
абстрактные классы). Это позволяет уменьшить связанность между компонентами
системы и облегчает их тестирование и замену.

Пример
Рассмотрим простой пример без применения DIP:

```java
class Database {
    public void saveData(String data) {
        // Сохранение данных в базу
    }
}

class UserService {
    private Database database;

    public UserService() {
        this.database = new Database(); // Прямое создание зависимости
    }

    public void saveUser(String user) {
        database.saveData(user);
    }

}
```

В этом примере UserService напрямую зависит от класса Database. Если мы захотим
изменить способ хранения данных (например, использовать файл или удаленный
сервис), нам придется изменять код UserService.

Теперь применим принцип инверсии зависимостей:

```java
interface DataStorage {
    void saveData(String data);
}

class Database implements DataStorage {
    public void saveData(String data) {
        // Сохранение данных в базу
    }
}

class FileStorage implements DataStorage {
    public void saveData(String data) {
        // Сохранение данных в файл
    }
}

class UserService {
    private DataStorage dataStorage;

    public UserService(DataStorage dataStorage) { // Внедрение зависимости через конструктор
        this.dataStorage = dataStorage;
    }

    public void saveUser(String user) {
        dataStorage.saveData(user);
    }

}

```

В этом примере `UserService` зависит от абстракции DataStorage, а не от
конкретной реализации. Теперь мы можем легко заменить Database на FileStorage
или любую другую реализацию без изменения кода `UserService`.

**Преимущества применения DIP**

Уменьшение связанности: Компоненты системы становятся менее зависимыми друг от
друга.
Упрощение тестирования: Легче подменять зависимости на моки или стабы при
тестировании.
Гибкость и расширяемость: Легко добавлять новые реализации без изменения
существующего кода.
Улучшение читаемости кода: Код становится более понятным благодаря четкому
разделению интерфейсов и реализаций.
Принцип инверсии зависимостей является важным инструментом для создания
качественного программного обеспечения и способствует соблюдению других
принципов SOLID.

> 2. Можем как-то ограничить типы (про super)

В Java, как и в других языках программирования, концепция уровней обобщений (или
обобщенных типов) позволяет создавать классы, интерфейсы и методы, которые
работают с различными типами данных. Это достигается с помощью параметров типа (
type parameters). В контексте обобщений можно выделить верхний и нижний уровни
обобщений.

Верхний уровень обобщений (Upper Bound Wildcards)

Верхний уровень обобщений используется для ограничения типа, который может быть
использован в качестве параметра. Это делается с помощью ключевого слова
extends. Например:

```java
public void processList(List<? extends Number> list) {
    for (Number number : list) {
        System.out.println(number);
    }
}
```

В этом примере метод processList принимает список, содержащий объекты любого
типа, который является подтипом Number (например, Integer, Double и т.д.). Это
позволяет работать с различными типами данных, сохраняя при этом безопасность
типов.

Нижний уровень обобщений (Lower Bound Wildcards)

Нижний уровень обобщений используется для указания того, что параметр может быть
определён как определённый тип или любой его суперкласс. Это делается с помощью
ключевого слова super. Например:

```java
public void addNumbers(List<? super Integer> list) {
    list.add(1);
    list.add(2);
}
```

В этом примере метод addNumbers принимает список, который может содержать
объекты типа Integer или любого его суперкласса (например, Number или Object).
Это позволяет добавлять элементы в список без необходимости знать точный тип
списка.

Применение
Верхние границы полезны, когда вы хотите читать данные из структуры данных и не
хотите беспокоиться о том, какой конкретный подтип вы получаете.
Нижние границы полезны, когда вы хотите добавлять данные в структуру данных и
хотите гарантировать, что вы можете добавлять элементы определенного типа или
его подтипов.
Эти концепции позволяют создавать более гибкие и безопасные API в Java.

> 3. PECS

Принцип PECS (Producer Extends, Consumer Super) — это концепция, связанная с
использованием обобщений (generics) в Java, которая помогает правильно управлять
типами при работе с коллекциями и другими обобщенными структурами данных. Этот
принцип особенно полезен для понимания того, как использовать wildcard-тип (
неопределенный тип) в Java.

**Основные идеи PECS**

Producer Extends: Если вы хотите создать структуру данных, которая будет
производить элементы (например, возвращать элементы из коллекции), используйте
`? extends T`. Это означает, что вы можете использовать любой подтип T.

Consumer Super: Если вы хотите создать структуру данных, которая будет
потреблять элементы (например, добавлять элементы в коллекцию), используйте
`? super T`. Это означает, что вы можете использовать любой суперкласс T.

_Примеры_

**Producer Extends**

Предположим, у вас есть класс Animal и его подклассы Dog и Cat. Если у вас есть
метод, который возвращает список животных:

```java
class Animal {
}

class Dog extends Animal {
}

class Cat extends Animal {
}

public void printAnimals(List<? extends Animal> animals) {
    for (Animal animal : animals) {
        System.out.println(animal);
    }
}
```

В этом примере метод printAnimals принимает список животных `(List<? extends
Animal>)`. Это позволяет передавать списки как List<Dog>, так и List<Cat>,
поскольку оба класса являются подтипами Animal. Метод может безопасно читать
объекты из списка и обрабатывать их как объекты типа Animal.

**Consumer Super**

Теперь рассмотрим ситуацию, когда вам нужно добавить животных в коллекцию:

```java
public void addDogs(List<? super Dog> dogs) {
    dogs.add(new Dog());
    // dogs.add(new Animal()); // Ошибка компиляции
}
```

В этом примере метод addDogs принимает список, который может содержать объекты
типа Dog или любого его суперкласса (например, Animal или даже Object). Это
позволяет добавлять объекты типа Dog в список. Однако вы не можете добавлять
объекты типа Animal, потому что это может привести к нарушению типов.

В Java, когда вы используете обобщения (generics) с `? super T`, важно понимать,
как работает механизм типов и что именно разрешено добавлять в коллекцию.

Объяснение

Тип ? super T:

Когда вы используете `List<? super Dog>`, это означает, что вы можете передать
список, который может содержать объекты типа Dog или любого его суперкласса (
например, Animal или даже Object).  
Однако это также означает, что вы не можете добавлять объекты типа Animal,
потому что компилятор не может гарантировать, что этот список предназначен для
хранения объектов типа Animal. Он может быть списком, который предназначен
только для хранения объектов типа Dog.
Добавление объектов:

Когда вы добавляете объект типа Dog, это безопасно, потому что Dog является
подклассом и совместим с любым суперклассом.  
Однако если бы вы попытались добавить объект типа Animal, компилятор не смог бы
гарантировать, что это допустимо. Например, если у вас есть список типа
List<Animal>, он может содержать объекты других подклассов (например, Cat). Если
бы вы добавили объект типа Animal, это могло бы привести к ситуации, когда в
списке окажутся объекты разных типов (например, и Dog, и Cat), что нарушает
типизацию.

Пример

Рассмотрим следующий код:

```java
import java.util.ArrayList;
import java.util.List;

class Animal {
}

class Dog extends Animal {
}

class Cat extends Animal {
}

public class ConsumerSuperExample {
    public void addDogs(List<? super Dog> dogs) {
        dogs.add(new Dog()); // Это допустимо
        // dogs.add(new Animal()); // Ошибка компиляции
    }

    public static void main(String[] args) {
        List<Animal> animalList = new ArrayList<>();
        List<Dog> dogList = new ArrayList<>();

        ConsumerSuperExample example = new ConsumerSuperExample();

        example.addDogs(animalList); // Это допустимо
        // example.addDogs(dogList); // Ошибка компиляции
    }

}
```

Почему это происходит:  
Добавление объекта типа Dog:

Когда вы вызываете dogs.add(new Dog()), это безопасно, потому что метод ожидает
список, который может содержать объекты типа Dog или его суперклассы. Таким
образом, добавление объекта типа Dog всегда будет допустимо.
Попытка добавить объект типа Animal:

Если бы вы попытались добавить объект типа Animal, компилятор выдаст ошибку. Это
связано с тем, что метод не знает точно, какой именно тип данных хранится в
списке. Например:

```java
List<Animal> animalList = new ArrayList<>();
List<Cat> catList = new ArrayList<>();example.

addDogs(catList);
// Это вызвало бы ошибку компиляции
```

В этом случае метод не может гарантировать безопасность добавления объекта типа
Animal, так как он может быть несовместим с типом данных в списке.
Заключение
Таким образом, использование обобщений с типом ? super T позволяет вам добавлять
объекты определенного подкласса (в данном случае — объекты класса Dog), но не
позволяет добавлять объекты базового класса (Animal) из-за ограничений типизации
и обеспечения безопасности типов в Java.

**Применение PECS**  
Принцип PECS помогает разработчикам правильно выбирать между использованием
верхних (extends) и нижних (super) границ при работе с обобщениями. Вот
несколько рекомендаций:

- Используйте ? extends T, когда:
    - Вы читаете данные из структуры данных.
    - Вам нужно получить элементы из коллекции.

- Используйте ? super T, когда:
    - Вы записываете данные в структуру данных.
    - Вам нужно добавлять элементы в коллекцию.

Заключение

Принцип PECS является важным инструментом для работы с обобщениями в Java. Он
помогает избежать ошибок компиляции и делает код более безопасным и понятным.
Понимание этого принципа позволяет разработчикам более эффективно использовать
возможности языка Java и создавать гибкие архитектуры программного обеспечения.

> 4. Вызов без терминальной операции

Промежуточные операции не выполняются немедленно — они откладываются до тех пор,
пока не будет вызвана терминальная операция.  
Именно терминальная операция запускает выполнение потока. После ее вызова
происходит анализ операций в пайплайне, и определяется эффективная стратегия его
выполнения.

> 5. .parallel(), fork-join-poll

.parallel()

Для запуска потоков в параллельном режиме можно использовать методы
parallelStream() или parallel(). По умолчанию потоки выполняются
последовательно, но с явным вызовом одного из этих методов поток переключается в
параллельный режим.

Для разделения коллекций на части, которые обрабатываются параллельно, Java
использует Spliterator и его метод trySplit(). Этот метод разделяет данные на
подзадачи, которые затем могут быть распределены между несколькими потоками.
Каждая часть обрабатывается независимо, и результаты объединяются после
завершения работы всех потоков.

ForkJoinPool

Java использует ForkJoinPool для распределения задач параллельных потоков. Это
общий пул потоков, где задачи разбиваются на более мелкие фрагменты и
распределяются между потоками. Такой же подход применяется и в
CompletableFuture. При необходимости можно указать свой пул потоков, если
текущий пул перегружен или необходимо изменить его поведение.

> 6. GCRoot

В Java, GC Root (или корень сборщика мусора) — это объект, который является
начальной точкой для процесса сборки мусора (Garbage Collection, GC). Сборщик
мусора использует корни для определения, какие объекты в памяти все еще доступны
и могут быть использованы, а какие объекты больше не нужны и могут быть удалены.

Что такое GC Root?

GC Root — это набор объектов, которые всегда доступны и служат отправной точкой
для поиска всех достижимых объектов в памяти. Если объект не может быть
достигнут из любого из корней, он считается "мусором" и может быть удален
сборщиком мусора.

Примеры GC Root<br>
Вот несколько примеров объектов, которые считаются GC Root:

- Статические поля:<br>
  Объекты, на которые ссылаются статические поля классов. Например, если у вас
  есть статическое поле в классе, которое ссылается на объект, этот объект будет
  являться корнем.
- Активные потоки:<br>
  Объекты, связанные с активными потоками (например, текущий поток выполнения).
- Объекты в локальных переменных:<br>
  Объекты, на которые ссылаются локальные переменные методов. Пока метод
  выполняется и локальные переменные находятся в стеке вызовов, эти объекты
  считаются достижимыми.
- JNI ссылки:<br>
  Объекты, на которые ссылаются нативные методы через Java Native Interface (
  JNI).
- Объекты класса java.lang.Runtime:<br>
  Объект Runtime, который предоставляет информацию о среде выполнения Java.

Как работает сборка мусора?<br>
Сборщик мусора использует алгоритмы для определения достижимости объектов:

1. Начинает с GC Roots: Сборщик начинает с объектов GC Root и проходит по всем
   ссылкам от этих объектов.
2. Обходит граф объектов: Он рекурсивно проверяет все объекты, на которые
   ссылаются корни.
3. Определяет недостижимые объекты: Все объекты, которые не могут быть
   достигнуты из корней, помечаются как "мусор" и подлежат удалению.

Важность GC Root<br>
Понимание концепции GC Root важно для оптимизации работы приложения и управления
памятью:

1. Помогает разработчикам избегать утечек памяти.
2. Позволяет лучше понимать поведение сборщика мусора.
3. Способствует более эффективному управлению ресурсами в приложениях.

Как пометить объект "живым"<br>
В Java объекты помечаются как "живые" (или "достижимые") в контексте сборки
мусора (Garbage Collection) на основе ссылок на них. Если объект доступен через
одну или несколько ссылок, он считается живым и не может быть удален сборщиком
мусора. Вот несколько способов, как можно пометить объект как живой:

1. Создание ссылок на объект<br>
   Чтобы объект считался живым, необходимо создать хотя бы одну ссылку на него.
   Например:

```java
class MyObject {
// Поля и методы
}

public class Main {
    public static void main(String[] args) {
        MyObject obj = new MyObject(); // Создаем объект и сохраняем ссылку на него
// Объект obj считается "живым", пока существует ссылка на него
    }
}
```

В этом примере obj является ссылкой на экземпляр MyObject, и пока эта ссылка
существует, объект будет считаться живым.

2. Использование коллекций<br>
   Объекты могут быть помечены как живые, если они хранятся в коллекциях, таких
   как списки, множества или карты:

```java
import java.util.ArrayList;
import java.util.List;

class MyObject {
    // Поля и методы
}

public class Main {
    public static void main(String[] args) {
        List<MyObject> list = new ArrayList<>();
        MyObject obj = new MyObject();
        list.add(obj); // Объект obj теперь считается "живым", так как он хранится в списке
    }
}
```

3. Статические поля<br>
   Если объект хранится в статическом поле класса, он также будет считаться
   живым:

```java
class MyClass {
    static MyObject staticObj = new MyObject(); // Статическое поле хранит ссылку на объект
}

public class Main {
    public static void main(String[] args) {
        // Объект staticObj считается "живым" благодаря статической ссылке
    }
}
```

4. Передача объектов в методы<br>
   Когда вы передаете объект в метод, он также считается живым, пока метод
   выполняется:

```java
class MyObject {
    // Поля и методы
}

public class Main {
    public static void process(MyObject obj) {
        // Объект obj считается "живым" внутри этого метода
    }

    public static void main(String[] args) {
        MyObject myObj = new MyObject();
        process(myObj); // Передаем объект в метод
    }
}

```

5. Использование внешних библиотек или фреймворков
   Некоторые фреймворки и библиотеки могут управлять жизненным циклом объектов и
   поддерживать ссылки на них для обеспечения их доступности.

Заключение<br>
Объекты в Java считаются "живыми", если на них существуют ссылки из других
объектов или переменных. Чтобы пометить объект как живой, достаточно создать
хотя бы одну ссылку на него — это может быть локальная переменная, элемент
коллекции или статическое поле класса. Как только все ссылки на объект будут
удалены (например, переменные выйдут из области видимости или будут присвоены
null), объект станет недостижимым и может быть удален сборщиком мусора.

GC Root — это ключевая концепция в управлении памятью Java и сборке мусора. Она
определяет начальные точки для поиска достижимых объектов и помогает сборщику
мусора эффективно освобождать память от ненужных объектов.

> 7. HashMap чуть лучше про то как устроен, и сложности методов

HashMap в Java — это структура данных, которая реализует интерфейс Map и
использует хеш-таблицу для хранения пар "ключ-значение". Она обеспечивает
быстрый доступ к элементам по ключу, что делает её одной из самых популярных
реализаций Map. Давайте рассмотрим, как работает HashMap, его основные
характеристики и внутренние механизмы.

Основные характеристики HashMap

1. Ключи и значения: HashMap хранит данные в виде пар "ключ-значение". Каждый
   ключ должен быть уникальным, но значения могут повторяться.
2. Неупорядоченность: Элементы в HashMap не имеют определенного порядка. Порядок
   вставки не сохраняется.
3. Допускает null: HashMap позволяет использовать один null в качестве ключа и
   любое количество null в качестве значений.
4. Не синхронизирован: HashMap не является потокобезопасным. Если несколько
   потоков одновременно изменяют его, необходимо использовать внешнюю
   синхронизацию.

Как работает HashMap

1. Хеширование
   Когда вы добавляете пару "ключ-значение" в HashMap, ключ проходит через
   хеш-функцию, которая вычисляет хеш-код для этого ключа. Хеш-код — это целое
   число, которое используется для определения индекса в массиве (хеш-таблице),
   где будет храниться значение.

```java
int hash = key.hashCode();
int index = hash % array.length; // Определяем индекс в массиве
```

2. Обработка коллизий
   Коллизия происходит, когда два разных ключа имеют одинаковый хеш-код и,
   следовательно, попадают в один и тот же индекс массива. Для обработки
   коллизий HashMap использует метод цепочек (chaining):

    1. Каждый элемент массива представляет собой связный список (или дерево с
       Java 8 и выше), который хранит все пары "ключ-значение", имеющие
       одинаковый индекс.
    2. Если возникает коллизия, новая пара добавляется в конец связного списка
       или дерева.
3. Резервирование места
   Когда количество элементов в HashMap превышает определенный порог (обычно 75%
   от текущей емкости), происходит увеличение емкости:
    1. Создается новый массив большего размера.
    2. Все существующие элементы перераспределяются по новому массиву на основе
       их хеш-кодов.
4. Время доступа
   В среднем время доступа к элементам по ключу составляет O(1) благодаря
   использованию хеширования. Однако в худшем случае (например, если все
   элементы попадают в одну цепочку) время доступа может составлять O(n). Чтобы
   избежать этого, важно правильно выбирать размер начального массива и
   коэффициент загрузки.

Пример использования HashMap

```java
import java.util.HashMap;

public class Main {
    public static void main(String[] args) {
        HashMap<String, Integer> map = new HashMap<>();

        // Добавление элементов
        map.put("Alice", 30);
        map.put("Bob", 25);
        map.put("Charlie", 35);

        // Получение элемента
        System.out.println("Age of Alice: " + map.get("Alice"));

        // Проверка наличия ключа
        if (map.containsKey("Bob")) {
            System.out.println("Bob is in the map.");
        }

        // Удаление элемента
        map.remove("Charlie");

        // Итерация по элементам
        for (String key : map.keySet()) {
            System.out.println(key + ": " + map.get(key));
        }
    }
}
```

Заключение
HashMap — это мощная структура данных для хранения пар "ключ-значение" с быстрым
доступом к элементам по ключу. Она использует хеширование для обеспечения
высокой производительности и обрабатывает коллизии с помощью цепочек. Понимание
работы HashMap поможет вам эффективно использовать её в ваших Java-приложениях.

___


В HashMap в Java ключи должны быть уникальными. Если вы попытаетесь добавить
пару "ключ-значение" с уже существующим ключом, новое значение заменит старое.
Однако, если вам нужно хранить несколько значений для одного ключа, вы можете
использовать несколько подходов.

1. Использование HashMap с List или Set
   Один из самых распространенных способов обработки одинаковых ключей — это
   использование HashMap, где значениями являются коллекции (например, List или
   Set). Это позволяет хранить несколько значений для одного ключа.

Пример с использованием ArrayList

```java
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;

public class Main {
    public static void main(String[] args) {
        HashMap<String, List<Integer>> map = new HashMap<>();

        // Добавление значений
        addValue(map, "Alice", 30);
        addValue(map, "Alice", 31);
        addValue(map, "Bob", 25);
        addValue(map, "Charlie", 35);
        addValue(map, "Alice", 32);

        // Вывод значений
        for (String key : map.keySet()) {
            System.out.println(key + ": " + map.get(key));
        }
    }

    private static void addValue(HashMap<String, List<Integer>> map, String key, Integer value) {
        // Получаем список значений по ключу
        List<Integer> values = map.get(key);

        // Если список не существует, создаем новый
        if (values == null) {
            values = new ArrayList<>();
            map.put(key, values);
        }

        // Добавляем новое значение в список
        values.add(value);
    }
}
```

2. Использование HashMap с Set

Если вам нужно хранить уникальные значения для каждого ключа (без дубликатов),
вы можете использовать HashSet вместо ArrayList.

```java
import java.util.HashMap;
import java.util.HashSet;
import java.util.Set;

public class Main {
    public static void main(String[] args) {
        HashMap<String, Set<Integer>> map = new HashMap<>();

        // Добавление значений
        addValue(map, "Alice", 30);
        addValue(map, "Alice", 31);
        addValue(map, "Bob", 25);
        addValue(map, "Charlie", 35);
        addValue(map, "Alice", 30); // Дубликат не будет добавлен

        // Вывод значений
        for (String key : map.keySet()) {
            System.out.println(key + ": " + map.get(key));
        }
    }

    private static void addValue(HashMap<String, Set<Integer>> map, String key, Integer value) {
        // Получаем множество значений по ключу
        Set<Integer> values = map.get(key);

        // Если множество не существует, создаем новое
        if (values == null) {
            values = new HashSet<>();
            map.put(key, values);
        }

        // Добавляем новое значение в множество
        values.add(value);
    }
}
```

Заключение
Если вам нужно обрабатывать одинаковые пары ключ-значение в Java с
использованием HashMap, вы можете использовать коллекции (например, List или
Set) в качестве значений. Это позволит вам хранить несколько значений для одного
ключа и управлять ими более гибко. Выбор между списком и множеством зависит от
ваших требований к уникальности значений.






___

Как работает обработка коллизий в HashMap
Когда два ключа имеют одинаковый хеш-код и попадают в один и тот же индекс
массива, HashMap создает связный список (или дерево) для хранения всех пар "
ключ-значение", которые имеют одинаковый индекс. В Java 8 и выше, если
количество элементов в цепочке превышает определенный порог (обычно 8), HashMap
преобразует связный список в сбалансированное дерево (например, Red-Black Tree)
для улучшения производительности.

Пример обработки коллизий
Вот пример, который демонстрирует, как HashMap обрабатывает коллизии:

```java
import java.util.HashMap;

public class Main {
    public static void main(String[] args) {
        HashMap<Key, String> map = new HashMap<>();

        // Создаем ключи с одинаковым хеш-кодом
        Key key1 = new Key(1);
        Key key2 = new Key(2);

        // Добавляем пары "ключ-значение"
        map.put(key1, "Value for key 1");
        map.put(key2, "Value for key 2");

        // Вывод значений
        System.out.println("Key 1: " + map.get(key1));
        System.out.println("Key 2: " + map.get(key2));
    }
}

class Key {
    private int id;

    public Key(int id) {
        this.id = id;
    }

    @Override
    public int hashCode() {
        return 1; // Оба ключа будут иметь одинаковый хеш-код
    }

    @Override
    public boolean equals(Object obj) {
        if (this == obj) return true;
        if (!(obj instanceof Key)) return false;
        Key other = (Key) obj;
        return this.id == other.id;
    }
}
```

Объяснение кода

1. Класс Key: Мы создаем класс Key, который имеет метод hashCode(), возвращающий
   одно и то же значение (в данном случае 1). Это означает, что все экземпляры
   этого класса будут иметь одинаковый хеш-код.
2. Добавление пар: Мы добавляем два разных ключа (key1 и key2) в HashMap.
   Несмотря на то что они разные объекты, они имеют одинаковый хеш-код.
3. Обработка коллизий: Когда мы добавляем оба ключа в HashMap, они будут
   храниться в одной цепочке (связанном списке или дереве), так как их хеш-коды
   совпадают.
4. Получение значений: Мы можем получить значения по каждому из ключей без
   проблем, так как метод equals() также переопределен для сравнения объектов по
   их идентификатору.

Заключение
В случае коллизий в HashMap, структура данных автоматически обрабатывает их с
помощью связных списков или деревьев. Вам не нужно беспокоиться о том, как
именно это происходит — просто используйте уникальные ключи для хранения
значений. Если вам нужно хранить несколько значений для одного ключа,
рассмотрите возможность использования коллекций (например, List или Set) как
значений.


___

**Бакеты**

В контексте HashMap в Java "бакеты" (или "ведра") — это структуры данных,
которые используются для хранения пар "ключ-значение". Бакеты помогают
организовать данные в HashMap и обеспечивают эффективный доступ к ним. Давайте
рассмотрим, как это работает.

Основные концепции

1. Хеширование: Когда вы добавляете пару "ключ-значение" в HashMap, сначала
   вычисляется хеш-код ключа с помощью метода hashCode(). Этот хеш-код затем
   используется для определения индекса (или бакета) в массиве, который хранит
   все бакеты.

2. Массив бакетов: HashMap использует массив для хранения бакетов. Каждый
   элемент массива может содержать один или несколько объектов (пары "
   ключ-значение"). Индекс массива определяется на основе хеш-кода ключа.

3. Обработка коллизий: Если два или более ключа имеют одинаковый хеш-код и,
   следовательно, попадают в один и тот же индекс массива (это называется
   коллизией), HashMap использует метод цепочек (chaining) для обработки этих
   коллизий. В этом случае все пары "ключ-значение", которые имеют одинаковый
   индекс, будут храниться в связанном списке или дереве внутри соответствующего
   бакета.

Пример работы с бакетами

```java
import java.util.HashMap;

public class Main {
    public static void main(String[] args) {
        HashMap<String, String> map = new HashMap<>();

        // Добавление пар "ключ-значение"
        map.put("key1", "value1");
        map.put("key2", "value2");
        map.put("key3", "value3");

        // Получение значения по ключу
        System.out.println(map.get("key1")); // Вывод: value1
    }
}
```

Как это выглядит под капотом

1. Добавление элемента:

    1. При добавлении "key1" вычисляется его хеш-код.
    2. На основе этого хеш-кода определяется индекс в массиве.
    3. Если по этому индексу еще нет других элементов, создается новый бакет и
       добавляется пара "key1" : "value1".

2. Обработка коллизий:

    1. Если вы добавите другой ключ, который имеет тот же хеш-код (например, "
       key4"),
       он попадет в тот же индекс.
    2. В этом случае HashMap создаст связанный список или дерево внутри этого
       бакета и
       добавит пару "key4" : "value4" туда.

3. Получение элемента:

    1. При получении значения по ключу сначала вычисляется его хеш-код.
    2. Затем определяется индекс массива.
    3. Если по этому индексу есть несколько элементов (из-за коллизий), HashMap
       будет перебирать элементы в связанном списке или дереве до тех пор, пока
       не найдет нужный ключ.

Заключение
Бакеты в HashMap — это важная часть структуры данных, которая позволяет
эффективно хранить и извлекать пары "ключ-значение". Они обеспечивают обработку
коллизий и позволяют поддерживать производительность операций вставки и поиска
на высоком уровне.


___ 

Метод цепочек для обработки колизий
Метод цепочек (chaining) — это один из способов обработки коллизий в
хеш-таблицах, таких как HashMap в Java. Когда два или более ключа имеют
одинаковый хеш-код и, следовательно, попадают в один и тот же индекс массива (
бакета), метод цепочек позволяет хранить все эти пары "ключ-значение" в одной
структуре данных, связанной с этим индексом.

Как работает метод цепочек

1. Хеширование: Когда вы добавляете пару "ключ-значение" в HashMap, сначала
   вычисляется хеш-код ключа с помощью метода hashCode(). Этот хеш-код
   используется для определения индекса в массиве бакетов.
2. Создание бакета: Если по этому индексу еще нет других элементов, создается
   новый бакет. В Java это обычно реализуется как связный список или дерево.
3. Добавление элементов: Если по этому индексу уже есть элементы (из-за
   коллизий), новая пара "ключ-значение" добавляется в существующий бакет. В
   случае связного списка новый элемент добавляется в конец списка, а если
   используется сбалансированное дерево (например, Red-Black Tree), то элемент
   будет вставлен в соответствующее место дерева.
4. Поиск элементов: При поиске значения по ключу сначала вычисляется его хеш-код
   и индекс массива. Затем HashMap проверяет бакет по этому индексу:

    1. Если бакет представляет собой связный список, он перебирает элементы
       списка до тех пор, пока не найдет нужный ключ.
    2. Если бакет представляет собой дерево, поиск выполняется с использованием
       алгоритма поиска дерева.

Пример работы метода цепочек

```java
import java.util.LinkedList;

class HashMapWithChaining<K, V> {
    private static class Entry<K, V> {
        K key;
        V value;

        Entry(K key, V value) {
            this.key = key;
            this.value = value;
        }
    }

    private LinkedList<Entry<K, V>>[] buckets;
    private int capacity;

    @SuppressWarnings("unchecked")
    public HashMapWithChaining(int capacity) {
        this.capacity = capacity;
        buckets = new LinkedList[capacity];
        for (int i = 0; i < capacity; i++) {
            buckets[i] = new LinkedList<>();
        }
    }

    public void put(K key, V value) {
        int index = getIndex(key);
        LinkedList<Entry<K, V>> bucket = buckets[index];

        // Проверяем наличие ключа и обновляем значение
        for (Entry<K, V> entry : bucket) {
            if (entry.key.equals(key)) {
                entry.value = value;
                return;
            }
        }

        // Если ключ не найден, добавляем новую пару
        bucket.add(new Entry<>(key, value));
    }

    public V get(K key) {
        int index = getIndex(key);
        LinkedList<Entry<K, V>> bucket = buckets[index];

        for (Entry<K, V> entry : bucket) {
            if (entry.key.equals(key)) {
                return entry.value;
            }
        }

        return null; // Ключ не найден
    }

    private int getIndex(K key) {
        return Math.abs(key.hashCode()) % capacity; // Вычисление индекса
    }
}
```

Преимущества метода цепочек

1. Простота реализации: Метод цепочек легко реализовать с использованием
   стандартных структур данных (например, списков или деревьев).

2. Гибкость: Он позволяет хранить несколько значений для одного и того же
   индекса
   без необходимости перераспределения памяти.

3. Устойчивость к коллизиям: Даже если количество коллизий увеличивается,
   производительность операций вставки и поиска остается приемлемой.

Недостатки метода цепочек

1. Память: Использование дополнительных структур данных для хранения элементов
   может привести к увеличению потребления памяти.

2. Производительность: В худшем случае (например, если все элементы попадают в
   один
   бакет) производительность операций может ухудшиться до O(n), где n —
   количество
   элементов в бакете.

3. Необходимость управления размером: При увеличении количества элементов может
   потребоваться перераспределение памяти и увеличение размера массива бакетов
   для
   поддержания производительности.

Заключение

Метод цепочек — это эффективный способ обработки коллизий в хеш-таблицах. Он
позволяет сохранять производительность операций вставки и поиска на высоком
уровне даже при наличии коллизий за счет использования связанных списков или
деревьев для хранения пар "ключ-значение".

___
Колизии

Коллизия в контексте хеш-таблиц возникает, когда два или более ключа имеют
одинаковый хеш-код, что приводит к тому, что они попадают в один и тот же индекс
массива (бакета). Это может произойти по нескольким причинам:

1. Ограниченное количество индексов
   Хеш-таблицы используют фиксированный размер массива для хранения данных. Если
   количество возможных ключей превышает количество доступных индексов, то
   неизбежно будут коллизии. Например, если у вас есть 10 возможных индексов и
   15 различных ключей, то как минимум 5 ключей будут иметь одинаковый индекс.
2. Хеш-функция
   Хеш-функция преобразует ключ в целое число (хеш-код), которое затем
   используется для определения индекса в массиве. Если хеш-функция не
   распределяет ключи равномерно по всем возможным индексам, это может привести
   к большому количеству коллизий. Например, если хеш-функция возвращает одно и
   то же значение для разных ключей или если она слишком проста (например,
   просто возвращает последний символ строки), это может привести к частым
   коллизиям.

3. Ограниченная длина хеша
   Некоторые хеш-функции могут генерировать хеш-коды с ограниченной длиной (
   например, 32 бита), что также увеличивает вероятность коллизий. В этом случае
   множество различных входных данных будет отображаться на ограниченное
   количество выходных значений.

4. Сходство ключей
   Если ключи имеют схожие характеристики (например, строки с одинаковыми
   префиксами или числа с одинаковыми значащими цифрами), это может привести к
   тому, что они будут генерировать одинаковые хеш-коды.

Примеры

1. Простая хеш-функция: Если у вас есть строка "abc" и "cba", и ваша хеш-функция
   просто суммирует ASCII-коды символов, то обе строки могут дать один и тот же
   результат.

2. Ограниченный диапазон: Если вы используете целые числа в качестве ключей и
   ваша хеш-функция просто берет остаток от деления на 10 (например, key % 10), то все числа, заканчивающиеся на одну и ту же цифру (например, 12 и 22), будут иметь одинаковый индекс.

Заключение
Коллизии — это естественная часть работы с хеш-таблицами из-за ограниченного
количества индексов и особенностей хеш-функций. Эффективные алгоритмы обработки
коллизий (такие как метод цепочек или открытая адресация) помогают
минимизировать их влияние на производительность операций вставки и поиска в
хеш-таблицах.

> 8. Сложность получения последнего элемента в LinkedList (O(1))
>9. ExecutorService
>10. Atomic пакет Механизм под капотом (CAS)
>11. Scope бинов чуть лучше
>12. Проблема n+1
>13. Уровни кеширования в Hibernate лучше изучить
>14. Оптимистические/Пессимистические блокировки
>15. self injection и как работать с аннотациями в спринге, например Transaction
>16. Kafka про патриции чуть лучше
>17. Индексы в SQL
>18. Уровни транзакции
>19. ACID, проблемы
>20. Java Core:
>- устройство памяти и сборка мусора
>- Collection Framework и внутренняя работа коллекций
>- Работа с исключениями
>- Устройство и особенности StreamAPI
>21. Multithreading
>- Механизмы синхронизации: synchronized, volatile, atomic types
>- Пробелемы race condition и deadlock, способы решения
>- Optimistic и Pessimistic locking
>- Многопоточные коллекции, пулы потоков, Future и CompletableFutute
